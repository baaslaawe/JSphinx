%!
%%BoundingBox: (atend)
%%Pages: (atend)
%%DocumentFonts: (atend)
%%EndComments
%
% FrameMaker PostScript Prolog 3.0, for use with FrameMaker 3.0
% Copyright (c) 1986,87,89,90,91 by Frame Technology Corporation.
% All rights reserved.
%
% Known Problems:
%	Due to bugs in Transcript, the 'PS-Adobe-' is omitted from line 1
/FMversion (3.0) def 
% Set up Color vs. Black-and-White
	/FMPrintInColor systemdict /colorimage known
		systemdict /currentcolortransfer known or def
% Uncomment this line to force b&w on color printer
%   /FMPrintInColor false def
/FrameDict 195 dict def 
systemdict /errordict known not {/errordict 10 dict def
		errordict /rangecheck {stop} put} if
% The readline in 23.0 doesn't recognize cr's as nl's on AppleTalk
FrameDict /tmprangecheck errordict /rangecheck get put 
errordict /rangecheck {FrameDict /bug true put} put 
FrameDict /bug false put 
mark 
% Some PS machines read past the CR, so keep the following 3 lines together!
currentfile 5 string readline
00
0000000000
cleartomark 
errordict /rangecheck FrameDict /tmprangecheck get put 
FrameDict /bug get { 
	/readline {
		/gstring exch def
		/gfile exch def
		/gindex 0 def
		{
			gfile read pop 
			dup 10 eq {exit} if 
			dup 13 eq {exit} if 
			gstring exch gindex exch put 
			/gindex gindex 1 add def 
		} loop
		pop 
		gstring 0 gindex getinterval true 
		} def
	} if
/FMVERSION {
	FMversion ne {
		/Times-Roman findfont 18 scalefont setfont
		100 100 moveto
		(FrameMaker version does not match postscript_prolog!)
		dup =
		show showpage
		} if
	} def 
/FMLOCAL {
	FrameDict begin
	0 def 
	end 
	} def 
	/gstring FMLOCAL
	/gfile FMLOCAL
	/gindex FMLOCAL
	/orgxfer FMLOCAL
	/orgproc FMLOCAL
	/organgle FMLOCAL
	/orgfreq FMLOCAL
	/yscale FMLOCAL
	/xscale FMLOCAL
	/manualfeed FMLOCAL
	/paperheight FMLOCAL
	/paperwidth FMLOCAL
/FMDOCUMENT { 
	array /FMfonts exch def 
	/#copies exch def
	FrameDict begin
	0 ne dup {setmanualfeed} if
	/manualfeed exch def
	/paperheight exch def
	/paperwidth exch def
	/yscale exch def
	/xscale exch def
	currenttransfer cvlit /orgxfer exch def
	currentscreen cvlit /orgproc exch def
	/organgle exch def /orgfreq exch def
	setpapername 
	desperatepapersize
	end 
	} def 
	/pagesave FMLOCAL
	/orgmatrix FMLOCAL
	/landscape FMLOCAL
/FMBEGINPAGE { 
	FrameDict begin 
	/pagesave save def
	3.86 setmiterlimit
	/landscape exch 0 ne def
	landscape { 
		90 rotate 0 exch neg translate pop 
		}
		{pop pop}
		ifelse
	xscale yscale scale
	/orgmatrix matrix def
	gsave 
	} def 
/FMENDPAGE {
	grestore 
	pagesave restore
	end 
	showpage
	} def 
/FMFONTDEFINE { 
	FrameDict begin
	findfont 
	ReEncode 
	1 index exch 
	definefont 
	FMfonts 3 1 roll 
	put
	end 
	} def 
/FMFILLS {
	FrameDict begin
	array /fillvals exch def
	end 
	} def 
/FMFILL {
	FrameDict begin
	 fillvals 3 1 roll put
	end 
	} def 
/FMNORMALIZEGRAPHICS { 
	newpath
	0.0 0.0 moveto
	1 setlinewidth
	0 setlinecap
	0 0 0 sethsbcolor
	0 setgray 
	} bind def
	/fx FMLOCAL
	/fy FMLOCAL
	/fh FMLOCAL
	/fw FMLOCAL
	/llx FMLOCAL
	/lly FMLOCAL
	/urx FMLOCAL
	/ury FMLOCAL
/FMBEGINEPSF { 
	end 
	/FMEPSF save def 
	/showpage {} def 
	FMNORMALIZEGRAPHICS 
	[/fy /fx /fh /fw /ury /urx /lly /llx] {exch def} forall 
	fx fy translate 
	rotate
	fw urx llx sub div fh ury lly sub div scale 
	llx neg lly neg translate 
	} bind def
/FMENDEPSF {
	FMEPSF restore
	FrameDict begin 
	} bind def
FrameDict begin 
/setmanualfeed {
%%BeginFeature *ManualFeed True
	 statusdict /manualfeed true put
%%EndFeature
	} def
/max {2 copy lt {exch} if pop} bind def
/min {2 copy gt {exch} if pop} bind def
/inch {72 mul} def
/pagedimen { 
	paperheight sub abs 16 lt exch 
	paperwidth sub abs 16 lt and
	{/papername exch def} {pop} ifelse
	} def
	/papersizedict FMLOCAL
/setpapername { 
	/papersizedict 14 dict def 
	papersizedict begin
	/papername /unknown def 
		/Letter 8.5 inch 11.0 inch pagedimen
		/LetterSmall 7.68 inch 10.16 inch pagedimen
		/Tabloid 11.0 inch 17.0 inch pagedimen
		/Ledger 17.0 inch 11.0 inch pagedimen
		/Legal 8.5 inch 14.0 inch pagedimen
		/Statement 5.5 inch 8.5 inch pagedimen
		/Executive 7.5 inch 10.0 inch pagedimen
		/A3 11.69 inch 16.5 inch pagedimen
		/A4 8.26 inch 11.69 inch pagedimen
		/A4Small 7.47 inch 10.85 inch pagedimen
		/B4 10.125 inch 14.33 inch pagedimen
		/B5 7.16 inch 10.125 inch pagedimen
	end
	} def
/papersize {
	papersizedict begin
		/Letter {lettertray letter} def
		/LetterSmall {lettertray lettersmall} def
		/Tabloid {11x17tray 11x17} def
		/Ledger {ledgertray ledger} def
		/Legal {legaltray legal} def
		/Statement {statementtray statement} def
		/Executive {executivetray executive} def
		/A3 {a3tray a3} def
		/A4 {a4tray a4} def
		/A4Small {a4tray a4small} def
		/B4 {b4tray b4} def
		/B5 {b5tray b5} def
		/unknown {unknown} def
	papersizedict dup papername known {papername} {/unknown} ifelse get
	end
	/FMdicttop countdictstack 1 add def 
	statusdict begin stopped end 
	countdictstack -1 FMdicttop {pop end} for 
	} def
/manualpapersize {
	papersizedict begin
		/Letter {letter} def
		/LetterSmall {lettersmall} def
		/Tabloid {11x17} def
		/Ledger {ledger} def
		/Legal {legal} def
		/Statement {statement} def
		/Executive {executive} def
		/A3 {a3} def
		/A4 {a4} def
		/A4Small {a4small} def
		/B4 {b4} def
		/B5 {b5} def
		/unknown {unknown} def
	papersizedict dup papername known {papername} {/unknown} ifelse get
	end
	stopped 
	} def
/desperatepapersize {
	statusdict /setpageparams known
		{
		paperwidth paperheight 0 1 
		statusdict begin
		{setpageparams} stopped pop 
		end
		} if
	} def
/savematrix {
	orgmatrix currentmatrix pop
	} bind def
/restorematrix {
	orgmatrix setmatrix
	} bind def
/dmatrix matrix def
/dpi    72 0 dmatrix defaultmatrix dtransform
    dup mul exch   dup mul add   sqrt def
/freq dpi 18.75 div 8 div round dup 0 eq {pop 1} if 8 mul dpi exch div def
/sangle 1 0 dmatrix defaultmatrix dtransform exch atan def
/DiacriticEncoding [
/.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef
/.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef
/.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef
/.notdef /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef
/.notdef /.notdef /.notdef /.notdef /space /exclam /quotedbl
/numbersign /dollar /percent /ampersand /quotesingle /parenleft
/parenright /asterisk /plus /comma /hyphen /period /slash /zero /one
/two /three /four /five /six /seven /eight /nine /colon /semicolon
/less /equal /greater /question /at /A /B /C /D /E /F /G /H /I /J /K
/L /M /N /O /P /Q /R /S /T /U /V /W /X /Y /Z /bracketleft /backslash
/bracketright /asciicircum /underscore /grave /a /b /c /d /e /f /g /h
/i /j /k /l /m /n /o /p /q /r /s /t /u /v /w /x /y /z /braceleft /bar
/braceright /asciitilde /.notdef /Adieresis /Aring /Ccedilla /Eacute
/Ntilde /Odieresis /Udieresis /aacute /agrave /acircumflex /adieresis
/atilde /aring /ccedilla /eacute /egrave /ecircumflex /edieresis
/iacute /igrave /icircumflex /idieresis /ntilde /oacute /ograve
/ocircumflex /odieresis /otilde /uacute /ugrave /ucircumflex
/udieresis /dagger /.notdef /cent /sterling /section /bullet
/paragraph /germandbls /registered /copyright /trademark /acute
/dieresis /.notdef /AE /Oslash /.notdef /.notdef /.notdef /.notdef
/yen /.notdef /.notdef /.notdef /.notdef /.notdef /.notdef
/ordfeminine /ordmasculine /.notdef /ae /oslash /questiondown
/exclamdown /logicalnot /.notdef /florin /.notdef /.notdef
/guillemotleft /guillemotright /ellipsis /.notdef /Agrave /Atilde
/Otilde /OE /oe /endash /emdash /quotedblleft /quotedblright
/quoteleft /quoteright /.notdef /.notdef /ydieresis /Ydieresis
/fraction /currency /guilsinglleft /guilsinglright /fi /fl /daggerdbl
/periodcentered /quotesinglbase /quotedblbase /perthousand
/Acircumflex /Ecircumflex /Aacute /Edieresis /Egrave /Iacute
/Icircumflex /Idieresis /Igrave /Oacute /Ocircumflex /.notdef /Ograve
/Uacute /Ucircumflex /Ugrave /dotlessi /circumflex /tilde /macron
/breve /dotaccent /ring /cedilla /hungarumlaut /ogonek /caron
] def
/ReEncode { 
	dup 
	length 
	dict begin 
	{
	1 index /FID ne 
		{def} 
		{pop pop} ifelse 
	} forall 
	0 eq {/Encoding DiacriticEncoding def} if 
	currentdict 
	end 
	} bind def
/graymode true def
	/bwidth FMLOCAL
	/bpside FMLOCAL
	/bstring FMLOCAL
	/onbits FMLOCAL
	/offbits FMLOCAL
	/xindex FMLOCAL
	/yindex FMLOCAL
	/x FMLOCAL
	/y FMLOCAL
/setpattern {
	 /bwidth  exch def
	 /bpside  exch def
	 /bstring exch def
	 /onbits 0 def  /offbits 0 def
	 freq sangle landscape {90 add} if 
		{/y exch def
		 /x exch def
		 /xindex x 1 add 2 div bpside mul cvi def
		 /yindex y 1 add 2 div bpside mul cvi def
		 bstring yindex bwidth mul xindex 8 idiv add get
		 1 7 xindex 8 mod sub bitshift and 0 ne
		 {/onbits  onbits  1 add def 1}
		 {/offbits offbits 1 add def 0}
		 ifelse
		}
		setscreen
	 {} settransfer
	 offbits offbits onbits add div FMsetgray
	/graymode false def
	} bind def
/grayness {
	FMsetgray
	graymode not {
		/graymode true def
		orgxfer cvx settransfer
		orgfreq organgle orgproc cvx setscreen
		} if
	} bind def
	/HUE FMLOCAL
	/SAT FMLOCAL
	/BRIGHT FMLOCAL
	/Colors FMLOCAL
FMPrintInColor 
	
	{
	/HUE 0 def
	/SAT 0 def
	/BRIGHT 0 def
	% array of arrays Hue and Sat values for the separations [HUE BRIGHT]
	/Colors   
	[[0    0  ]    % black
	 [0    0  ]    % white
	 [0.00 1.0]    % red
	 [0.37 1.0]    % green
	 [0.60 1.0]    % blue
	 [0.50 1.0]    % cyan
	 [0.83 1.0]    % magenta
	 [0.16 1.0]    % comment / yellow
	 ] def
      
	/BEGINBITMAPCOLOR { 
		BITMAPCOLOR} def
	/BEGINBITMAPCOLORc { 
		BITMAPCOLORc} def
	/BEGINBITMAPTRUECOLOR { 
		BITMAPTRUECOLOR } def
	/BEGINBITMAPTRUECOLORc { 
		BITMAPTRUECOLORc } def
	/K { 
		Colors exch get dup
		0 get /HUE exch store 
		1 get /BRIGHT exch store
		  HUE 0 eq BRIGHT 0 eq and
			{1.0 SAT sub setgray}
			{HUE SAT BRIGHT sethsbcolor} 
		  ifelse
		} def
	/FMsetgray { 
		/SAT exch 1.0 exch sub store 
		  HUE 0 eq BRIGHT 0 eq and
			{1.0 SAT sub setgray}
			{HUE SAT BRIGHT sethsbcolor} 
		  ifelse
		} bind def
	}
	
	{
	/BEGINBITMAPCOLOR { 
		BITMAPGRAY} def
	/BEGINBITMAPCOLORc { 
		BITMAPGRAYc} def
	/BEGINBITMAPTRUECOLOR { 
		BITMAPTRUEGRAY } def
	/BEGINBITMAPTRUECOLORc { 
		BITMAPTRUEGRAYc } def
	/FMsetgray {setgray} bind def
	/K { 
		pop
		} def
	}
ifelse
/normalize {
	transform round exch round exch itransform
	} bind def
/dnormalize {
	dtransform round exch round exch idtransform
	} bind def
/lnormalize { 
	0 dtransform exch cvi 2 idiv 2 mul 1 add exch idtransform pop
	} bind def
/H { 
	lnormalize setlinewidth
	} bind def
/Z {
	setlinecap
	} bind def
	/fillvals FMLOCAL
/X { 
	fillvals exch get
	dup type /stringtype eq
	{8 1 setpattern} 
	{grayness}
	ifelse
	} bind def
/V { 
	gsave eofill grestore
	} bind def
/N { 
	stroke
	} bind def
/M {newpath moveto} bind def
/E {lineto} bind def
/D {curveto} bind def
/O {closepath} bind def
	/n FMLOCAL
/L { 
 	/n exch def
	newpath
	normalize
	moveto 
	2 1 n {pop normalize lineto} for
	} bind def
/Y { 
	L 
	closepath
	} bind def
	/x1 FMLOCAL
	/x2 FMLOCAL
	/y1 FMLOCAL
	/y2 FMLOCAL
	/rad FMLOCAL
/R { 
	/y2 exch def
	/x2 exch def
	/y1 exch def
	/x1 exch def
	x1 y1
	x2 y1
	x2 y2
	x1 y2
	4 Y 
	} bind def
/RR { 
	/rad exch def
	normalize
	/y2 exch def
	/x2 exch def
	normalize
	/y1 exch def
	/x1 exch def
	newpath
	x1 y1 rad add moveto
	x1 y2 x2 y2 rad arcto
	x2 y2 x2 y1 rad arcto
	x2 y1 x1 y1 rad arcto
	x1 y1 x1 y2 rad arcto
	closepath
	16 {pop} repeat
	} bind def
/C { 
	grestore
	gsave
	R 
	clip
	} bind def
	/FMpointsize FMLOCAL
/F { 
	FMfonts exch get
	FMpointsize scalefont
	setfont
	} bind def
/Q { 
	/FMpointsize exch def
	F 
	} bind def
/T { 
	moveto show
	} bind def
/RF { 
	rotate
	0 ne {-1 1 scale} if
	} bind def
/TF { 
	gsave
	moveto 
	RF
	show
	grestore
	} bind def
/P { 
	moveto
	0 32 3 2 roll widthshow
	} bind def
/PF { 
	gsave
	moveto 
	RF
	0 32 3 2 roll widthshow
	grestore
	} bind def
/S { 
	moveto
	0 exch ashow
	} bind def
/SF { 
	gsave
	moveto
	RF
	0 exch ashow
	grestore
	} bind def
/B { 
	moveto
	0 32 4 2 roll 0 exch awidthshow
	} bind def
/BF { 
	gsave
	moveto
	RF
	0 32 4 2 roll 0 exch awidthshow
	grestore
	} bind def
/G { 
	gsave
	newpath
	normalize translate 0.0 0.0 moveto 
	dnormalize scale 
	0.0 0.0 1.0 5 3 roll arc 
	closepath fill
	grestore
	} bind def
/A { 
	gsave
	savematrix
	newpath
	2 index 2 div add exch 3 index 2 div sub exch 
	normalize 2 index 2 div sub exch 3 index 2 div add exch 
	translate 
	scale 
	0.0 0.0 1.0 5 3 roll arc 
	restorematrix
	stroke
	grestore
	} bind def
	/x FMLOCAL
	/y FMLOCAL
	/w FMLOCAL
	/h FMLOCAL
	/xx FMLOCAL
	/yy FMLOCAL
	/ww FMLOCAL
	/hh FMLOCAL
	/FMsaveobject FMLOCAL
	/FMoptop FMLOCAL
	/FMdicttop FMLOCAL
/BEGINPRINTCODE { 
	/FMdicttop countdictstack 1 add def 
	/FMoptop count 4 sub def 
	/FMsaveobject save def
	userdict begin 
	/showpage {} def 
	FMNORMALIZEGRAPHICS 
	3 index neg 3 index neg translate
	} bind def
/ENDPRINTCODE {
	count -1 FMoptop {pop pop} for 
	countdictstack -1 FMdicttop {pop end} for 
	FMsaveobject restore 
	} bind def
/gn { 
	0 
	{	46 mul 
		cf read pop 
		32 sub 
		dup 46 lt {exit} if 
		46 sub add 
		} loop
	add 
	} bind def
	/str FMLOCAL
/cfs { 
	/str sl string def 
	0 1 sl 1 sub {str exch val put} for 
	str def 
	} bind def
/ic [ 
	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0223
	0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0223
	0
	{0 hx} {1 hx} {2 hx} {3 hx} {4 hx} {5 hx} {6 hx} {7 hx} {8 hx} {9 hx}
	{10 hx} {11 hx} {12 hx} {13 hx} {14 hx} {15 hx} {16 hx} {17 hx} {18 hx}
	{19 hx} {gn hx} {0} {1} {2} {3} {4} {5} {6} {7} {8} {9} {10} {11} {12}
	{13} {14} {15} {16} {17} {18} {19} {gn} {0 wh} {1 wh} {2 wh} {3 wh}
	{4 wh} {5 wh} {6 wh} {7 wh} {8 wh} {9 wh} {10 wh} {11 wh} {12 wh}
	{13 wh} {14 wh} {gn wh} {0 bl} {1 bl} {2 bl} {3 bl} {4 bl} {5 bl} {6 bl}
	{7 bl} {8 bl} {9 bl} {10 bl} {11 bl} {12 bl} {13 bl} {14 bl} {gn bl}
	{0 fl} {1 fl} {2 fl} {3 fl} {4 fl} {5 fl} {6 fl} {7 fl} {8 fl} {9 fl}
	{10 fl} {11 fl} {12 fl} {13 fl} {14 fl} {gn fl}
	] def
	/sl FMLOCAL
	/val FMLOCAL
	/ws FMLOCAL
	/im FMLOCAL
	/bs FMLOCAL
	/cs FMLOCAL
	/len FMLOCAL
	/pos FMLOCAL
/ms { 
	/sl exch def 
	/val 255 def 
	/ws cfs 
	/im cfs 
	/val 0 def 
	/bs cfs 
	/cs cfs 
	} bind def
400 ms 
/ip { 
	is 
	0 
	cf cs readline pop 
	{	ic exch get exec 
		add 
		} forall 
	pop 
	
	} bind def
/wh { 
	/len exch def 
	/pos exch def 
	ws 0 len getinterval im pos len getinterval copy pop
	pos len 
	} bind def
/bl { 
	/len exch def 
	/pos exch def 
	bs 0 len getinterval im pos len getinterval copy pop
	pos len 
	} bind def
/s1 1 string def
/fl { 
	/len exch def 
	/pos exch def 
	/val cf s1 readhexstring pop 0 get def
	pos 1 pos len add 1 sub {im exch val put} for
	pos len 
	} bind def
/hx { 
	3 copy getinterval 
	cf exch readhexstring pop pop 
	} bind def
	/h FMLOCAL
	/w FMLOCAL
	/d FMLOCAL
	/lb FMLOCAL
	/bitmapsave FMLOCAL
	/is FMLOCAL
	/cf FMLOCAL
/wbytes { 
	dup 
	8 eq {pop} {1 eq {7 add 8 idiv} {3 add 4 idiv} ifelse} ifelse
	} bind def
/BEGINBITMAPBWc { 
	1 {} COMMONBITMAPc
	} bind def
/BEGINBITMAPGRAYc { 
	8 {} COMMONBITMAPc
	} bind def
/BEGINBITMAP2BITc { 
	2 {} COMMONBITMAPc
	} bind def
/COMMONBITMAPc { 
	/r exch def
	/d exch def
	gsave
	translate rotate scale /h exch def /w exch def
	/lb w d wbytes def 
	sl lb lt {lb ms} if 
	/bitmapsave save def 
	r                    
	/is im 0 lb getinterval def 
	ws 0 lb getinterval is copy pop 
	/cf currentfile def 
	w h d [w 0 0 h neg 0 h] 
	{ip} image 
	bitmapsave restore 
	grestore
	} bind def
/BEGINBITMAPBW { 
	1 {} COMMONBITMAP
	} bind def
/BEGINBITMAPGRAY { 
	8 {} COMMONBITMAP
	} bind def
/BEGINBITMAP2BIT { 
	2 {} COMMONBITMAP
	} bind def
/COMMONBITMAP { 
	/r exch def
	/d exch def
	gsave
	translate rotate scale /h exch def /w exch def
	/bitmapsave save def 
	r                    
	/is w d wbytes string def
	/cf currentfile def 
	w h d [w 0 0 h neg 0 h] 
	{cf is readhexstring pop} image
	bitmapsave restore 
	grestore
	} bind def
	/proc1 FMLOCAL
	/proc2 FMLOCAL
	/newproc FMLOCAL
/Fmcc {
    /proc2 exch cvlit def
    /proc1 exch cvlit def
    /newproc proc1 length proc2 length add array def
    newproc 0 proc1 putinterval
    newproc proc1 length proc2 putinterval
    newproc cvx
} bind def
/ngrayt 256 array def
/nredt 256 array def
/nbluet 256 array def
/ngreent 256 array def
	/gryt FMLOCAL
	/blut FMLOCAL
	/grnt FMLOCAL
	/redt FMLOCAL
	/indx FMLOCAL
	/cynu FMLOCAL
	/magu FMLOCAL
	/yelu FMLOCAL
	/k FMLOCAL
	/u FMLOCAL
/colorsetup {
	currentcolortransfer
	/gryt exch def
	/blut exch def
	/grnt exch def
	/redt exch def
	0 1 255 {
		/indx exch def
		/cynu 1 red indx get 255 div sub def
		/magu 1 green indx get 255 div sub def
		/yelu 1 blue indx get 255 div sub def
		/k cynu magu min yelu min def
		/u k currentundercolorremoval exec def
		nredt indx 1 0 cynu u sub max sub redt exec put
		ngreent indx 1 0 magu u sub max sub grnt exec put
		nbluet indx 1 0 yelu u sub max sub blut exec put
		ngrayt indx 1 k currentblackgeneration exec sub gryt exec put
	} for
	{255 mul cvi nredt exch get}
	{255 mul cvi ngreent exch get}
	{255 mul cvi nbluet exch get}
	{255 mul cvi ngrayt exch get}
	setcolortransfer
	{pop 0} setundercolorremoval
	{} setblackgeneration
	} bind def
	/tran FMLOCAL
/fakecolorsetup {
	/tran 256 string def
	0 1 255 {/indx exch def 
		tran indx
		red indx get 77 mul
		green indx get 151 mul
		blue indx get 28 mul
		add add 256 idiv put} for
	currenttransfer
	{255 mul cvi tran exch get 255.0 div}
	exch Fmcc settransfer
} bind def
/BITMAPCOLOR { 
	/d 8 def
	gsave
	translate rotate scale /h exch def /w exch def
	/bitmapsave save def 
	colorsetup
	/is w d wbytes string def
	/cf currentfile def 
	w h d [w 0 0 h neg 0 h] 
	{cf is readhexstring pop} {is} {is} true 3 colorimage 
	bitmapsave restore 
	grestore
	} bind def
/BITMAPCOLORc { 
	/d 8 def
	gsave
	translate rotate scale /h exch def /w exch def
	/lb w d wbytes def 
	sl lb lt {lb ms} if 
	/bitmapsave save def 
	colorsetup
	/is im 0 lb getinterval def 
	ws 0 lb getinterval is copy pop 
	/cf currentfile def 
	w h d [w 0 0 h neg 0 h] 
	{ip} {is} {is} true 3 colorimage
	bitmapsave restore 
	grestore
	} bind def
/BITMAPTRUECOLORc { 
        gsave
        translate rotate scale /h exch def /w exch def
        /bitmapsave save def 
        
        /is w string def
        
        ws 0 w getinterval is copy pop 
        /cf currentfile def 
        w h 8 [w 0 0 h neg 0 h] 
        {ip} {gip} {bip} true 3 colorimage
        bitmapsave restore 
        grestore
        } bind def
/BITMAPTRUECOLOR { 
        gsave
        translate rotate scale /h exch def /w exch def
        /bitmapsave save def 
        /is w string def
        /gis w string def
        /bis w string def
        /cf currentfile def 
        w h 8 [w 0 0 h neg 0 h] 
        { cf is readhexstring pop } 
        { cf gis readhexstring pop } 
        { cf bis readhexstring pop } 
        true 3 colorimage 
        bitmapsave restore 
        grestore
        } bind def
/BITMAPTRUEGRAYc { 
        gsave
        translate rotate scale /h exch def /w exch def
        /bitmapsave save def 
        
        /is w string def
        
        ws 0 w getinterval is copy pop 
        /cf currentfile def 
        w h 8 [w 0 0 h neg 0 h] 
        {ip gip bip w gray} image
        bitmapsave restore 
        grestore
        } bind def
/ww FMLOCAL
/r FMLOCAL
/g FMLOCAL
/b FMLOCAL
/i FMLOCAL
/gray { 
        /ww exch def
        /b exch def
        /g exch def
        /r exch def
        0 1 ww 1 sub { /i exch def r i get .299 mul g i get .587 mul
			b i get .114 mul add add r i 3 -1 roll floor cvi put } for
        r
        } bind def
/BITMAPTRUEGRAY { 
        gsave
        translate rotate scale /h exch def /w exch def
        /bitmapsave save def 
        /is w string def
        /gis w string def
        /bis w string def
        /cf currentfile def 
        w h 8 [w 0 0 h neg 0 h] 
        { cf is readhexstring pop 
          cf gis readhexstring pop 
          cf bis readhexstring pop w gray}  image
        bitmapsave restore 
        grestore
        } bind def
/BITMAPGRAY { 
	8 {fakecolorsetup} COMMONBITMAP
	} bind def
/BITMAPGRAYc { 
	8 {fakecolorsetup} COMMONBITMAPc
	} bind def
/ENDBITMAP {
	} bind def
end 
	/ALDsave FMLOCAL
	/ALDmatrix matrix def ALDmatrix currentmatrix pop
/StartALD {
	/ALDsave save def
	 savematrix
	 ALDmatrix setmatrix
	} bind def
/InALD {
	 restorematrix
	} bind def
/DoneALD {
	 ALDsave restore
	} bind def
%%EndProlog
%%BeginSetup
(3.0) FMVERSION
1 1 612 792 0 1 13 FMDOCUMENT
0 0 /Helvetica-Bold FMFONTDEFINE
1 0 /Helvetica FMFONTDEFINE
2 0 /Times-Roman FMFONTDEFINE
3 0 /Helvetica-Oblique FMFONTDEFINE
4 1 /Symbol FMFONTDEFINE
5 0 /Times-Bold FMFONTDEFINE
32 FMFILLS
0 0 FMFILL
1 0.1 FMFILL
2 0.3 FMFILL
3 0.5 FMFILL
4 0.7 FMFILL
5 0.9 FMFILL
6 0.97 FMFILL
7 1 FMFILL
8 <0f1e3c78f0e1c387> FMFILL
9 <0f87c3e1f0783c1e> FMFILL
10 <cccccccccccccccc> FMFILL
11 <ffff0000ffff0000> FMFILL
12 <8142241818244281> FMFILL
13 <03060c183060c081> FMFILL
14 <8040201008040201> FMFILL
16 1 FMFILL
17 0.9 FMFILL
18 0.7 FMFILL
19 0.5 FMFILL
20 0.3 FMFILL
21 0.1 FMFILL
22 0.03 FMFILL
23 0 FMFILL
24 <f0e1c3870f1e3c78> FMFILL
25 <f0783c1e0f87c3e1> FMFILL
26 <3333333333333333> FMFILL
27 <0000ffff0000ffff> FMFILL
28 <7ebddbe7e7dbbd7e> FMFILL
29 <fcf9f3e7cf9f3f7e> FMFILL
30 <7fbfdfeff7fbfdfe> FMFILL
%%EndSetup
%%Page: "1" 1
%%BeginPaperSize: Letter
%%EndPaperSize
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
72 32.67 540 42.67 R
V
72 72 540 720 R
V
0 14 Q
0 X
(Connected Digit Recognition over Long Distance T) 86.49 630.67 T
(elephone Lines) 423.65 630.67 T
(using the SPHINX-II System) 213.86 614.67 T
1 F
(Uday Jain) 274.89 502.67 T
1 12 Q
(Submitted to the Department of Electrical and Computer Engineering) 123.35 376 T
(in Partial Ful\336llment of the Requirements for the) 179.36 362 T
(Degree of Master of Science at) 223.34 348 T
(Carnegie Mellon University) 234.36 306 T
(Pittsburgh, Pennsylvania 15213) 221.67 292 T
(May 1996) 279.67 236 T
FMENDPAGE
%%EndPage: "1" 2
%%Page: "2" 2
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
72 32.67 540 42.67 R
V
72 72 540 720 R
V
2 12 Q
0 X
(Abstract 4) 72 712 T
(Introduction 5) 72 698 T
0 10 Q
(1.1) 90 685.33 T
1 F
( Large vocabulary vs. small vocabulary tasks) 103.89 685.33 T
(   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .) 302.85 685.33 T
(5) 534.44 685.33 T
0 F
(1.2) 90 673.33 T
1 F
( Overview) 103.89 673.33 T
(  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .) 150.04 673.33 T
(6) 534.44 673.33 T
2 12 Q
(The SPHINX II System 8) 72 660 T
0 10 Q
(2.1) 90 647.33 T
1 F
( Overview of SPHINX II) 103.89 647.33 T
( .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .) 208.38 647.33 T
(8) 534.44 647.33 T
0 F
(2.2) 90 635.33 T
1 F
( Hidden Markov Models \050HMMs\051) 103.89 635.33 T
(   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .) 247.28 635.33 T
(8) 534.44 635.33 T
(Recognition Unit 9) 108 623.33 T
0 F
(2.3) 90 611.33 T
1 F
( The SPHINX-II T) 103.89 611.33 T
(rainer) 181.28 611.33 T
( .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .) 208.38 611.33 T
(10) 528.89 611.33 T
(Acoustical Feature Extraction 10) 108 599.33 T
(Lexical Feature Extraction 10) 108 587.33 T
(Context-Independent System T) 108 575.33 T
(raining 1) 245.95 575.33 T
(1) 283.54 575.33 T
(Segmentation and Senonic Clustering 1) 108 563.33 T
(1) 283.36 563.33 T
(Context-Dependent System T) 108 551.33 T
(raining 12) 239.28 551.33 T
0 F
(2.4) 90 539.33 T
1 F
( Decoder) 103.89 539.33 T
(.   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .) 144.48 539.33 T
(12) 528.89 539.33 T
0 F
(2.5) 90 527.33 T
1 F
( The T) 103.89 527.33 T
(raining Procedure) 132.41 527.33 T
(   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .) 213.94 527.33 T
(13) 528.89 527.33 T
(Bootstrapped T) 108 515.33 T
(raining 13) 175.96 515.33 T
(Acoustic Feature Extraction 13) 126 503.33 T
(Lexical Feature Extraction 13) 126 491.33 T
(Segmentation 13) 126 479.33 T
(Creation of CI-DHMMs 13) 126 467.33 T
(Creation of the Senonic Decision T) 126 455.33 T
(rees and Mapping T) 280.05 455.33 T
(able 14) 367.83 455.33 T
(Creation of CD-SCHMMs 14) 126 443.33 T
(Fine T) 126 431.33 T
(uning the CD-SCHMMs 14) 153.96 431.33 T
(T) 108 419.33 T
(raining from Scratch 15) 113.74 419.33 T
(Acoustic Feature Extraction 15) 126 407.33 T
(Lexical Feature Extraction 15) 126 395.33 T
(Creation of CI-SCHMMs 15) 126 383.33 T
(Segmentation and the Creation of Senonic Decision T) 126 371.33 T
(rees and Mapping T) 363.95 371.33 T
(able 15) 451.72 371.33 T
(Creation of CD-SCHMMs 16) 126 359.33 T
(Fine T) 126 347.33 T
(uning the CD-SCHMMs 16) 153.96 347.33 T
0 F
(2.6) 90 335.33 T
1 F
( Summary) 103.89 335.33 T
(  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .) 150.04 335.33 T
(16) 528.89 335.33 T
2 12 Q
(Speech Corpora 17) 72 322 T
0 10 Q
(3.1) 90 309.33 T
1 F
( MALL Databases) 103.89 309.33 T
(  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .) 183.38 309.33 T
(17) 528.89 309.33 T
0 F
(3.2) 90 297.33 T
1 F
( Other Databases) 103.89 297.33 T
(  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .) 183.38 297.33 T
(18) 528.89 297.33 T
(Reduced Bandwidth AN4 19) 108 285.33 T
(Filtered WSJ0+WSJ1 19) 108 273.33 T
(Macrophone 20) 108 261.33 T
0 F
(3.3) 90 249.33 T
1 F
( Summary) 103.89 249.33 T
(  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .) 150.04 249.33 T
(20) 528.89 249.33 T
2 12 Q
(Performance of Existing Systems 21) 72 236 T
0 10 Q
(4.1) 90 223.33 T
1 F
( Reduced Bandwidth AN4) 103.89 223.33 T
( .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .) 219.5 223.33 T
(21) 528.89 223.33 T
0 F
(4.2) 90 211.33 T
1 F
( Filtered WSJ 1PD models) 103.89 211.33 T
(.   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .) 222.28 211.33 T
(22) 528.89 211.33 T
0 F
(4.3) 90 199.33 T
1 F
( Macrophone models) 103.89 199.33 T
( .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .) 197.27 199.33 T
(23) 528.89 199.33 T
0 F
(4.4) 90 187.33 T
1 F
( Summary) 103.89 187.33 T
(  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .) 150.04 187.33 T
(24) 528.89 187.33 T
2 12 Q
(Bootstrapped Training 25) 72 174 T
0 10 Q
(5.1) 90 161.33 T
1 F
( Filtered WSJ models) 103.89 161.33 T
(.   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .) 200.05 161.33 T
(25) 528.89 161.33 T
0 F
(5.2) 90 149.33 T
1 F
( Macrophone models) 103.89 149.33 T
( .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .) 197.27 149.33 T
(26) 528.89 149.33 T
0 F
(5.3) 90 137.33 T
1 F
( Summary) 103.89 137.33 T
(  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .) 150.04 137.33 T
(27) 528.89 137.33 T
2 12 Q
(Data-Driven Training 28) 72 124 T
0 10 Q
(6.1) 90 111.33 T
1 F
( MALL 88) 103.89 111.33 T
(   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .) 147.26 111.33 T
(29) 528.89 111.33 T
(Context-Independent Semi-Continuous HMMs 29) 108 99.33 T
(Context-Dependent Semi-Continuous HMMs 30) 108 87.33 T
0 F
(6.2) 90 75.33 T
1 F
( MALL91) 103.89 75.33 T
(.   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .) 144.48 75.33 T
(32) 528.89 75.33 T
FMENDPAGE
%%EndPage: "2" 3
%%Page: "3" 3
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
72 32.67 540 42.67 R
V
72 72 540 720 R
V
1 10 Q
0 X
(Context-Independent Semi-Continuous HMMs 32) 108 713.33 T
(Context-Dependent Semi-Continuous HMMs 32) 108 701.33 T
(Context-Dependent Semi-Continuous HMMs 34) 108 689.33 T
0 F
(6.3) 90 677.33 T
1 F
( Summary) 103.89 677.33 T
(  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .) 150.04 677.33 T
(34) 528.89 677.33 T
2 12 Q
(Word-Based Systems 36) 72 664 T
0 10 Q
(7.1) 90 651.33 T
1 F
( System Description) 103.89 651.33 T
(  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .) 194.49 651.33 T
(36) 528.89 651.33 T
0 F
(7.2) 90 639.33 T
1 F
( T) 103.89 639.33 T
(raining) 112.41 639.33 T
(.   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .) 144.48 639.33 T
(37) 528.89 639.33 T
(The MALL88 Database 38) 108 627.33 T
(Context-Independent Semi Continuous HMMs 38) 126 615.33 T
(Context-Dependent Semi-Continuous HMMs 39) 126 603.33 T
(Further Processing 40) 126 591.33 T
(The MALL91 Database 40) 108 579.33 T
(Context-Independent Semi-Continuous HMMs 40) 126 567.33 T
(Context Dependent Semi-Continuous HMMs 41) 126 555.33 T
(Further Processing 42) 126 543.33 T
0 F
(7.3) 90 531.33 T
1 F
( Summary) 103.89 531.33 T
(  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .) 150.04 531.33 T
(42) 528.89 531.33 T
2 12 Q
(Towards a Word-based System using an Approximation to Continuous HMMs 43) 72 518 T
0 10 Q
(8.1) 90 505.33 T
1 F
( T) 103.89 505.33 T
(raining using Multiple Gaussian Set \050MGS\051) 112.41 505.33 T
(   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .) 302.85 505.33 T
(44) 528.89 505.33 T
0 F
(8.2) 90 493.33 T
1 F
( Gender-dependent training) 103.89 493.33 T
(  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .) 227.84 493.33 T
(45) 528.89 493.33 T
0 F
(8.3) 90 481.33 T
1 F
( Summary) 103.89 481.33 T
(  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .) 150.04 481.33 T
(46) 528.89 481.33 T
2 12 Q
(Environmental Adaptation 47) 72 468 T
0 10 Q
(9.1) 90 455.33 T
1 F
( CDCN) 103.89 455.33 T
(   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .) 136.15 455.33 T
(47) 528.89 455.33 T
0 F
(9.2) 90 443.33 T
1 F
( Cross Environment Normalization) 103.89 443.33 T
(.   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .) 255.62 443.33 T
(47) 528.89 443.33 T
(MALL88 48) 108 431.33 T
(MALL91 49) 108 419.33 T
0 F
(9.3) 90 407.33 T
1 F
( T) 103.89 407.33 T
(est set Normalization) 111.67 407.33 T
(  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .) 205.61 407.33 T
(50) 528.89 407.33 T
0 F
(9.4) 90 395.33 T
1 F
( Summary) 103.89 395.33 T
(  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .) 150.04 395.33 T
(51) 528.89 395.33 T
2 12 Q
(Conclusion 52) 72 382 T
0 10 Q
(10.1) 90 369.33 T
1 F
( T) 109.45 369.33 T
(raining models closer to the training data) 117.96 369.33 T
(.   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .) 300.08 369.33 T
(53) 528.89 369.33 T
0 F
(10.2) 90 357.33 T
1 F
( Making the system completely digit oriented) 109.45 357.33 T
( .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .) 308.41 357.33 T
(53) 528.89 357.33 T
0 F
(10.3) 90 345.33 T
1 F
( Increased models size and reduced parameter sharing) 109.45 345.33 T
(.   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .) 355.64 345.33 T
(54) 528.89 345.33 T
0 F
(10.4) 90 333.33 T
1 F
( Normalization) 109.45 333.33 T
( .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .) 175.04 333.33 T
(54) 528.89 333.33 T
0 F
(10.5) 90 321.33 T
1 F
( Future W) 109.45 321.33 T
(ork) 153.15 321.33 T
(   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .) 169.49 321.33 T
(55) 528.89 321.33 T
(Power variance training 55) 108 309.33 T
(Silence removal 55) 108 297.33 T
2 12 Q
(References 56) 72 284 T
FMENDPAGE
%%EndPage: "3" 4
%%Page: "5" 4
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
72 32.67 540 42.67 R
V
72 72 540 720 R
V
0 18 Q
0 X
(Acknowledgments) 226.53 708 T
1 11 Q
-0.1 (I would like to thank the following people whose help and guidance made this work possi-) 108 672.67 P
(ble. Dr) 72 650.67 T
(. Stern, my advisor who guided my research by encouraging me to question the methods) 103.75 650.67 T
(used rather than follow them blindly) 72 628.67 T
(. He showed me that the path to the answer has treasures) 243.99 628.67 T
-0.21 (more valuable than the \336nal result. Dr) 72 606.67 P
-0.21 (. Raj Reddy for sponsoring my stay at Carnegie Mellon Uni-) 252.7 606.67 P
-0.36 (versity) 72 584.67 P
-0.36 (. Dr) 102.93 584.67 P
-0.36 (. Pedro Moreno for his interest and guidance which proved invaluable. Matthew Siegler) 119.66 584.67 P
(for patiently guiding me through the SPHINX II trainer) 72 562.67 T
(. Bhiksha Raj, Evandro Gouvea and V) 330.92 562.67 T
(ipul) 515.75 562.67 T
(Parikh for the numerous discussions we had. Eric Thayer) 72 540.67 T
(, Ravi Mosur and Bob W) 349.21 540.67 T
(eide for the) 468.07 540.67 T
(support they provide by maintaining the SPHINX II system.) 72 518.67 T
FMENDPAGE
%%EndPage: "5" 5
%%Page: "4" 5
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter1: Introduction) 72 749.33 T
(4) 534.44 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
0 18 Q
0 X
(Abstract) 269.52 708 T
1 11 Q
(This report documents the performance of the SPHINX II system on two connected digit) 108 672.67 T
-0.36 (databases. The two databases, MALL88 and MALL91 were collected on long distance telephone) 72 650.67 P
(lines at two sites, and they have the identical vocabulary of the ten digits + \322OH\323.) 72 628.67 T
(W) 108 606.67 T
(e describe the performance of the system using existing models developed for large) 118.17 606.67 T
(vocabulary speech recognition. T) 72 584.67 T
(o further improve recognition accuracy two training procedures) 231.98 584.67 T
(\050bootstrapped training and data-driven training\051 are described and compared. It was found that) 72 562.67 T
(further improvements can be obtained by untying parameters trained and increasing the model) 72 540.67 T
-0.13 (size. This is possible due to the small vocabulary size. T) 72 518.67 P
-0.13 (o facilitate the untying of the parameters) 342.42 518.67 P
(a new phone set was de\336ned and trained, which separated distributions that were shared in pre-) 72 496.67 T
-0.03 (vious training procedures. The new phones also ensure that training data is not shared between) 72 474.67 P
(words. Results for all three training procedures are presented. Application of the procedures) 72 452.67 T
(described in this report reduced the word error rate from 18 percent \050using systems that had) 72 430.67 T
(been trained for large vocabulary recognition\051 to 1.6 percent.) 72 408.67 T
-0.14 (Finally the use of channel and test-set normalization was also explored. It was found that) 108 386.67 P
(the CDCN algorithm \050which compensates for unknown additive noise and unknown linear \336lter-) 72 364.67 T
(ing\051 did not provide further improvements to recognition accuracy for these data.) 72 342.67 T
FMENDPAGE
%%EndPage: "4" 6
%%Page: "5" 6
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter1: Introduction) 72 749.33 T
(5) 534.44 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
0 18 Q
0 X
(Chapter 1) 264.52 708 T
(Introduction) 253.53 674 T
1 11 Q
-0.49 (Connected digit recognition, the recognition of the digits ZERO \050and/or OH\051 through NINE,) 108 638.67 P
-0.33 (is an important task domain for continuous speech recognition. It shows up in a variety of applica-) 72 616.67 P
-0.29 (tions such as speaker identi\336cation, telephone banking, form or database entry) 72 594.67 P
-0.29 (, remote or hands-) 451.12 594.67 P
-0.06 (free credit card transactions. In many of these applications the telephone is a very convenient in-) 72 572.67 P
0.71 (terface between the user and the machine providing the services. Above all the telephone pro-) 72 550.67 P
-0.75 (vides for remote access to all users accessing the system, because it has become truly ubiquitous.) 72 528.67 P
-0.54 (The limited vocabulary of the digit task, with its reduced acoustic confusability) 72 506.67 P
-0.54 (, also make it an ide-) 441.35 506.67 P
(al testbed for new recognition systems.) 72 484.67 T
0 14 Q
(1.1) 72 448.67 T
(Large vocabulary vs. small vocabulary tasks) 99.23 448.67 T
1 11 Q
1.96 (T) 108 424.67 P
1.96 (raditional speech recognition systems have been very task dependent. Their perfor-) 114.31 424.67 P
0.03 (mance degrades when they are tested on a domain that is dif) 72 402.67 P
0.03 (ferent from the one with which they) 369.48 402.67 P
0.39 (were trained. This drop in performance is due to the fact that systems are \336ne tuned to the task) 72 380.67 P
-0.39 (they have been built for) 72 358.67 P
-0.39 (, which reduces their adaptability to dif) 184.03 358.67 P
-0.39 (ferent tasks. In this work we explore) 367.72 358.67 P
(the adaptability of the SPHINX II system across the dimension of vocabulary size.) 72 336.67 T
0.26 (Systems built to work on large-vocabulary tasks with dictionary sizes in the thousands of) 108 314.67 P
(words are optimized as follows:) 72 292.67 T
(\245) 90 270.67 T
(Phone models. Phone units are easily trained and shared across large vocabularies.) 99 270.67 T
(\245) 90 247.67 T
1.03 (Large dictionaries. The large vocabularies increase the acoustic variability that has to be) 99 247.67 P
(modelled which results in increased confusability between hypotheses.) 99 234.67 T
(\245) 90 211.67 T
-0.24 (Shared parameters across models. T) 99 211.67 P
-0.24 (o successfully model the greater variability of the data,) 277.54 211.67 P
0.62 (the amount of training data required also increases. Model parameters have to be shared) 99 198.67 P
(due to the reality of limited training data.) 99 185.67 T
(\245) 90 162.67 T
0.12 (Language models. Additional gain in performance is obtained from modelling the language) 99 162.67 P
(structure.) 99 149.67 T
-0.44 (On the other hand, systems that have been built to work on small vocabulary tasks are op-) 108 126.67 P
(timized dif) 72 104.67 T
(ferently:) 121.25 104.67 T
FMENDPAGE
%%EndPage: "5" 7
%%Page: "6" 7
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter1: Introduction) 72 749.33 T
(6) 534.44 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
1 11 Q
0 X
(\245) 90 712.67 T
-0.24 (W) 99 712.67 P
-0.24 (ord models. W) 109.17 712.67 P
-0.24 (ords are modelled rather than the phones. This is advantageous for contin-) 179.31 712.67 P
(uous speech because coarticulation gets better modelled.) 99 699.67 T
(\245) 90 676.67 T
0.17 (Small dictionaries. The smaller vocabulary results in a reduced amount of acoustic confus-) 99 676.67 P
(ability) 99 663.67 T
(.) 126.27 663.67 T
(\245) 90 640.67 T
0.16 (Independent parameters. Because the training data are being used to model fewer param-) 99 640.67 P
0.47 (eters \050a digit system requires fewer acoustic classes than a large-vocabulary system\051, pa-) 99 627.67 P
(rameter sharing is no longer necessary) 99 614.67 T
(.) 288.08 614.67 T
(\245) 90 591.67 T
0.36 (No language models. A language structure is not always available or learned for small vo-) 99 591.67 P
0.21 (cabulary tasks. This means that the entire model dif) 99 578.67 P
0.21 (ferentiation power must come from the) 351.48 578.67 P
(acoustic dimension.) 99 565.67 T
-0.71 (In this body of work we start with a large-vocabulary con\336guration of the SPHINX II system,) 108 542.67 P
-0.58 (and try to adapt the system to a digit recognition task. W) 72 520.67 P
-0.58 (e are working with the additional complex-) 338.96 520.67 P
0.1 (ity that the digits were collected over the telephone network. The telephone network reduces the) 72 498.67 P
1.24 (bandwidth of the signal available for analysis, adds noise, and adds spectral coloration to the) 72 476.67 P
(speech signals.) 72 454.67 T
0 14 Q
(1.2) 72 418.67 T
(Overview) 99.23 418.67 T
1 11 Q
0.43 (W) 108 394.67 P
0.43 (e start by exploring the performance level that is obtained by models trained for large-) 118.17 394.67 P
-0.12 (vocabulary tasks when used to recognize a digit database test set. W) 72 372.67 P
-0.12 (e test models trained on \0501\051) 406.9 372.67 P
-0.08 (bandlimited speech, \0502\051 speech passed through an average telephone channel, and \0503\051 real tele-) 72 350.67 P
0.87 (phone speech. By so doing we observe the change in recognition accuracy as the models ap-) 72 328.67 P
0.5 (proach the test set across the dimension of degradation caused by limited bandwidth and other) 72 306.67 P
(channel ef) 72 284.67 T
(fects.) 122.49 284.67 T
1.01 (T) 108 262.67 P
1.01 (o further improve performance we realize that training using the digit data is required.) 113.49 262.67 P
0.37 (Here we explore the usual training paradigm involving the initialization of the training data using) 72 240.67 P
0.67 (existing models. This is the method routinely used when training models for a large vocabulary) 72 218.67 P
0.21 (task. This method is then compared to training where no initial models are used and the training) 72 196.67 P
-0.67 (is completely driven by domain-speci\336c data. W) 72 174.67 P
-0.67 (e observe that the second procedure provides bet-) 299.19 174.67 P
(ter models for the small vocabulary task.) 72 152.67 T
-0.37 (W) 108 130.67 P
-0.37 (e would still like to obtain a \336nal system that is optimized for the digit task using SPHINX) 118.17 130.67 P
-0.12 (II. In an attempt to increase the model size from phone models to word models and to reduce the) 72 108.67 P
-0.09 (amount of parameter sharing we explore the possibility of word based phones. W) 72 86.67 P
-0.09 (e de\336ne a com-) 464.55 86.67 P
FMENDPAGE
%%EndPage: "6" 8
%%Page: "7" 8
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter1: Introduction) 72 749.33 T
(7) 534.44 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
1 11 Q
0 X
1.12 (pletely new phone set for the digit recognition task and compare the results when models are) 72 712.67 P
0.58 (trained using this new phone set. An improvement in performance is observed over recognition) 72 690.67 P
(using the usual phone models.) 72 668.67 T
1.06 (Finally we explore the possibilities for channel and test set normalization to reduce the) 108 646.67 P
0.27 (acoustic dif) 72 624.67 P
0.27 (ferences between the training and the testing speech data. Since stereo data \050simul-) 127.02 624.67 P
-0.16 (taneously recorded using noisy and clean speech\051 are not available, we use the CDCN algorithm) 72 602.67 P
0.3 (in our investigation. This algorithm does not require stereo data and attempts to correct for deg-) 72 580.67 P
(radations due to linear channel and additive noise.) 72 558.67 T
-0.25 (Through this work we show that it is possible to obtain acceptable results on a digit recog-) 108 536.67 P
(nition task using a system that was built for large vocabulary speech recognition.) 72 514.67 T
FMENDPAGE
%%EndPage: "7" 9
%%Page: "8" 9
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 2: The SPHINX-II System) 72 749.33 T
(8) 534.44 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
0 18 Q
0 X
(Chapter 2) 264.52 708 T
(The SPHINX II System) 212.02 674 T
1 11 Q
-0.71 (The speech recognition system used in this project is the SPHINX II [8]. system. This chap-) 108 638.67 P
0.38 (ter provides an overview of various training methods for SPHINX II, discussing each of the sub-) 72 616.67 P
0.4 (sections that make up the training system. The decoder used will also be discussed to a limited) 72 594.67 P
(degree.) 72 572.67 T
0 14 Q
(2.1) 72 536.67 T
(Overview of SPHINX II) 99.23 536.67 T
1 11 Q
0.26 (SPHINX-II is a large vocabulary) 108 512.67 P
0.26 (, speaker independent, Semi-Continuous Hidden Markov) 262.7 512.67 P
-0.53 (Model \050SCHMM\051 based continuous speech recognition system. The original SPHINX [10] system,) 72 490.67 P
-0.44 (developed at CMU in 1988, was one of the \336rst systems to demonstrate the feasibility of accurate,) 72 468.67 P
1.38 (speaker-independent, large vocabulary continuous speech recognition. Since then the system) 72 446.67 P
1.14 (has gone through signi\336cant improvements and changes, such as the use of semi continuous) 72 424.67 P
(HMMs and the use of senonic clustering [9], that have considerably enhanced its performance.) 72 402.67 T
0 14 Q
(2.2) 72 366.67 T
(Hidden Markov Models \050HMMs\051) 99.23 366.67 T
1 11 Q
0.19 (Hidden Markov Modelling [7],[14] is the most widely accepted and successful technology) 108 342.67 P
-0.54 (used for contemporary speech recognition. It is a statistical method that characterizes the spectral) 72 320.67 P
0.26 (and temporal properties of speech. HMMs can model speech on many levels, including phones,) 72 298.67 P
0.78 (syllables and words. Depending on the availability of training data and the size of the task, the) 72 276.67 P
-0.7 (model size can be selected to ensure that the parameters of the models will be estimated with min-) 72 254.67 P
(imum error) 72 232.67 T
(. This selection of the model size is usually carried out in an) 124.49 232.67 T
3 F
(ad hoc) 416.97 232.67 T
1 F
( manner) 449.95 232.67 T
(.) 489.64 232.67 T
1.11 (Speech recognition systems are adversely af) 108 210.67 P
1.11 (fected by any changes in the training and) 331.93 210.67 P
0.38 (testing environment. The performance of HMMs also degrades as acoustic dif) 72 188.67 P
0.38 (ferences between) 452.91 188.67 P
-0.51 (the training and testing data increase. T) 72 166.67 P
-0.51 (o alleviate this problem researchers try to either train mod-) 260.69 166.67 P
0.12 (els with training data that is very similar to the testing data, or to increase the robustness of their) 72 144.67 P
(systems by using normalization algorithms.) 72 122.67 T
FMENDPAGE
%%EndPage: "8" 10
%%Page: "9" 10
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 2: The SPHINX-II System) 72 749.33 T
(9) 534.44 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
0 14 Q
0 X
(2.2.1) 72 710.67 T
(Recognition Unit) 110.9 710.67 T
1 11 Q
-0.29 (SPHINX II models phone-level acoustic phenomena. It uses a phone set of 50 Context In-) 108 686.67 P
2.16 (dependent \050CI\051 phones along with additional phones for noise and silence segments. Since) 72 664.67 P
-0.17 (SPHINX II was designed to recognize continuous speech, it is necessary to model co-articulation) 72 642.67 P
1.12 (of phones in dif) 72 620.67 P
1.12 (ferent contexts. Hence instead of only modelling phones in isolation, it models) 149.68 620.67 P
-0.17 (phones in their left and right context. This modelling unit is called a triphone. Since the number of) 72 598.67 P
-0.11 (possible triphones can potentially exceed the number of triphones that a training corpus can suit-) 72 576.67 P
0.63 (ably train, SPHINX II allows for the sharing of acoustic states between triphones that share the) 72 554.67 P
(same central phone. The shared acoustic state is known as a senone [9].) 72 528 T
-0.02 (Each triphone in the system is modelled as a 5 state left to right Bakis HMM [3] as shown) 108 288.58 P
-0.59 (in \336gure 1. The parameters that must be trained for this model are the transition probabilities \050with-) 72 266.58 P
-0.35 (in and between states\051, the output distributions, and the initial probabilities for the states. The out-) 72 244.58 P
-0.76 (put distributions are formed by a mixture of 4 Gaussian distributions. The parameters to be learned) 72 222.58 P
-0.39 (for the output distributions are the mixture weights and the tied means and variances. As SPHINX) 72 200.58 P
0.02 (II is a semi-continuous system the tying is across all states of all phones. However SPHINX II al-) 72 178.58 P
-0.27 (lows the tying to be within phone classes rather than among the entire phone set, which results in) 72 156.58 P
0.32 (a greater pool of distributions to form the output distributions from. This increases the resolution) 72 134.58 P
(of the models to the various acoustic events in a multi-speaker multi-environment task.) 72 112.58 T
72 72 540 720 C
78.34 306.91 533.66 522 C
7 X
0 K
90 450 18 18 150.34 422.01 G
0.5 H
0 Z
0 X
90 450 18 18 150.34 422.01 A
7 X
90 450 18 18 213.34 422.01 G
0 X
90 450 18 18 213.34 422.01 A
183.8 425.32 195.34 422.01 183.8 418.7 183.8 422.01 4 Y
V
168.34 422.01 183.8 422.01 2 L
7 X
V
2 Z
0 X
N
7 X
90 450 18 18 276.34 422.01 G
0 Z
0 X
90 450 18 18 276.34 422.01 A
246.8 425.32 258.34 422.01 246.8 418.7 246.8 422.01 4 Y
V
231.34 422.01 246.8 422.01 2 L
7 X
V
2 Z
0 X
N
7 X
90 450 18 18 339.34 422.01 G
0 Z
0 X
90 450 18 18 339.34 422.01 A
309.8 425.32 321.34 422.01 309.8 418.7 309.8 422.01 4 Y
V
294.34 422.01 309.8 422.01 2 L
7 X
V
2 Z
0 X
N
7 X
90 450 18 18 402.34 422.01 G
0 Z
0 X
90 450 18 18 402.34 422.01 A
372.8 425.32 384.34 422.01 372.8 418.7 372.8 422.01 4 Y
V
357.34 422.01 372.8 422.01 2 L
7 X
V
2 Z
0 X
N
480.8 425.32 492.34 422.01 480.8 418.7 480.8 422.01 4 Y
V
420.34 422.01 480.8 422.01 2 L
7 X
V
0 X
N
264.42 402.5 276.33 404.01 267.03 396.42 265.73 399.46 4 Y
V
150.34 404.01 M
 209.58 378.62 213.11 377.1 265.72 399.47 D
0 Z
N
327.42 402.5 339.33 404.01 330.03 396.42 328.73 399.46 4 Y
V
213.34 404.01 M
 272.58 378.62 276.11 377.1 328.72 399.47 D
N
390.42 402.5 402.33 404.01 393.03 396.42 391.73 399.46 4 Y
V
276.34 404.01 M
 335.58 378.62 339.11 377.1 391.72 399.47 D
N
480.42 411.52 492.33 413.01 483.02 405.44 481.72 408.48 4 Y
V
339.34 404.01 M
 398.67 378.58 426.08 385.08 481.7 408.49 D
N
410.74 448.57 402.33 440.01 404.92 451.73 407.83 450.15 4 Y
V
407.82 450.18 M
 410.61 461.21 408.79 476.01 402.34 476.01 D
 393.34 476.01 393.34 447.21 402.34 440.01 D
2 Z
N
347.74 448.57 339.33 440.01 341.93 451.72 344.84 450.15 4 Y
V
344.82 450.18 M
 347.61 461.21 345.79 476.01 339.34 476.01 D
 330.34 476.01 330.34 447.21 339.34 440.01 D
N
284.75 448.57 276.33 440.01 278.93 451.72 281.84 450.14 4 Y
V
281.82 450.18 M
 284.61 461.21 282.79 476.01 276.34 476.01 D
 267.34 476.01 267.34 447.21 276.34 440.01 D
N
221.75 448.57 213.33 440.01 215.93 451.72 218.84 450.14 4 Y
V
218.82 450.18 M
 221.61 461.21 219.79 476.01 213.34 476.01 D
 204.34 476.01 204.34 447.21 213.34 440.01 D
N
158.75 448.56 150.34 440.01 152.94 451.72 155.84 450.14 4 Y
V
155.82 450.18 M
 158.61 461.21 156.79 476.01 150.34 476.01 D
 141.34 476.01 141.34 447.21 150.34 440.01 D
N
1 18 Q
(0) 141.34 416.95 T
(1) 205.34 416.95 T
(2) 269.34 416.95 T
(3) 333.33 416.95 T
(4) 397.33 416.95 T
(a) 213.34 476.01 T
1 14 Q
(ij) 222.34 471.51 T
1 18 Q
(P\050X/S) 87.34 395.01 T
1 14 Q
(i) 134.33 390.51 T
1 18 Q
(\051) 137.43 395.01 T
1 11 Q
(Figure 1: The 5 state left to right Bakis model used to model a triphone in SPHINX II.) 91.69 335.08 T
72 72 540 720 C
0 0 612 792 C
FMENDPAGE
%%EndPage: "9" 11
%%Page: "10" 11
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 2: The SPHINX-II System) 72 749.33 T
(10) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
0 14 Q
0 X
(2.3) 72 710.67 T
(The SPHINX-II T) 99.23 710.67 T
(rainer) 204.2 710.67 T
1 11 Q
-0.49 (W) 108 686.67 P
-0.49 (e now describe the SPHINX II trainer) 118.17 686.67 P
-0.49 (. While we divide the system into individual subsec-) 294.17 686.67 P
-0.45 (tions for easier understanding, it should be remembered that information from each subsection in-) 72 664.67 P
(teracts at multiple levels.) 72 642.67 T
0 14 Q
(2.3.1) 72 612.67 T
(Acoustical Feature Extraction) 110.9 612.67 T
1 11 Q
-0.13 (SPHINX II works on speech that has been parametrized using Mel-scale Frequency Cep-) 108 588.67 P
-0.65 (stral Coef) 72 566.67 P
-0.65 (\336cients \050MFCCs\051 [8]. The cepstral coef) 118.17 566.67 P
-0.65 (\336cients are static features that carry the short time) 302.16 566.67 P
-0.11 (frequency information of the speech signal. Dynamic features are obtained by taking the \336rst and) 72 544.67 P
0.48 (second order dif) 72 522.67 P
0.48 (ferences of the cepstral coef) 151.54 522.67 P
0.48 (\336cients. The following are the steps followed in the) 291.28 522.67 P
(SPHINX II front end to obtain acoustic features for telephone bandwidth speech:) 72 500.67 T
(\245) 90 478.67 T
(Input speech is digitized at a sampling rate of 8 kHz) 99 478.67 T
(\245) 90 455.67 T
0.46 (A pre-emphasis \336lter is used to suppress the ef) 99 455.67 P
0.46 (fects of glottal pulses and radiation imped-) 331.46 455.67 P
(ance while enhancing the spectral properties of the vocal tract.) 99 442.67 T
(\245) 90 419.67 T
(A Hamming window of 25.6 ms duration is applied at the rate of 100 windows/sec) 99 419.67 T
(\245) 90 396.67 T
(The power spectrum of each windowed signal is computed using a 512-point DFT) 99 396.67 T
(\245) 90 373.67 T
0.47 (40 Mel Frequency Spectral Coef) 99 373.67 P
0.47 (\336cients are derived based on mel-frequency bandpass \336l-) 258.24 373.67 P
-0.02 (ters with 13 linear bands for 200 Hz to 1 kHz and 18 logarithmic bands for 1 kHz to 3.5 kHz) 99 360.67 P
(\245) 90 337.67 T
-0.23 (For each frame, 12 MFCCs are computed using the cosine transform of the logarithm of the) 99 337.67 P
(modi\336ed spectrum that was obtained from the above \336lter outputs) 99 324.67 T
(\245) 90 301.67 T
0.69 (The dynamic features are obtained by taking the \336rst- and second-order dif) 99 301.67 P
0.69 (ferences. Nor-) 469.71 301.67 P
-0.73 (malized cepstral power) 99 288.67 P
-0.73 (, dif) 209.27 288.67 P
-0.73 (ference power) 226.05 288.67 P
-0.73 (, and second-order dif) 294.33 288.67 P
-0.73 (ference power form the fourth) 398.81 288.67 P
(feature stream) 99 275.67 T
-0.33 (These streams are then individually clustered into 256 groups using a hierarchical cluster-) 108 252.67 P
-0.1 (ing algorithm [1) 72 230.67 P
-0.1 (1]. The data are then vector quantized [6] using these clusters. Diagonal variance) 146.09 230.67 P
(matrices are calculated for each cluster) 72 208.67 T
(.) 262.5 208.67 T
0 14 Q
(2.3.2) 72 178.67 T
(Lexical Feature Extraction) 110.9 178.67 T
1 11 Q
-0.05 (The basic lexical feature is the phone set that is to be used in the \336nal system. SPHINX II) 108 154.67 P
0.3 (is built around a phone set of 50 unique context-independent phones, 10 noise phones \050) 72 132.67 P
3 F
0.3 (e.g.) 503.68 132.67 P
1 F
0.3 ( lip-) 522 132.67 P
0.25 (smacks, exhale, inhale and other such extraneous acoustic phenomena\051, and 3 types of silence) 72 110.67 P
-0.06 (phones. The next level of acoustic information is the set of words to be recognized. These, along) 72 88.67 P
FMENDPAGE
%%EndPage: "10" 12
%%Page: "11" 12
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 2: The SPHINX-II System) 72 749.33 T
(1) 529.63 749.33 T
(1) 534.44 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
1 11 Q
0 X
-0.68 (with their pronunciations are de\336ned in the dictionary using the above phone set. SPHINX II allows) 72 712.67 P
(multiple pronunciations of the same word.) 72 690.67 T
0.03 (Once the phone set and the dictionary are ready) 108 668.67 P
0.03 (, a list of all possible triphones is created) 342.54 668.67 P
-0.07 (using the dictionary) 72 646.67 P
-0.07 (. If these triphones appear in the training set with a preset frequency) 165.69 646.67 P
-0.07 (, they will) 494.97 646.67 P
0.28 (be trained. The rest are classi\336ed as unseen triphones. All unseen \050untrained\051 triphones are de-) 72 624.67 P
-0.73 (coded using the senonic mapping table. Unseen triphones are modelled as a sequences of trained) 72 602.67 P
-0.29 (states derived from trained triphones. The mapping table consists of a list of all the trained states.) 72 580.67 P
0.02 (An initial mapping table is constructed using the triphone list and senonic decision trees from the) 72 558.67 P
(selected initial models.) 72 536.67 T
0 14 Q
(2.3.3) 72 506.67 T
(Context-Independent System T) 110.9 506.67 T
(raining) 316.15 506.67 T
1 11 Q
-0.26 (The acoustic data clusters serve as initial models for the training of semi-continuous mod-) 108 482.67 P
-0.24 (els. These models start from \337at output distributions, uniform initial states, and uniform state tran-) 72 460.67 P
1.13 (sition probabilities. This training requires the vector-quantized data, the transcriptions, and the) 72 438.67 P
-0.46 (segmentation information. Segmentation information is generated during forced recognition of the) 72 416.67 P
(training data. This procedure will be described in the next section.) 72 394.67 T
2.06 (Baum-W) 108 372.67 P
2.06 (elch training [4] results in Context-Independent Discrete HMMs \050CI-DHMMs\051.) 150.53 372.67 P
-0.67 (These models are not necessarily optimized. They are obtained to serve as initial models for semi-) 72 350.67 P
-0.26 (continuous training and as seeds for the initial discrete context-dependent models from which the) 72 328.67 P
(senonic clustering trees are based.) 72 306.67 T
0 14 Q
(2.3.4) 72 276.67 T
(Segmentation and Senonic Clustering) 110.9 276.67 T
1 11 Q
-0.25 (Segmentation involves forced recognition of the entire training corpus using existing mod-) 108 252.67 P
0.32 (els. The segmentation allows us to classify automatically the frames of training data into distinct) 72 230.67 P
0.43 (acoustic classes, which in our case are the CI phones and the triphones de\336ned in the triphone) 72 208.67 P
-0.23 (list. Since the transcriptions are available, it is assumed that the segmentation output will result in) 72 186.67 P
-0.03 (clean clusters for the models to be trained. However) 72 164.67 P
-0.03 (, phoneme-level segmentation of continuous) 324.56 164.67 P
0.47 (speech is not an easy task due to the high degree of co-articulation that blurs phoneme bound-) 72 142.67 P
(aries. Hence it is best to always use the best possible models for the segmentation task.) 72 120.67 T
0.03 (The clustering process also generates revised transcripts that include alternate pronunci-) 108 98.67 P
-0.4 (ations for words with multiple pronunciations in the dictionary) 72 76.67 P
-0.4 (. The transcriptions are used to com-) 363.5 76.67 P
FMENDPAGE
%%EndPage: "11" 13
%%Page: "12" 13
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 2: The SPHINX-II System) 72 749.33 T
(12) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
1 11 Q
0 X
0.05 (pile an accurate list of all the triphones that can be trained from the training corpus. The triphone) 72 712.67 P
-0.4 (list, the CI-DHMMs, and the classi\336ed training data are used to generate unclustered Context-De-) 72 690.67 P
(pendent DHMMs.) 72 668.67 T
0.75 (The next step is the creation of senonic clustering trees. A senone is the shared output) 108 646.67 P
0.16 (distribution associated with a cluster of similar states. The output distributions of the unclustered) 72 624.67 P
0.5 (CD-DHMMs are used to decide which states should be clustered together based on an entropy) 72 602.67 P
1.29 (measure. Senonic decision trees are generated using linguistic questions. Each leaf on these) 72 580.67 P
0.66 (trees is a senone that can be trained. This allows the modelling of unseen triphones that might) 72 558.67 P
(appear in test data.) 72 536.67 T
0 14 Q
(2.3.5) 72 506.67 T
(Context-Dependent System T) 110.9 506.67 T
(raining) 305.27 506.67 T
1 11 Q
0.91 (Context-dependent modelling is achieved by modelling phones in left and right context,) 108 482.67 P
0.14 (called triphones. Baum-W) 72 460.67 P
0.14 (elch training is performed using the CI-DHMMs and the variance infor-) 197.86 460.67 P
1.5 (mation as initial models. The resulting Context-Dependent \050CD\051 models are Semi-Continuous) 72 438.67 P
(\050SCHMMs\051 and speaker independent.) 72 416.67 T
0.59 (Further \336ne tuning to groups of speakers is possible by separating the training data into) 108 394.67 P
-0.02 (the desired groups and training individual models for each group. Usually this just involves sepa-) 72 372.67 P
-0.08 (rating the data into males and females for gender-dependent models. However further classi\336ca-) 72 350.67 P
0.13 (tions into \336ner sets of speaker types is possible. The only constraints are that more training data) 72 328.67 P
(and a more complex decoding scheme are needed.) 72 306.67 T
0 14 Q
(2.4) 72 270.67 T
(Decoder) 99.23 270.67 T
1 11 Q
0.72 (The SPHINX II decoder nominally performs 3 passes on test utterances [2]. In this task) 108 246.67 P
-0.2 (only the forward pass was used on the test utterances, as the backward pass did not improve the) 72 224.67 P
-0.5 (results in any appreciable way) 72 202.67 P
-0.5 (. The third pass involves a rescoring of the lattices generated based) 216.34 202.67 P
-0.23 (on acoustic and language models. This pass was not performed as no language model was used) 72 180.67 P
0.16 (in this task. The digit task did not require a language model because we assumed every word to) 72 158.67 P
(be equally likely) 72 136.67 T
(.) 148.73 136.67 T
0.42 (When working with dif) 108 114.67 P
0.42 (ferent sets of models \050such as male models and females models\051,) 215.89 114.67 P
-0.36 (the decoder generates a pre-selected number of the most likely transcription hypotheses for each) 72 92.67 P
FMENDPAGE
%%EndPage: "12" 14
%%Page: "13" 14
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 2: The SPHINX-II System) 72 749.33 T
(13) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
1 11 Q
0 X
0.14 (set of models. The most likely hypothesis from the combined set of hypotheses for the particular) 72 712.67 P
-0.36 (utterance is selected based on a reevaluation of the acoustic score. W) 72 690.67 P
-0.36 (orking with multiple models) 409.21 690.67 P
(obviously increases the run time, as multiple acoustic models have to be used for decoding.) 72 668.67 T
0 14 Q
(2.5) 72 632.67 T
(The T) 99.23 632.67 T
(raining Procedure) 135.78 632.67 T
1 11 Q
-0.26 (W) 108 608.67 P
-0.26 (e now provide a detailed description of the two training procedures, \322bootstrapped train-) 118.17 608.67 P
0.12 (ing\323 and \322data-driven training\323 that are evaluated in this work. The dif) 72 586.67 P
0.12 (ference between these pro-) 405.9 586.67 P
(cedures lies in the use of existing models to bootstrap the training procedure.) 72 564.67 T
0 14 Q
(2.5.1) 72 534.67 T
(Bootstrapped T) 110.9 534.67 T
(raining) 213.52 534.67 T
1 11 Q
0.06 (This procedure relies on existing models to bootstrap the training of a new set of models.) 108 510.67 P
0.63 (The models selected have been previously trained on the same data or data from a similar do-) 72 488.67 P
(main. Along with the models the corresponding senonic decision trees are also required.) 72 466.67 T
0 F
(2.5.1.1) 72 444.67 T
(Acoustic Feature Extraction) 111.71 444.67 T
1 F
-0.74 (The acoustic feature extraction procedure described above is followed to obtain cepstra for) 108 421.67 P
(the entire training database. The cepstral vectors obtained are vector quantized.) 72 399.67 T
0 F
(2.5.1.2) 72 377.67 T
(Lexical Feature Extraction) 111.71 377.67 T
1 F
-0.54 (The lexical feature extraction also proceeds as described above. The phone set is dictated) 108 354.67 P
0.26 (by the bootstrapping models being used. The senonic decision trees are used along with the tri-) 72 332.67 P
-0.6 (phone table for the training set to generate a mapping table for the training set. This mapping table) 72 310.67 P
(is required by the context-dependent bootstrapping models.) 72 288.67 T
0 F
(2.5.1.3) 72 266.67 T
(Segmentation) 111.71 266.67 T
1 F
-0.28 (Segmentation of the training set is carried out using the bootstrapping models, associated) 108 243.67 P
(mapping table, triphone list, and dictionary for the training set.) 72 221.67 T
0 F
(2.5.1.4) 72 199.67 T
(Creation of CI-DHMMs) 111.71 199.67 T
1 F
-0.1 (T) 108 176.67 P
-0.1 (raining vectors are classi\336ed into phones by the segmentation process. These classi\336ed) 114.31 176.67 P
0.33 (vectors are now used to train CI-DHMMs. The process usually uses existing discrete models as) 72 154.67 P
-0.35 (initial models, but models with uniform output distributions also can be used as initial models. The) 72 132.67 P
0.15 (CI-DHMMs, along with the variance information derived during VQ, serve as initial models in the) 72 110.67 P
FMENDPAGE
%%EndPage: "13" 15
%%Page: "14" 15
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 2: The SPHINX-II System) 72 749.33 T
(14) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
1 11 Q
0 X
0.41 (training of the CD-SCHMMs. They are also required in the senone clustering process which will) 72 712.67 P
(be described in the next section.) 72 690.67 T
0 F
(2.5.1.5) 72 668.67 T
(Creation of the Senonic Decision T) 111.71 668.67 T
(rees and Mapping T) 293.02 668.67 T
(able) 395.38 668.67 T
1 F
-0.46 (The CI-DHMMs along with the triphone list and the classi\336ed frames provide us with rough) 108 645.67 P
-0.24 (discrete estimates for the CD phones. The output distributions of these CD models are compared) 72 623.67 P
-0.33 (using an entropy measure and similar ones are clustered \050they share the output distributions\051 into) 72 601.67 P
-0.15 (senones. The senonic decision trees and a mapping table for the models being trained are creat-) 72 579.67 P
(ed.) 72 557.67 T
0 F
(2.5.1.6) 72 535.67 T
(Creation of CD-SCHMMs) 111.71 535.67 T
1 F
0.08 (Using the CI-DHMMs as initial models, and the mapping table containing senone cluster-) 108 512.67 P
2.33 (ing information, the CD-SCHMMs are trained using the Baum-W) 72 490.67 P
2.33 (elch algorithm. As the CD-) 402.45 490.67 P
-0.34 (SCHMMs are the \336nal models that will be used for the recognition process, care is taken to insure) 72 468.67 P
-0.03 (that they are optimally trained. This is usually done by ensuring that the output probabilities keep) 72 446.67 P
-0.31 (increasing and by monitoring their performance on a development set \050to ensure that they are not) 72 424.67 P
(over trained\051.) 72 402.67 T
0 F
(2.5.1.7) 72 380.67 T
(Fine T) 111.71 380.67 T
(uning the CD-SCHMMs) 143.25 380.67 T
1 F
-0.17 (Further improvement in performance of the models is obtained by focusing the models on) 108 357.67 P
-0.13 (speci\336c classes of speakers. This allows the models to be sharper) 72 335.67 P
-0.13 (, as they can be used to model) 391.27 335.67 P
0.22 (distinct subsets of speakers rather than the entire set. This technique is very useful in improving) 72 313.67 P
0.72 (the performance of speaker-independent systems as it provides us with a way to approach the) 72 291.67 P
-0.4 (performance of a speaker-dependent system in the limit. A common classi\336cation of the speakers) 72 269.67 P
(is based on the gender \050or pitch information\051 of the training speakers.) 72 247.67 T
-0.37 (However it should be noted that training gender-dependent models increases the demand) 108 225.67 P
0.44 (on training data as we are splitting the training data into two sets. The existing training data are) 72 203.67 P
-0.07 (now used to estimate twice the number of parameters. Another drawback with multiple models is) 72 181.67 P
-0.33 (that a speci\336c set of models must be selected for testing at run time. A computationally expensive) 72 159.67 P
0.05 (solution is to run the test utterances on all the \336nal models and select) 72 137.67 P
3 F
0.05 (a posteriori) 411.62 137.67 P
1 F
0.05 ( the hypothesis) 466.01 137.67 P
(with the best score.) 72 115.67 T
FMENDPAGE
%%EndPage: "14" 16
%%Page: "15" 16
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 2: The SPHINX-II System) 72 749.33 T
(15) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
0 14 Q
0 X
(2.5.2) 72 710.67 T
(T) 110.9 710.67 T
(raining from Scratch) 118.68 710.67 T
1 11 Q
-0.4 (This method dif) 108 686.67 P
-0.4 (fers from bootstrapped training in that no existing models are used to boot-) 182.1 686.67 P
0.48 (strap the training procedure. This might be because of a lack of previous models for the task at) 72 664.67 P
0.51 (hand or similar tasks. The number of parameters that needs to be estimated increases with the) 72 642.67 P
-0.33 (size of the task. Without existing models to provide good initial estimates for large tasks,) 72 620.67 P
-0.33 ( this pro-) 497.92 620.67 P
(cedure becomes computationaly expensive and can result in suboptimal models.) 72 598.67 T
0 F
(2.5.2.1) 72 576.67 T
(Acoustic Feature Extraction) 111.71 576.67 T
1 F
(The acoustic feature extraction is carried out as described above.) 108 553.67 T
0 F
(2.5.2.2) 72 531.67 T
(Lexical Feature Extraction) 111.71 531.67 T
1 F
-0.25 (The lexical feature extraction is also as described above but with one dif) 108 508.67 P
-0.25 (ference. Because) 454.75 508.67 P
-0.72 (no bootstrapping models are used, a mapping table for the training data cannot be generated. This) 72 486.67 P
-0.32 (does not pose a problem as we shall show that an initial mapping table is not required when mod-) 72 464.67 P
(els are being trained from scratch.) 72 442.67 T
0 F
(2.5.2.3) 72 420.67 T
(Creation of CI-SCHMMs) 111.71 420.67 T
1 F
0.04 (Dif) 108 397.67 P
0.04 (ferences in the two procedures emerge with the creation of the CI-SCHMMs. For each) 121.23 397.67 P
0.72 (of the phonemes that must be trained, uniform HMMs with \337at output distributions and equally-) 72 375.67 P
-0.7 (likely transition probabilities are constructed. Using the transcriptions, maximum likelihood training) 72 353.67 P
-0.71 (is used to train the CI-DHMMs. The dif) 72 331.67 P
-0.71 (ference between the bootstrapped process and this process) 253.67 331.67 P
-0.55 (is that these models are trained using the transcriptions in a maximum likelihood framework rather) 72 309.67 P
1.19 (than using preclassi\336ed training vectors. The estimated means and variances for the clusters,) 72 287.67 P
-0.62 (along with the previously-trained DHMMs, are used for further Baum-W) 72 265.67 P
-0.62 (elch iterations to obtain CI-) 411.8 265.67 P
-0.29 (SCHMMs. Care must be taken that the models are optimally trained as these models will be used) 72 243.67 P
(to create the context-dependent models.) 72 221.67 T
0 F
(2.5.2.4) 72 199.67 T
(Segmentation and the Creation of Senonic Decision T) 111.71 199.67 T
(rees and Mapping T) 391.31 199.67 T
(able) 493.67 199.67 T
1 F
-0.2 (The segmentation and the creation of the senonic decision trees and the mapping table is) 108 176.67 P
1.05 (carried on as before, but using the CI-SCHMMs for segmentation rather than existing models.) 72 154.67 P
0.3 (Since CI models do not require parameter sharing, and there are no unseen acoustic classes in) 72 132.67 P
(the training data, no initial mapping table is required.) 72 110.67 T
FMENDPAGE
%%EndPage: "15" 17
%%Page: "16" 17
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 2: The SPHINX-II System) 72 749.33 T
(16) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
0 11 Q
0 X
(2.5.2.5) 72 712.67 T
(Creation of CD-SCHMMs) 111.71 712.67 T
1 F
0.38 (Once the senonic trees and mapping table are available, Baum-W) 108 689.67 P
0.38 (elch training proceeds) 431.78 689.67 P
-0.25 (with the CI-SCHMMs used as initial models. In larger tasks, as we have noted, the eventual mod-) 72 667.67 P
0.55 (els are sometimes sub-optimal. In this case the models are used to resegment the data so that) 72 645.67 P
-0.06 (the senones can be reclustered and the models are further iterated with this new clustering infor-) 72 623.67 P
-0.1 (mation. This process is continued until the models achieve optimal performance or an) 72 601.67 P
3 F
-0.1 (ad hoc) 488.92 601.67 P
1 F
-0.1 (cri-) 524.75 601.67 P
(teria to stop the process is reached.) 72 579.67 T
0 F
(2.5.2.6) 72 557.67 T
(Fine T) 111.71 557.67 T
(uning the CD-SCHMMs) 143.25 557.67 T
1 F
0.89 (The training set can be clustered into speaker clusters using the same procedure as in) 108 534.67 P
(bootstrapped training, once the generic CD-SCHMMs have been created.) 72 512.67 T
0 14 Q
(2.6) 72 476.67 T
(Summary) 99.23 476.67 T
1 11 Q
0.38 (W) 108 452.67 P
0.38 (e have provided a brief overview of the SPHINX II system. The two training procedure) 118.17 452.67 P
0.07 (we describe are the training procedures compared in this work. The two procedures dif) 72 430.67 P
0.07 (fer on the) 493.44 430.67 P
-0.02 (technique used to initialize the training data. The optimum way to initialize training data would be) 72 408.67 P
2.04 (by hand segmenting and labelling all the training utterances into the acoustic classes being) 72 386.67 P
0.06 (trained. This is too expensive given the amount of training data used to generate models. Hence) 72 364.67 P
(we attempt to use automatic procedures to initialize the training data.) 72 342.67 T
0.8 (In bootstrapped training, existing models are used to initialize the training data. It is the) 108 320.67 P
-0.43 (usual procedure used to train models on the SPHINX II system. This method presupposes the ex-) 72 298.67 P
-0.2 (istence of models that are from a domain close to the domain for which models are being trained.) 72 276.67 P
1.08 (This ensures that the training data will be initialized without the errors caused by domain mis-) 72 254.67 P
(matches.) 72 232.67 T
-0.3 (T) 108 210.67 P
-0.3 (raining from scratch is usually carried out when existing models are not suitable to initial-) 114.31 210.67 P
-0.47 (ize the given training data. This usually occurs when the new task is signi\336cantly dif) 72 188.67 P
-0.47 (ferent from the) 469.49 188.67 P
(tasks for which models had been created.) 72 166.67 T
FMENDPAGE
%%EndPage: "16" 18
%%Page: "17" 18
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 3: Speech Corpora) 72 749.33 T
(17) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
0 18 Q
0 X
(Chapter 3) 264.52 708 T
(Speech Corpora) 236.52 674 T
1 11 Q
0.37 (This body of work was performed on two corpora of connected digits that were collected) 108 636.67 P
-0.36 (on long distance telephone lines. This chapter describes the similarities and the dif) 72 614.67 P
-0.36 (ferences of the) 468.05 614.67 P
0.7 (two databases. Their individual characteristics have led to dif) 72 592.67 P
0.7 (ferences in the training processes) 372.94 592.67 P
(employed to obtain models.) 72 570.67 T
0.43 (Existing speech corpora were also used for comparison experiments and to initialize the) 108 548.67 P
0.72 (training of the digit recognition systems. These speech databases and their features that make) 72 526.67 P
(them useful to this body of work are also described.) 72 504.67 T
0 14 Q
(3.1) 72 468.67 T
(MALL Databases) 99.23 468.67 T
1 11 Q
0.63 (The two major databases used in this work are known as the MALL88 and the MALL91) 108 444.67 P
0.44 (corpora. These data were provided by A) 72 422.67 P
0.44 (T&T Bell Labs. MALL88 was collected in the year 1988) 269.21 422.67 P
-0.68 (while MALL91 was collected three years later) 72 400.67 P
-0.68 (. In each case data were collected over long distance) 287.76 400.67 P
-0.67 (telephone lines from two sites, Long Island and Boston. Within a given year of data collection, data) 72 378.67 P
-0.24 (from the two sites are similar enough to be combined for training and testing. The speech was re-) 72 356.67 P
-0.55 (corded on electret and carbon button microphones, and training and a test set were collected from) 72 334.67 P
0.35 (each site. As the corpora were collected at dif) 72 312.67 P
0.35 (ferent times, the recording equipment used dif) 296.28 312.67 P
0.35 (fers) 521.68 312.67 P
-0.13 (in the two cases. This dif) 72 290.67 P
-0.13 (ference contributes to dif) 191.45 290.67 P
-0.13 (ferences in performance between the two data-) 311.17 290.67 P
(bases.) 72 268.67 T
0.58 (The MALL88 and MALL91 data consist of utterances of connected digits from male and) 108 246.67 P
2.35 (female speakers. The corpora are hence ideally suited for speaker independent continuous) 72 224.67 P
-0.32 (speech systems. The vocabulary is limited to the ten digits with \3240\325 being uttered either as \322ZERO\323) 72 202.67 P
0.02 (or as \322OH\323, resulting in a total vocabulary of eleven words. The utterances are of variable length.) 72 180.67 P
0.38 (Even though within a corpus the maximum utterance length \050in number of words\051 can be ascer-) 72 158.67 P
(tained from the training set, such information was not used in this work.) 72 136.67 T
FMENDPAGE
%%EndPage: "17" 19
%%Page: "18" 19
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 3: Speech Corpora) 72 749.33 T
(18) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
1 11 Q
0 X
0.55 (As the speaker is equally likely to speak any digit no language model was provided and) 108 712.67 P
0.63 (none was used. Each word in the vocabulary is assumed to be equiprobable. This allows us to) 72 690.67 P
(concentrate purely on the problem of acoustic modelling.) 72 668.67 T
-0.03 (T) 108 410.67 P
-0.03 (able 1 shows the distributions of utterances across recording sites, speaker gender) 113.49 410.67 P
-0.03 (, and) 515.59 410.67 P
1.15 (training-set vs. testing-set size, for the two MALL databases. The MALL88 data is sampled at) 72 388.67 P
0.33 (8kHz and stored in PCM linear format wav \336les. W) 72 366.67 P
0.33 (e see in the above table that this database is) 319.6 366.67 P
0.63 (female heavy as no male speech was recorded at the Boston site. Each speaker recorded 124) 72 344.67 P
0.34 (utterances, most of which are included in the corpus. A few were left out due to errors in the re-) 72 322.67 P
-0.75 (cording process. The utterance length ranges from a single digit to 7 digits. In contrast the MALL91) 72 300.67 P
0.36 (utterances are longer) 72 278.67 P
0.36 (, ranging from 14 to 16 digits with some 10 digit utterances. The longer ut-) 175.92 278.67 P
-0.51 (terances have the additional characteristic of being spoken faster and hence there is a greater de-) 72 256.67 P
0.06 (gree of co-articulation in this database. Each speaker recorded 12 utterances, most of which are) 72 234.67 P
0.59 (included in the corpus. A few were left out due to errors in the recording process. The MALL91) 72 212.67 P
-0.17 (data are also sampled at 8 kHz but mu-law encoded. The mu-law speech samples were coded in) 72 190.67 P
(gray code and stored in .wav \336les. Programs to decode the speech were provided by Bell Labs.) 72 168.67 T
0 14 Q
(3.2) 72 132.67 T
(Other Databases) 99.23 132.67 T
1 11 Q
-0.31 (The MALL databases are dif) 108 108.67 P
-0.31 (ferent from the ones usually used with the SPHINX) 244.56 108.67 P
4 F
-0.28 (II) 492.09 108.67 P
1 F
-0.31 ( system.) 499.41 108.67 P
-0.02 (T) 72 86.67 P
-0.02 (o measure the performance of SPHINX) 77.49 86.67 P
4 F
-0.02 (II) 271.54 86.67 P
1 F
-0.02 ( on the MALL data existing models were initially used.) 278.85 86.67 P
2 12 Q
(T) 214.83 615 T
(rain utt) 221.74 615 T
(T) 289.7 615 T
(est utt) 296.19 615 T
(M/F in T) 352.86 615 T
(r) 395.76 615 T
(. Set) 399.1 615 T
(M/F in T) 439.26 615 T
(r) 482.16 615 T
(. Set) 485.49 615 T
(MALL88) 101.76 591 T
(9039) 222 591 T
(4584) 294 591 T
(26/62) 366 591 T
(1) 456 591 T
(1/35) 461.55 591 T
(Long Island Set) 101.76 569 T
(5109) 222 569 T
(2083) 294 569 T
(26/24) 366 569 T
(1) 456 569 T
(1/10) 461.55 569 T
(Boston Set) 101.76 547 T
(3930) 222 547 T
(2501) 294 547 T
(0/38) 366 547 T
(0/25) 456 547 T
(MALL91) 101.76 525 T
(2585) 222 525 T
(2688) 294 525 T
(1) 357 525 T
(17/125) 362.55 525 T
(123/126) 447 525 T
(Long Island Set) 101.76 503 T
(1306) 222 503 T
(1331) 294 503 T
(61/60) 366 503 T
(59/66) 456 503 T
(Boston Set) 101.76 481 T
(1279) 222 481 T
(1357) 294 481 T
(56/65) 366 481 T
(64/60) 456 481 T
5 F
(T) 86.46 459 T
(able 1: Comparison of the MALL88 and MALL91 databases acr) 93.35 459 T
(oss the two sites, the) 422.62 459 T
(training and test sets and the speaker distributions.) 175.06 445 T
95.76 630 95.76 474 2 L
V
2 H
0 Z
N
199.44 632 199.44 472 2 L
V
0.5 H
N
271.44 632 271.44 472 2 L
V
N
343.44 632 343.44 472 2 L
V
N
429.84 632 429.84 472 2 L
V
N
516.24 630 516.24 474 2 L
V
2 H
N
94.76 631 517.24 631 2 L
V
N
94.76 605 517.24 605 2 L
V
N
94.76 583 517.24 583 2 L
V
0.5 H
N
94.76 561 517.24 561 2 L
V
N
94.76 539 517.24 539 2 L
V
N
94.76 517 517.24 517 2 L
V
N
94.76 495 517.24 495 2 L
V
N
94.76 473 517.24 473 2 L
V
2 H
N
FMENDPAGE
%%EndPage: "18" 20
%%Page: "19" 20
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 3: Speech Corpora) 72 749.33 T
(19) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
1 11 Q
0 X
-0.64 (These models had been trained on the data described below) 72 712.67 P
-0.64 (. Additionally models trained on these) 360.61 712.67 P
-0.37 (data were also used to initialize the training for the MALL databases. The following are some tele-) 72 690.67 P
(phone-bandwidth databases for which SPHINX) 72 668.67 T
4 F
(II) 304.04 668.67 T
1 F
( models have been created.) 311.36 668.67 T
0 14 Q
(3.2.1) 72 638.67 T
(Reduced Bandwidth AN4) 110.9 638.67 T
1 11 Q
-0.31 (AN4 [1] is a 106 word alphanumeric database. Its training set is composed of 74 speakers) 108 614.67 P
-0.06 (\05053 males and 21 females\051. There are about 14 utterances recorded by each speaker) 72 592.67 P
-0.06 (. It was col-) 484.62 592.67 P
-0.62 (lected over two channels in an of) 72 570.67 P
-0.62 (\336ce environment. The \322clean\323 channel was recorded using a Sen-) 228.07 570.67 P
-0.35 (nheiser HMD224 close talking microphone while the \322noisy\323 channel was recorded using a Crown) 72 548.67 P
(PZM6FS omnidirectional desk-top microphone.) 72 526.67 T
-0.2 (Since this database was originally sampled at 16 kHz, it contains more acoustic data than) 108 504.67 P
0.89 (a telephone channel. In this version of the database the clean channel was downsampled and) 72 482.67 P
-0.64 (passed through a low-pass \336lter with a 3600-kHz cutof) 72 460.67 P
-0.64 (f frequency) 330.42 460.67 P
-0.64 (. This was done to limit the band-) 383.31 460.67 P
(width to that of telephone speech.) 72 438.67 T
0 14 Q
(3.2.2) 72 408.67 T
(Filtered WSJ0+WSJ1) 110.9 408.67 T
1 11 Q
-0.34 (The Filtered WSJ0+WSJ1 [12] database was created for the 1994 ARP) 108 384.67 P
-0.34 (A Evaluation Hub2) 449.7 384.67 P
-0.13 (evaluation. This evaluation was aimed at measuring the recognition performance in an unlimited-) 72 362.67 P
0.27 (vocabulary speech recognition task where the speech was recorded on long distance telephone) 72 340.67 P
0.41 (networks. The database was created by passing WSJ0 and WSJ1 clean speech through a \336lter) 72 318.67 P
0.01 (with a frequency response that was designed to resemble that of an average telephone channel.) 72 296.67 P
(The power spectrum of the average telephone channel used is shown in Fig. 1, [12].) 72 274.67 T
-0.37 (The W) 108 120.67 P
-0.37 (all Street Journal \050WSJ\051 [13] databases were collected to enable research in gener-) 139.58 120.67 P
0.91 (al-purpose, large English vocabulary and high perplexity speech recognition tasks. These data) 72 98.67 P
(were collected from 1987 to 1993.) 72 76.67 T
FMENDPAGE
%%EndPage: "19" 21
%%Page: "20" 21
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 3: Speech Corpora) 72 749.33 T
(20) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
0 14 Q
0 X
(3.2.3) 72 434.24 T
(Macrophone) 110.9 434.24 T
1 11 Q
-0.64 (Macrophone is a large telephone speech database \050200,000 utterances recorded by about) 108 410.24 P
0.35 (5000 American speakers\051 that was sponsored by the Linguistic Data Consortium \050LDC\051 [5]. The) 72 388.24 P
-0.02 (utterance were collected in 8-bit mu-law format directly from a T1 line. It contains varied styles of) 72 366.24 P
1.8 (speech data \050digits, alphabets, dates, places, single word commands and longer utterances\051) 72 344.24 P
(adaptable to dif) 72 322.24 T
(ferent tasks.) 146.93 322.24 T
0 14 Q
(3.3) 72 286.24 T
(Summary) 99.23 286.24 T
1 11 Q
0.08 (W) 108 262.24 P
0.08 (e have provided descriptions of the various databases that were used in this work. The) 118.17 262.24 P
0.19 (AN4, Filtered WSJ0+WSJ1 and the MACROPHONE databases were only used in the initial part) 72 240.24 P
(of this work. Most of the development work solely depended on the MALL databases.) 72 218.24 T
72 72 540 720 C
104 471.57 508 720 C
0 -5 566 387 757 392 191 110 523 FMBEGINEPSF
%%BeginDocument: <inline>
%!PS-Adobe-2.0 EPSF-2.0
%%Title: channels.diagram  -  /usr0/pjm/reports/darpaH2+S595
%%Creator: Diagram
%%CreationDate: Tue Jan 17 21:06:53 1995
%%For: root
%%DocumentFonts: (atend)
%%Pages: 0 0
%%BoundingBox: -5 566 387 757
%%NXNextStepVersion: 3.0
%%EndComments

%%BeginProcSet: /usr/lib/NextStep/printPackage.ps 3.0
%!
% NeXT Printing Package
% Version: 3.0
% Copyright: 1988, NeXT, Inc.

/__NXdef{1 index where{pop pop pop}{def}ifelse}bind def
/__NXbdef{1 index where{pop pop pop}{bind def}ifelse}bind def
/UserObjects 10 array __NXdef
/defineuserobject{
	exch dup 1 add dup UserObjects length gt{
		array dup 0 UserObjects putinterval
		/UserObjects exch def
	}{pop}ifelse UserObjects exch 3 -1 roll put
}__NXbdef
/undefineuserobject{UserObjects exch null put}__NXbdef
/execuserobject{UserObjects exch get exec}__NXbdef
/__NXRectPath{4 2 roll moveto 1 index 0 rlineto
0 exch rlineto neg 0 rlineto closepath}__NXbdef
/__NXProcessRectArgs{
	1 index type /arraytype eq{
		exch 0 4 2 index length 1 sub{
			dup 3 add 1 exch{1 index exch get exch}for
			5 1 roll 5 index exec
		}for pop pop
	}{exec}ifelse
}__NXbdef
/rectfill{gsave newpath {__NXRectPath fill} __NXProcessRectArgs grestore}__NXbdef
/rectclip{newpath {__NXRectPath} __NXProcessRectArgs clip newpath}__NXbdef
/rectstroke{
	gsave newpath dup type /arraytype eq{dup length 6 eq}{false}ifelse{
		{gsave __NXRectPath null concat stroke grestore}
		dup length array cvx copy dup 2 4 -1 roll put __NXProcessRectArgs
	}{{__NXRectPath stroke} __NXProcessRectArgs}ifelse grestore
}__NXbdef
/_NXLevel2 systemdict /languagelevel known {languagelevel 2 ge}{false}ifelse __NXdef
/xyshow{
	0 1 3 index length 1 sub{
		currentpoint 4 index 3 index 1 getinterval show
		3 index 3 index 2 mul 1 add get add exch
		3 index	3 index 2 mul get add exch moveto pop
	}for pop pop
}__NXbdef
/xshow{
	0 1 3 index length 1 sub{
		currentpoint 4 index 3 index 1 getinterval show
		exch 3 index 3 index get add exch moveto pop
	}for pop pop
}__NXbdef
/yshow{
	0 1 3 index length 1 sub{
		currentpoint 4 index 3 index 1 getinterval show
		3 index 3 index get add moveto pop
	}for pop pop
}__NXbdef
/arct{arcto pop pop pop pop}__NXbdef
/setbbox{pop pop pop pop}__NXbdef
/ucache{}__NXbdef
/ucachestatus{mark 0 0 0 0 0}__NXbdef
/setucacheparams{cleartomark}__NXbdef
/uappend{systemdict begin cvx exec end}__NXbdef
/ueofill{gsave newpath uappend eofill grestore}__NXbdef
/ufill{gsave newpath uappend fill grestore}__NXbdef
/ustroke{
	gsave newpath dup length 6 eq
	{exch uappend concat}{uappend}ifelse
	stroke grestore
}__NXbdef
/__NXustrokepathMatrix dup where {pop pop}{matrix def}ifelse
/ustrokepath{
	newpath dup length 6 eq{
		exch uappend __NXustrokepathMatrix currentmatrix exch concat
		strokepath setmatrix
	}{uappend strokepath}ifelse
} __NXbdef
/upath{
	[exch {/ucache cvx}if pathbbox /setbbox cvx
	 {/moveto cvx}{/lineto cvx}{/curveto cvx}{/closepath cvx}pathforall]cvx
} __NXbdef
/setstrokeadjust{pop}__NXbdef
/currentstrokeadjust{false}__NXbdef
/selectfont{exch findfont exch
dup type /arraytype eq {makefont}{scalefont}ifelse setfont}__NXbdef
/_NXCombineArrays{
	counttomark dup 2 add index dup length 3 -1 roll {
		2 index length sub dup 4 1 roll 1 index exch 4 -1 roll putinterval exch
	}repeat pop pop pop
}__NXbdef
/flushgraphics{}def
/setwindowtype{pop pop}def
/currentwindowtype{pop 0}def
/setalpha{pop}def
/currentalpha{1.0}def
/hidecursor{}def
/obscurecursor{}def
/revealcursor{}def
/setcursor{4 {pop}repeat}bind def
/showcursor{}def
/NextStepEncoding where not{
/NextStepEncoding StandardEncoding 256 array copy def
0 [129/Agrave/Aacute/Acircumflex/Atilde/Adieresis/Aring/Ccedilla/Egrave
/Eacute/Ecircumflex/Edieresis/Igrave/Iacute/Icircumflex/Idieresis
/Eth/Ntilde/Ograve/Oacute/Ocircumflex/Otilde/Odieresis/Ugrave/Uacute
/Ucircumflex/Udieresis/Yacute/Thorn/mu/multiply/divide/copyright
176/registered 181/brokenbar 190/logicalnot 192/onesuperior 201/twosuperior
204/threesuperior 209/plusminus/onequarter/onehalf/threequarters/agrave
/aacute/acircumflex/atilde/adieresis/aring/ccedilla/egrave/eacute
/ecircumflex/edieresis/igrave 226/iacute 228/icircumflex/idieresis/eth
/ntilde 236/ograve/oacute/ocircumflex/otilde/odieresis 242/ugrave/uacute
/ucircumflex 246/udieresis/yacute 252/thorn/ydieresis]
{dup type /nametype eq
 {NextStepEncoding 2 index 2 index put pop 1 add}{exch pop}ifelse
}forall pop
/NextStepEncoding NextStepEncoding readonly def
/_NXfstr 128 string dup 0 (_NX) putinterval def
/_NXfindfont /findfont load def
/findfont{
 % Because we can never let NextStepEncoding get into
 % SharedFontDirectory, we cannot reencode a font to NextStepEncoding
 % if we are in shared mode.  So if currentshared is true,
 % we call the normal findfont and return that
 /currentshared where {pop currentshared} {false} ifelse
 {_NXfindfont}
 {dup _NXfstr 3 125 getinterval cvs length 3 add _NXfstr 0 3 -1 roll
  getinterval cvn exch FontDirectory 2 index known 
  {pop FontDirectory exch get}
  {_NXfindfont dup /Encoding get StandardEncoding eq
   {	dup length dict exch
	{1 index /FID ne {2 index 3 1 roll put}{pop pop}ifelse}forall
	 dup /Encoding NextStepEncoding put definefont
	}{exch pop} ifelse
   }ifelse
 }ifelse
}bind def
}{pop}ifelse
/_NXImageString {/__NXImageString where{pop}{/__NXImageString 4000 string __NXdef}ifelse __NXImageString}__NXbdef
/_NXDoImageOp{
	3 dict begin /parr 5 array def 1 index{dup}{1}ifelse /chans exch def
	chans 2 add 2 roll parr 0 chans getinterval astore pop
	5 index 4 index mul 2 index{1 sub 8 idiv 1 add mul}{mul 1 sub 8 idiv 1 add}ifelse
	4 index mul /totbytes exch def pop exch pop
	gsave matrix invertmatrix concat 0.5 setgray 0 0 4 2 roll rectfill grestore
	{0 1 chans 1 sub{parr exch get exec length totbytes exch sub /totbytes exch def}for totbytes 0 le{exit}if}loop end
}__NXbdef
/alphaimage{1 add _NXDoImageOp}def
_NXLevel2{ 
	/NXCalibratedRGBColorSpace where{pop}{
		/NXCalibratedRGBColorSpace
		{mark /NXCalibratedRGB /ColorSpace findresource exch pop}stopped
		{cleartomark /NXCalibratedRGB[/CIEBasedABC 2 dict dup begin 
		/MatrixLMN[.4124 .2126 .0193 .3576 .7152 .1192 .1805 .0722 .9505]def
		/WhitePoint[.9505 1 1.089] def end] /ColorSpace defineresource}if def}ifelse
	/nxsetrgbcolor{NXCalibratedRGBColorSpace setcolorspace setcolor}__NXbdef
	/nxsetgray{dup dup nxsetrgbcolor}__NXbdef
	/_NXCalibratedImage{exch{array astore dup length true}{false}ifelse
		8 -1 roll{NXCalibratedRGBColorSpace setcolorspace}if
		8 dict dup 9 1 roll begin /ImageType 1 def /MultipleDataSources exch def
		currentcolorspace 0 get /Indexed eq{pop /Decode[0 2 6 index exp 1 sub]def}
		{2 mul dup array /Decode exch def 1 sub 0 1 3 -1 roll{Decode exch dup 2 mod put}for}ifelse
		/DataSource exch def /ImageMatrix exch def 
		/BitsPerComponent exch def /Height exch def /Width exch def end image}__NXbdef
} {
	/setcmykcolor{
		1.0 exch sub dup dup 6 -1 roll sub dup 0 lt{pop 0}if 5 1 roll
		4 -1 roll sub dup 0 lt{pop 0}if 3 1 roll exch sub dup 0 lt{pop 0}if setrgbcolor}__NXbdef
	/currentcmykcolor{currentrgbcolor 3{1.0 exch sub 3 1 roll}repeat 0}__NXbdef
	/colorimage{_NXDoImageOp}__NXbdef
	/nxsetrgbcolor{setrgbcolor}__NXbdef /nxsetgray{setgray}__NXbdef
	/setpattern{pop .5 setgray}__NXbdef
	/_NXCalibratedImage{dup 1 eq {pop pop image}{colorimage}ifelse pop}__NXbdef
} ifelse
/_NXSetCMYKOrRGB where{pop}{
	mark{systemdict /currentwindow get exec}stopped
	{{pop pop pop setcmykcolor}}{{nxsetrgbcolor pop pop pop pop}}ifelse /_NXSetCMYKOrRGB exch def cleartomark
}ifelse
%%EndProcSet

_NXLevel2{/_NXsethsb where{pop}{/_NXsethsb /sethsbcolor load def}ifelse /sethsbcolor{_NXsethsb currentrgbcolor nxsetrgbcolor}def /setrgbcolor{nxsetrgbcolor}bind def /setgray{nxsetgray}bind def
}if
gsave
-20 -28 translate
 /__NXbasematrix matrix currentmatrix def
grestore
%%EndProlog
%%BeginSetup
/DIAGRAMline {
    moveto rlineto stroke
} def /DIAGRAMarrow {
    [] 0 setdash newpath moveto dup rotate 0 currentlinewidth sub 1.2 mul 0 rmoveto -9 3 rlineto 2 -3 rlineto -2 -3 rlineto closepath gsave 0 setlinejoin stroke grestore fill neg rotate
} def /DIAGRAMpreparelines {
    /DIAGRAMlinetype exch def setlinewidth setrgbcolor 2 setlinejoin DIAGRAMlinetype 0 eq {
        [] 0 setdash
    } if DIAGRAMlinetype 1 eq {
        [ 5 currentlinewidth add dup ] 0 currentlinewidth add setdash
    } if DIAGRAMlinetype 2 eq {
        [ 0 currentlinewidth add 5 currentlinewidth add ] 0 currentlinewidth add setdash
    } if DIAGRAMlinetype 3 eq {
        [ 5 currentlinewidth add 4 currentlinewidth add 0 currentlinewidth add 4 currentlinewidth add ] 0 currentlinewidth add setdash
    } if
} def
%%EndSetup
gsave
-5 566.5 392 190 rectclip
gsave
0.000000 571.500000 transform
gsave __NXbasematrix setmatrix itransform translate
0 0 360 180 rectclip

/__NXEPSSave save def /showpage {} def
_NXLevel2{/_NXsethsb where{pop}{/_NXsethsb /sethsbcolor load def}ifelse /sethsbcolor{_NXsethsb currentrgbcolor nxsetrgbcolor}def /setrgbcolor{nxsetrgbcolor}bind def /setgray{nxsetgray}bind def
/_NXcimage where{pop}{/_NXcimage /colorimage load def}ifelse /colorimage{dup 3 eq{true 2 index{1 index}{1}ifelse 7 add 1 roll _NXCalibratedImage}{_NXcimage}ifelse}def}if
0 setgray 0 setlinecap 1 setlinewidth
0 setlinejoin 10 setmiterlimit [] 0 setdash newpath count /__NXEPSOpCount exch def /__NXEPSDictCount countdictstack def
%%BeginDocument: 
%!PS-Adobe-2.0 EPSF-1.2
%%DocumentFonts: (atend)
%%Creator: PLOT X1.0c
%%Pages: 0
%%BoundingBox: 0 0 360 180
%%EndComments
/MT {moveto} bind def
/LT {lineto} bind def
/sethsbcolor {setgray pop pop} bind def
/x2sqrt3 2 sqrt 3 mul def
%
% () x y o DoLText
%
%  Left justified text.
/DoLText {
    gsave
    3 1 roll
    translate
    rotate
    newpath
    0 0 moveto
    show
    grestore
} def
%
% () x y o DoRText
%
%  Right justified text.
/DoRText {
    gsave
    3 1 roll
    translate
    rotate
    dup stringwidth pop neg 0 translate
    newpath
    0 0 moveto
    show
    grestore
} def
%
% () x y o DoCText
%
%  Center justified text.
/DoCText {
    gsave
    3 1 roll
    translate
    rotate
    dup stringwidth pop 2 div neg 0 translate
    newpath
    0 0 moveto
    show
    grestore
} def
%
% Symbol Definitions
%
%
/SymbolStart {
    gsave
    [] 0 setdash
    3 1 roll
    translate
    dup dup scale
    1 exch div setlinewidth
    newpath
} def
/SBox {
    SymbolStart
    -3 -3 moveto
    3 -3 lineto
    3 3 lineto
    -3 3 lineto
    closepath
    stroke
    grestore
} def
/SBullet {
    SymbolStart
    0 0 3 0 360 arc fill
    grestore
} def
/SCircle {
    SymbolStart
    0 0 3 0 360 arc stroke
    grestore
} def
/SCross {
    SymbolStart
    -3 -3 moveto
    3 3 lineto stroke
    -3 3 moveto
    3 -3 lineto stroke
    grestore
} def
/SCustom {
    pop pop pop
} def
/SDel {
    SymbolStart
    x2sqrt3 2 moveto
    x2sqrt3 neg 2 lineto
    0 -4 lineto
    closepath stroke
    grestore
} def
/SPlus {
    SymbolStart
    -3 0 moveto
    3 0 lineto stroke
    0 -3 moveto
    0 3 lineto stroke
    grestore
} def
/SDiamond {
    SymbolStart
    45 rotate
    -3 -3 moveto
    3 -3 lineto
    3 3 lineto
    -3 3 lineto
    closepath
    stroke
    grestore
} def
/SEllipse {
    SymbolStart
    2 1 scale
    0 0 3 0 360 arc
    closepath
    stroke
    grestore
} def
/SNone {
    pop pop pop
} def
/SNumber {
    SymbolStart
    grestore
} def
/SSolidBox {
    SymbolStart
    -3 -3 moveto
    3 -3 lineto
    3 3 lineto
    -3 3 lineto
    closepath
    fill
    grestore
} def
/StarSide 6 36 cos div dup 36 sin mul sub 36 sin mul 36 cos div def
/SStar {
    SymbolStart
    0 3 translate
    -108 rotate
    0 0 moveto
    5 {
	StarSide 0 translate
	0 0 lineto
	-72 rotate
	StarSide 0 translate
	0 0 lineto
	144 rotate
    } repeat
    closepath
    stroke
    grestore
} def
/STriangle {
    SymbolStart
    x2sqrt3 -2 moveto
    x2sqrt3 neg -2 lineto
    0 4 lineto
    closepath stroke
    grestore
} def
%
% ci w h o x y bar
%
/bar {
    gsave
    translate
    rotate
%
    exch 2 div exch		% ci w/2 h
%
    newpath
    2 copy pop 0 moveto
    2 copy lineto
    2 copy exch neg exch lineto
    2 copy pop neg 0 lineto
    closepath stroke		% ci w/2 h
%
    3 -1 roll dup 0 ne {	% w/2 h ci
	3 copy pop moveto	% w/2 h ci
	3 copy add lineto
	3 copy add exch neg exch lineto
	3 copy pop exch neg exch lineto
	stroke
	3 copy pop moveto	% w/2 h ci
	3 copy sub lineto
	3 copy sub exch neg exch lineto
	3 copy pop exch neg exch lineto
	stroke
	currentlinewidth 2 mul setlinewidth
	pop 2 copy moveto
	exch neg exch lineto stroke
    } {pop pop pop } ifelse
%
    grestore
} def
%
% a linesfill
% 
/linesfill {
    gsave
    clip
    initmatrix
    MFactor MFactor scale
    0.5 setlinewidth
    rotate
    1 dict begin
    /ksp 1000 MFactor div def
    ksp neg 5 ksp {	% v
	newpath
	dup ksp exch moveto
	ksp neg exch lineto stroke
    } for
    end
    grestore
    newpath
} def
%
% a lines2fill
% 
/lines2fill {
    gsave
    clip
    initmatrix
    MFactor MFactor scale
    0.5 setlinewidth
    rotate
    1 dict begin
    /ksp 1000 MFactor div def
    ksp neg 8 ksp {	% v
	newpath
	dup ksp exch moveto
	dup ksp neg exch lineto stroke
	2 add
	dup ksp exch moveto
	ksp neg exch lineto stroke
    } for
    end
    grestore
    newpath
} def
%
% a lineswfill
% 
/lineswfill {
    gsave
    clip
    initmatrix
    MFactor MFactor scale
    0.5 setlinewidth
    rotate
    1 dict begin
    /ksp 1000 MFactor div def
    ksp neg 10 ksp {	% v
	newpath
	dup ksp exch moveto
	ksp neg exch lineto stroke
    } for
    end
    grestore
    newpath
} def
/crosshatch {
    dup gsave linesfill grestore
    90 add linesfill
} def
%
% ci w h o x y {pg2} {pg1} linefillbar
%
/fillbar {
    2 dict begin
    /pg1 exch def
    /pg2 exch def    
    6 copy			% save bar parameters
    gsave
    translate
    rotate
%
    exch 2 div exch		% ci w/2 h
    3 -1 roll			% w/2 h ci
%
    newpath
%
    3 copy pop pop neg 0 moveto
    3 copy sub exch neg exch lineto
    3 copy sub lineto
    3 copy pop pop 0 lineto
    closepath pg1
%
    3 copy sub exch neg exch moveto
    3 copy add exch neg exch lineto
    3 copy add lineto
    3 copy sub lineto
    closepath pg2
%
    grestore
    pop pop pop
    bar
    end
} def
%%EndProlog
save	% Start Page
save
0.0 0.0 translate
1.000000 1.000000 scale
/MFactor 1.000000 def
1.000000 setlinewidth
[] 0 setdash
1.000000 setlinewidth
[] 0 setdash
1.000000 setlinewidth
[] 0 setdash
newpath
53.0 42.2 MT
56.6 58.5 LT
60.2 74.8 LT
63.8 94.3 LT
67.4 115.5 LT
71.0 123.7 LT
74.6 130.2 LT
78.2 133.4 LT
81.8 136.7 LT
89.0 140.0 LT
96.2 138.3 LT
103.4 136.7 LT
110.6 130.2 LT
117.8 125.3 LT
125.0 122.0 LT
132.3 120.4 LT
139.5 118.8 LT
146.7 118.8 LT
153.9 117.1 LT
161.1 117.1 LT
168.3 117.1 LT
175.5 117.1 LT
189.9 113.9 LT
197.1 112.2 LT
204.4 110.6 LT
218.8 110.6 LT
233.2 109.0 LT
240.4 107.4 LT
247.6 105.7 LT
254.8 104.1 LT
262.0 102.5 LT
269.2 99.2 LT
276.5 97.6 LT
283.7 95.9 LT
290.9 92.7 LT
298.1 89.4 LT
305.3 86.2 LT
312.5 78.0 LT
319.7 71.5 LT
326.9 61.7 LT
334.1 55.2 LT
341.3 42.2 LT
stroke
1.000000 setlinewidth
[] 0 setdash
53.0 42.2 1.0000 SNone
56.6 58.5 1.0000 SNone
60.2 74.8 1.0000 SNone
63.8 94.3 1.0000 SNone
67.4 115.5 1.0000 SNone
71.0 123.7 1.0000 SNone
74.6 130.2 1.0000 SNone
78.2 133.4 1.0000 SNone
81.8 136.7 1.0000 SNone
89.0 140.0 1.0000 SNone
96.2 138.3 1.0000 SNone
103.4 136.7 1.0000 SNone
110.6 130.2 1.0000 SNone
117.8 125.3 1.0000 SNone
125.0 122.0 1.0000 SNone
132.3 120.4 1.0000 SNone
139.5 118.8 1.0000 SNone
146.7 118.8 1.0000 SNone
153.9 117.1 1.0000 SNone
161.1 117.1 1.0000 SNone
168.3 117.1 1.0000 SNone
175.5 117.1 1.0000 SNone
189.9 113.9 1.0000 SNone
197.1 112.2 1.0000 SNone
204.4 110.6 1.0000 SNone
218.8 110.6 1.0000 SNone
233.2 109.0 1.0000 SNone
240.4 107.4 1.0000 SNone
247.6 105.7 1.0000 SNone
254.8 104.1 1.0000 SNone
262.0 102.5 1.0000 SNone
269.2 99.2 1.0000 SNone
276.5 97.6 1.0000 SNone
283.7 95.9 1.0000 SNone
290.9 92.7 1.0000 SNone
298.1 89.4 1.0000 SNone
305.3 86.2 1.0000 SNone
312.5 78.0 1.0000 SNone
319.7 71.5 1.0000 SNone
326.9 61.7 1.0000 SNone
334.1 55.2 1.0000 SNone
341.3 42.2 1.0000 SNone
53.0 25.9 MT
341.4 25.9 LT
stroke
125.1 25.9 MT
125.1 29.5 LT
stroke
197.2 25.9 MT
197.2 29.5 LT
stroke
269.3 25.9 MT
269.3 29.5 LT
stroke
341.4 25.9 MT
341.4 29.5 LT
stroke
/Helvetica-BoldOblique findfont 12 scalefont setfont
(1000.0) 106.8 10.3 0 DoLText
(2000.0) 178.9 10.3 0 DoLText
(3000.0) 251.0 10.3 0 DoLText
(4000.0) 323.1 10.3 0 DoLText
53.0 9.6 MT
53.0 172.6 LT
stroke
53.0 9.6 MT
56.6 9.6 LT
stroke
53.0 42.2 MT
56.6 42.2 LT
stroke
53.0 74.8 MT
56.6 74.8 LT
stroke
53.0 107.4 MT
56.6 107.4 LT
stroke
53.0 140.0 MT
56.6 140.0 LT
stroke
53.0 172.6 MT
56.6 172.6 LT
stroke
/Helvetica-BoldOblique findfont 14 scalefont setfont
(Response \(dB\)) 14.0 74.0 90 DoLText
(-40.0) 17.6 2.6 0 DoLText
(-30.0) 17.6 35.2 0 DoLText
(-20.0) 17.6 67.8 0 DoLText
(-10.0) 17.6 100.4 0 DoLText
(0.0) 30.0 133.0 0 DoLText
(10.0) 22.3 165.6 0 DoLText
/Helvetica-BoldOblique findfont 12 scalefont setfont
(0.0) 56.6 10.3 0 DoLText
restore
%%Trailer
restore
%%DocumentFonts: Helvetica-BoldOblique

%%EndDocument
count __NXEPSOpCount sub {pop} repeat countdictstack __NXEPSDictCount sub {end} repeat __NXEPSSave restore
grestore
0 0 0 0 0 DIAGRAMpreparelines
gsave
/Helvetica-BoldOblique findfont 14 scalefont [1 0 0 -1 0 0] makefont
168
exch
defineuserobject
168 execuserobject setfont
0 nxsetgray
[1 0 0 -1 0 1201.482178] concat
168 execuserobject setfont
0 nxsetgray
356.483734 602.241089 moveto (Hz) show
grestore
grestore
gsave
0 0 576 756 rectclip
[1 0 0 -1 0 756] concat
grestore
grestore
%%Trailer
%%DocumentFonts: Helvetica-BoldOblique

%%EndDocument
FMENDEPSF
0 11 Q
0 X
0 K
(Figure 1: Equalization \336lter applied to WSJ0 and WSJ1 utterances to) 117.36 506.38 T
(approximate the power spectrum of telephone speech.) 117.36 495.38 T
72 72 540 720 C
0 0 612 792 C
FMENDPAGE
%%EndPage: "20" 22
%%Page: "21" 22
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 4: Performance of Existing Systems) 72 749.33 T
(21) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
0 18 Q
0 X
(Chapter 4) 264.52 708 T
(Performance of Existing Systems) 163.03 674 T
1 11 Q
-0.43 (Small vocabulary continuous speech recognition on the telephone network is a task signif-) 108 638.67 P
-0.21 (icantly dif) 72 616.67 P
-0.21 (ferent from the large vocabulary tasks for which the SPHINX II system is normally used.) 117.38 616.67 P
0.98 (Hence to calibrate our performance the MALL88 database was tested on some of the existing) 72 594.67 P
(models and decoding systems at our disposal.) 72 572.67 T
0.34 (W) 108 550.67 P
0.34 (e test models trained on bandlimited speech, speech passed through an average tele-) 118.17 550.67 P
1.19 (phone channel and real telephone speech. The improvement in performance observed as the) 72 528.67 P
1.3 (models approach the test set across the dimension of degradation caused by channel ef) 72 506.67 P
1.3 (fects) 516.8 506.67 P
-0.18 (show how the system depends on the acoustic dif) 72 484.67 P
-0.18 (ferences between the training and the test data) 312.21 484.67 P
(being a minimum.) 72 462.67 T
0 14 Q
(4.1) 72 426.67 T
(Reduced Bandwidth AN4) 99.23 426.67 T
1 11 Q
-0.12 (Models trained on the downsampled and lowpass \336ltered version of the AN4 database [1]) 108 402.67 P
1.41 (were used. While the models were trained on speech with the same bandwidth as telephone) 72 380.67 P
-0.17 (speech, the training speech lacks other degradations found in telephone speech, such as attenu-) 72 358.67 P
0.05 (ation of higher frequencies and noise in the telephone channel. This is a source of mismatch be-) 72 336.67 P
-0.07 (tween the Reduced Bandwidth AN4 and the MALL88 data. Because the MALL88 vocabulary is a) 72 314.67 P
0.75 (subset of the AN4 task, the test was \336rst run using the AN4 dictionary) 72 292.67 P
0.75 (. The mismatch between) 418.06 292.67 P
-0.51 (models and test data compounded with the larger dictionary caused a large number of recognition) 72 270.67 P
-0.19 (errors. The test set was then run with the subset of the AN4 dictionary that contained only the vo-) 72 248.67 P
-0.29 (cabulary of the MALL88 database. This time acoustic confusions involving words not in the MALL) 72 226.67 P
-0.35 (vocabulary did not occur and the results were a purer measure of the acoustic mismatch between) 72 204.67 P
(the models and the test environment.) 72 182.67 T
FMENDPAGE
%%EndPage: "21" 23
%%Page: "22" 23
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 4: Performance of Existing Systems) 72 749.33 T
(22) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
1 11 Q
0 X
-0.49 (W) 108 564.67 P
-0.49 (e see that removing extraneous words from the dictionary caused a relative drop in error) 118.17 564.67 P
-0.09 (rate of 47%. From this point on the digit dictionary was used in all recognition systems. T) 72 542.67 P
-0.09 (o further) 499.18 542.67 P
0.69 (improve performance, models that better model the degradations in the telephone environment) 72 520.67 P
(and that are more robust to them are required.) 72 498.67 T
0 14 Q
(4.2) 72 462.67 T
(Filtered WSJ 1PD models) 99.23 462.67 T
1 11 Q
0.02 (The \336ltered WSJ 1PD models were trained on the \336ltered WSJ0 and WSJ1databases, as) 108 438.67 P
1.85 (described above. The 1PD indicates that the output probability distributions are modelled by) 72 416.67 P
-0.4 (Gaussians that are derived from a single set of 256 Gaussian distributions. In this way the models) 72 394.67 P
(for all the phones are tied to one another) 72 372.67 T
(.) 269.27 372.67 T
-0.4 (The male models perform better than the female models. After perfect sex classi\336cation of) 108 110.67 P
0.71 (the test utterances \050using knowledge of the identity of the speaker\051, performance is better than) 72 88.67 P
2 12 Q
(Models used) 239.52 681 T
(WER) 418.67 681 T
(AN4 reduced band models and AN4 dictionary) 150 657 T
(34%) 420 657 T
(AN4 reduced band models and Digits dictionary) 150 635 T
(18%) 420 635 T
5 F
(T) 103.83 613 T
(able 2: Results with AN4 Reduced Band models. A comparison of the acoustic) 110.73 613 T
(confusability by the system dictionary size.) 196.73 599 T
2 F
(Filtered WSJ System) 160.32 305 T
-0.59 (WER on entire) 321.87 312 P
(test set) 341.35 298 T
(WER on part of) 414.74 319 T
-0.41 (test set matched to) 408.41 305 P
(models used) 423.06 291 T
(Perfect sex classi\336cation of test utt.) 113.28 267 T
(\050male and female models used\051) 113.28 253 T
(12.9) 347.64 267 T
(Male models only) 113.28 231 T
(14.5) 347.64 231 T
(7.2) 437.28 231 T
(Female models only) 113.28 209 T
(15.9) 347.64 209 T
(14.9) 437.28 209 T
5 F
-0.23 (T) 72 187 P
-0.23 (able 3: Performance of the \336lter) 78.9 187 P
-0.23 (ed WSJ sex-dependent models. Perfect classi\336cation of the) 241.05 187 P
(test utterances is compar) 95.58 173 T
(ed to running solely on either male or female models. The) 222.93 173 T
-0.15 (performance of the male models on male speech and female models on female speech is also) 72.66 159 P
(pr) 240.98 145 T
(ovided for comparison.) 252.76 145 T
144 696 144 627.25 2 L
V
2 H
0 Z
N
396 698 396 626.75 2 L
V
0.5 H
N
468 696 468 627.25 2 L
V
2 H
N
143 697 469 697 2 L
V
N
143 671 469 671 2 L
V
N
143 649 469 649 2 L
V
0.5 H
N
143 627 469 627 2 L
V
N
107.28 334 107.28 201.25 2 L
V
2 H
N
314.64 336 314.64 200.75 2 L
V
0.5 H
N
401.04 336 401.04 200.75 2 L
V
N
504.72 334 504.72 201.25 2 L
V
2 H
N
106.28 335 505.72 335 2 L
V
N
106.28 281 505.72 281 2 L
V
N
106.28 245 505.72 245 2 L
V
0.5 H
N
106.28 223 505.72 223 2 L
V
N
106.28 201 505.72 201 2 L
V
N
FMENDPAGE
%%EndPage: "22" 24
%%Page: "23" 24
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 4: Performance of Existing Systems) 72 749.33 T
(23) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
1 11 Q
0 X
-0.41 (using only male or only female models. This is because these models do not perform well in cross) 72 712.67 P
0.63 (conditions. The WER rate after perfect sex classi\336cation however has fallen another 28% com-) 72 690.67 P
-0.63 (pared to results obtained using the reduced bandwidth AN4 models. This improvement is primarily) 72 668.67 P
-0.02 (due to the fact that the \336lter used is a better model of the frequency response of telephone chan-) 72 646.67 P
0.77 (nels than the down-sampling used in the AN4 database. Furthermore, the \336ltered WSJ models) 72 624.67 P
(were better trained as a greater amount of continuous speech data was used.) 72 602.67 T
0 14 Q
(4.3) 72 566.67 T
(Macrophone models) 99.23 566.67 T
1 11 Q
-0.49 (The Macrophone [5] models, like the \336ltered WSJ models, were trained for the 1994 ARP) 108 542.67 P
-0.49 (A) 532.67 542.67 P
0.37 (Hub 2 evaluation. However these models were trained on real telephone speech. The WSJ and) 72 520.67 P
-0.39 (TIMIT utterances that are part of the Macrophone database made up the training corpus. The rest) 72 498.67 P
-0.02 (of Macrophone corpus was not used because it was not suitable for training models for unlimited) 72 476.67 P
(vocabulary continuous speech. These models were also 1PD models.) 72 454.67 T
0.82 (The Macrophone models also produce the dif) 108 234.67 P
0.82 (ference in performance between the male) 333.17 234.67 P
0.59 (and female models that was observed in the \336ltered WSJ models. With the use of Macrophone) 72 212.67 P
-0.52 (models the WER has fallen another 32%. This further improvement is due to the fact that the Mac-) 72 190.67 P
0.32 (rophone models do more than simply model the shape of the telephone channel. Other sources) 72 168.67 P
0.42 (of degradations have also been modelled and hence there is a better match in the Macrophone) 72 146.67 P
(models and the test speech from the MALL88 database.) 72 124.67 T
2 12 Q
(Macrophone System) 161.49 387 T
-0.59 (WER on entire) 326.19 394 P
(test set) 345.67 380 T
(WER on part of) 419.06 401 T
-0.41 (test set matched to) 412.73 387 P
(models used) 427.38 373 T
(Perfect sex classi\336cation of test utt.) 108.96 349 T
(\050male and female models used\051) 108.96 335 T
(8.8) 342.96 349 T
(Male models only) 108.96 313 T
(8.8) 342.96 313 T
(4.1) 447 313 T
(Female models only) 108.96 291 T
(12.8) 342.96 291 T
(10.4) 447 291 T
5 F
(T) 143.43 269 T
(able 4: Performance of the sex dependent Macr) 150.33 269 T
(ophone models) 392.26 269 T
102.96 416 102.96 283.25 2 L
V
2 H
0 Z
N
318.96 418 318.96 282.75 2 L
V
0.5 H
N
405.36 418 405.36 282.75 2 L
V
2 H
N
509.04 416 509.04 283.25 2 L
V
N
101.96 417 510.04 417 2 L
V
N
101.96 363 510.04 363 2 L
V
N
101.96 327 510.04 327 2 L
V
0.5 H
N
101.96 305 510.04 305 2 L
V
N
101.96 283 510.04 283 2 L
V
N
FMENDPAGE
%%EndPage: "23" 25
%%Page: "24" 25
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 4: Performance of Existing Systems) 72 749.33 T
(24) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
0 14 Q
0 X
(4.4) 72 710.67 T
(Summary) 99.23 710.67 T
1 11 Q
-0.5 (W) 108 686.67 P
-0.5 (e have seen that as the mismatch in the models and dictionary of the recognition system) 118.17 686.67 P
0.68 (was reduced, performance on the MALL88 database improved. The best WER achieved so far) 72 664.67 P
0.34 (was obtained with models trained on a subset of the Macrophone corpus and using a dictionary) 72 642.67 P
-0.13 (consisting of the digits. The fact that the best result were obtained by models trained on real tele-) 72 620.67 P
-0.06 (phone speech also show us that bandlimiting and linear \336ltering are only approximation to the ef-) 72 598.67 P
(fects the telephone network has on speech.) 72 576.67 T
0.18 (Further improvement in this task can be achieved if the models are adapted to the MALL) 108 554.67 P
-0.18 (domain. This can be achieved by using the MALL training data. Since enough data exist for train-) 72 532.67 P
-0.44 (ing a unique set of models, models trained on the MALL88 database should provide us with better) 72 510.67 P
(results.) 72 488.67 T
FMENDPAGE
%%EndPage: "24" 26
%%Page: "25" 26
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 5: Bootstrapped T) 72 749.33 T
(raining) 189.4 749.33 T
(25) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
0 18 Q
0 X
(Chapter 5) 264.52 708 T
(Bootstrapped T) 210.04 674 T
(raining) 341.98 674 T
1 11 Q
-0.35 (As stated in the previous chapter) 108 638.67 P
-0.35 (, further improvements in acoustic modelling of the MALL) 265.62 638.67 P
0.17 (environment would reduce the acoustic mismatch between the models and the test environment) 72 616.67 P
0.45 (and further decrease the WER. The next step in the process was to train models speci\336c to the) 72 594.67 P
0.44 (MALL88 and MALL91 databases. Since the MALL databases have their own training sets there) 72 572.67 P
(are enough data to train models speci\336c to the task rather than just adapting existing models.) 72 550.67 T
0.19 (Adapting existing models requires training on existing models using training speech from) 108 528.67 P
-0.65 (the new domain. T) 72 506.67 P
-0.65 (raining new models requires the generation of a new senone mapping table and) 160.02 506.67 P
(senone clustering trees that are unique to the individual databases.) 72 484.67 T
-0.73 (The training was carried using existing models to bootstrap the training process, hence this) 108 462.67 P
-0.31 (training paradigm is called bootstrapped training. The models best suited to this task were the ex-) 72 440.67 P
0.48 (isting models trained on telephone environments, namely the \336ltered WSJ and the Macrophone) 72 418.67 P
-0.02 (models that were tested in the previous chapter) 72 396.67 P
-0.02 (. The male models were used to use to bootstrap) 302.06 396.67 P
(the training process as they perform much better than the female models.) 72 374.67 T
-0.24 (The MALL test sets were recognized using the \336nal models. The models were tested both) 108 352.67 P
-0.4 (in \322matched conditions\323 \050training and testing data from the same database\051 and \322cross conditions\323) 72 330.67 P
-0.33 (testing \050training data from one database and test data from the other database\051. This was done to) 72 308.67 P
0.07 (assess the performance and the robustness/adaptability of the models that had been generated.) 72 286.67 P
-0.08 (W) 72 264.67 P
-0.08 (e also wanted to see that if there was much dif) 82.17 264.67 P
-0.08 (ference in performance using models generated) 307.13 264.67 P
(by the two databases.) 72 242.67 T
0 14 Q
(5.1) 72 206.67 T
(Filtered WSJ models) 99.23 206.67 T
1 11 Q
0.27 (W) 108 182.67 P
0.27 (e \336rst used the \336ltered WSJ models as bootstrap models during the training procedure) 118.17 182.67 P
-0.07 (described above. Generic CD-SCHMMs were obtained, that were not \336ne tuned to any particular) 72 160.67 P
(speaker set.) 72 138.67 T
-0.02 (Five iterations were required for the MALL88 data and six iterations for the MALL91 data.) 108 116.67 P
(This is because the variability in the MALL91 data is greater than that in the MALL88 database.) 72 94.67 T
FMENDPAGE
%%EndPage: "25" 27
%%Page: "26" 27
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 5: Bootstrapped T) 72 749.33 T
(raining) 189.4 749.33 T
(26) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
1 11 Q
0 X
-0.29 (W) 108 536.67 P
-0.29 (e see from the results in T) 118.17 536.67 P
-0.29 (able 5 that the models do not perform well in cross conditions.) 242.19 536.67 P
-0.02 (This suggests that the acoustic mismatch in the two databases is greater than the models\325 ability) 72 514.67 P
(to generalize. The absolute error rates, however) 72 492.67 T
(, have dropped further) 305.26 492.67 T
(.) 412.75 492.67 T
0.36 (There were enough training data to train gender-dependent models, which produced im-) 108 470.67 P
0.19 (proved recognition accuracy) 72 448.67 P
0.19 (. Male and female models were individually selected on a sentence-) 208.96 448.67 P
0.4 (by-sentence basis according to the hypothesis transcription that had the best score. Further im-) 72 426.67 P
(provements were observed in absolute error rate.) 72 404.67 T
0 14 Q
(5.2) 72 368.67 T
(Macrophone models) 99.23 368.67 T
1 11 Q
-0.35 (The Macrophone models were also used to bootstrap the training process for the MALL88) 108 344.67 P
0.06 (and the MALL91 databases. The results obtained using the resulting generic and gender depen-) 72 322.67 P
(dent models trained are shown in T) 72 300.67 T
(able 6.) 242.37 300.67 T
2 12 Q
(MALL88) 205.26 674 T
(generic models) 191.77 660 T
(MALL91) 291.65 674 T
(generic models) 278.17 660 T
(MALL88) 378.05 681 T
(gender dep.) 373.07 667 T
(models) 383.71 653 T
(MALL91) 464.45 681 T
(gender dep.) 459.46 667 T
(models) 470.11 653 T
(MALL88 test set) 87.36 629 T
(8.2) 209.04 629 T
(12.2) 295.44 629 T
(6.2) 381.84 629 T
(1) 468.24 629 T
(1.0) 473.79 629 T
(MALL91 test set) 87.36 607 T
(9.7) 209.04 607 T
(6.3) 295.44 607 T
(7.8) 381.84 607 T
(4.7) 468.24 607 T
5 F
(T) 86.62 585 T
(able 5: Filter) 93.52 585 T
(ed WSJ used to bootstrap the MALL models. Results of the generic and) 159.26 585 T
(gender dependent MALL88 and MALL91 models.) 177.07 571 T
81.36 696 81.36 599.25 2 L
V
2 H
0 Z
N
185.04 698 185.04 598.75 2 L
V
0.5 H
N
271.44 698 271.44 598.75 2 L
V
N
357.84 698 357.84 598.75 2 L
V
2 H
N
444.24 698 444.24 598.75 2 L
V
0.5 H
N
530.64 696 530.64 599.25 2 L
V
2 H
N
80.36 697 531.64 697 2 L
V
N
80.36 643 531.64 643 2 L
V
N
80.36 621 531.64 621 2 L
V
0.5 H
N
80.36 599 531.64 599 2 L
V
N
FMENDPAGE
%%EndPage: "26" 28
%%Page: "27" 28
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 5: Bootstrapped T) 72 749.33 T
(raining) 189.4 749.33 T
(27) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
1 11 Q
0 X
0.94 (The performance of these models has improved over the performance achieved by the) 108 570.67 P
0.72 (Macrophone models because of the use of MALL data for additional training. The performance) 72 548.67 P
-0.63 (however is not an improvement on the models that were bootstrapped using the \336ltered WSJ data.) 72 526.67 P
(This suggests that the parameters of the bootstrapped models have settled in a local maxima.) 72 504.67 T
0 14 Q
(5.3) 72 468.67 T
(Summary) 99.23 468.67 T
1 11 Q
-0.12 (T) 108 444.67 P
-0.12 (ask-speci\336c training has improved the system\325) 113.49 444.67 P
-0.12 (s performance on the connected digit task) 336.76 444.67 P
0.25 (even further) 72 422.67 P
0.25 (. However the WER is still a lot worse than is achieved by digit recognition systems,) 130.27 422.67 P
-0.42 (for clean speech. In this case the data were obtained from telephone networks so there is a great-) 72 400.67 P
0.58 (er degree of acoustic mismatch between training and testing environments. T) 72 378.67 P
0.58 (elephone environ-) 451.49 378.67 P
4.35 (ment notwithstanding, the classi\336cation power of the models must be improved further) 72 356.67 P
4.35 (.) 536.95 356.67 P
(Improvements can be obtained by improving the inputs to the training process.) 72 334.67 T
0.01 (Thus far the inputs to training have been the initial models and the mapping table used in) 108 312.67 P
0.17 (the training and even further back the models used for the segmentation of the data. Further im-) 72 290.67 P
1.5 (provements presumably can be obtained by using better models for segmentation. The initial) 72 268.67 P
-0.13 (models will have to be closer to the optimum models and the clusters created for the mapping ta-) 72 246.67 P
(ble will have to be cleaner) 72 224.67 T
(. These points will be tackled in the following chapters.) 197.79 224.67 T
2 12 Q
(MALL88) 205.26 697 T
(generic models) 191.77 683 T
(MALL91) 291.65 697 T
(generic models) 278.17 683 T
(MALL88) 378.05 704 T
(gender dep.) 373.07 690 T
(models) 383.71 676 T
(MALL91) 464.45 704 T
(gender dep.) 459.46 690 T
(models) 470.11 676 T
(MALL88 test set) 87.36 652 T
(8.1) 218.04 652 T
(1) 304.44 652 T
(1.9) 309.99 652 T
(6.0) 390.84 652 T
(10.8) 477.24 652 T
(MALL91 test set) 87.36 630 T
(9.6) 218.04 630 T
(6.1) 304.44 630 T
(7.7) 390.84 630 T
(4.5) 477.24 630 T
5 F
(T) 79.8 608 T
(able 6: Macr) 86.69 608 T
(ophone models used to bootstrap the MALL models. Results of the generic) 151.76 608 T
(and gender dependent MALL88 and MALL91 models.) 165.9 594 T
81.36 719 81.36 622.25 2 L
V
2 H
0 Z
N
185.04 721 185.04 621.75 2 L
V
0.5 H
N
271.44 721 271.44 621.75 2 L
V
N
357.84 721 357.84 621.75 2 L
V
2 H
N
444.24 721 444.24 621.75 2 L
V
0.5 H
N
530.64 719 530.64 622.25 2 L
V
2 H
N
80.36 720 531.64 720 2 L
V
N
80.36 666 531.64 666 2 L
V
N
80.36 644 531.64 644 2 L
V
0.5 H
N
80.36 622 531.64 622 2 L
V
N
FMENDPAGE
%%EndPage: "27" 29
%%Page: "28" 29
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 6: Data-Driven T) 72 749.33 T
(raining) 183.27 749.33 T
(28) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
0 18 Q
0 X
(Chapter 6) 264.52 708 T
(Data-Driven T) 218.03 674 T
(raining) 333.99 674 T
1 11 Q
-0.27 (W) 108 638.67 P
-0.27 (e saw in the previous chapter that using task speci\336c training data improves the accura-) 118.17 638.67 P
-0.71 (cy of the recognition system. However to further improve performance we have to improve the per-) 72 616.67 P
-0.2 (formance of the segmenting models and start the training process with better initial models. Even) 72 594.67 P
-0.63 (though the existing telephone models from the WSJ tasks provide good results, they are not a per-) 72 572.67 P
-0.68 (fect environmental match. They were trained for an unlimited vocabulary task while the vocabulary) 72 550.67 P
(of the MALL databases is limited to the digits.) 72 528.67 T
-0.4 (This mismatch between training and testing conditions concerns more than just the size of) 108 506.67 P
0.71 (the dictionaries in both the systems: the \336ltered WSJ and Macrophone models have to be very) 72 484.67 P
-0.72 (robust and acoustically adaptable test data that are not seen during the training phase \050the unseen) 72 462.67 P
-0.03 (triphone problem\051. On the other hand, due to the limited vocabulary of the MALL database, there) 72 440.67 P
-0.18 (is a negligible amount of unseen test data. Since we know that the test data will be very similar to) 72 418.67 P
-0.06 (the training data we want the models to model the training data perfectly rather than also provide) 72 396.67 P
(acoustic coverage for unseen test data.) 72 374.67 T
0.5 (Another dif) 108 352.67 P
0.5 (ference, though indirect, is that the \336ltered WSJ and the Macrophone models) 161.43 352.67 P
-0.07 (rely on language models to provide discriminating information in the case of acoustic confusions.) 72 330.67 P
-0.47 (Since the systems built for digit tasks do not have language models and hence acoustic confusion) 72 308.67 P
-0.1 (will have to be further minimized in these systems. Hence it was decided that attempts should be) 72 286.67 P
-0.28 (made to disconnect the \336ltered WSJ/Macrophone models from the training process as far as pos-) 72 264.67 P
(sible. There are two ways that this can be achieved.) 72 242.67 T
-0.72 (The \336rst method of reducing the dependence on cross-domain models is to use the models) 108 220.67 P
-0.63 (created in the current training run to resegment the data and carry out a complete retraining. Since) 72 198.67 P
1.06 (the entire training process uses Maximum Likelihood estimation it is assumed that the models) 72 176.67 P
-0.47 (achieved at the end of retraining will perform better than the previous models. While these models) 72 154.67 P
-0.67 (will perform better on training data, it is assumed that the train and test sets are acoustically similar) 72 132.67 P
0.51 (so that performance on the test set will improve as well. Several iterations of segmentation and) 72 110.67 P
-0.68 (training will produce optimally trained models that bear very little resemblance to the cross-domain) 72 88.67 P
FMENDPAGE
%%EndPage: "28" 30
%%Page: "29" 30
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 6: Data-Driven T) 72 749.33 T
(raining) 183.27 749.33 T
(29) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
1 11 Q
0 X
0.52 (models used initially) 72 712.67 P
0.52 (. Unfortunately) 170.53 712.67 P
0.52 (, this process is extremely time consuming even for a simple) 241.69 712.67 P
-0.35 (digits task. In addition, there is no lower bound on the rate of convergence of the models. Further-) 72 690.67 P
0.34 (more, an) 72 668.67 P
3 F
0.34 (ad hoc) 119.08 668.67 P
1 F
0.34 ( criteria must be used to stop the process which might also be sub-optimal. For) 152.41 668.67 P
(these reasons this method was not used.) 72 646.67 T
-0.17 (Another way of reducing the dependence on cross-domain models is to create models for) 108 624.67 P
0.03 (the new task from scratch, and using these models to segment the data. W) 72 602.67 P
0.03 (e call this method the) 436.09 602.67 P
0.8 (data-driven approach as the training is completely driven by the training data with no in\337uence) 72 580.67 P
0.35 (from previous models. Furthermore when there is acoustic confusability in the training set, deci-) 72 558.67 P
-0.29 (sions will be based on what has been learned from the same database, acoustic properties of an-) 72 536.67 P
1.16 (other training database will not corrupt the current training process. W) 72 514.67 P
1.16 (e observed that models) 422.32 514.67 P
0.07 (obtained by this procedure outperformed the models obtained using the training procedures pre-) 72 492.67 P
(viously discussed.) 72 470.67 T
-0.2 (A similar approach was used for the MALL91 database with minor dif) 108 448.67 P
-0.2 (ferences which were) 440.26 448.67 P
0.64 (due to the dif) 72 426.67 P
0.64 (ferences in the two databases. The training procedure used for both MALL88 and) 137.24 426.67 P
(MALL91 will be described in detail in the rest of the chapter) 72 404.67 T
(.) 359.01 404.67 T
0 14 Q
(6.1) 72 368.67 T
(MALL 88) 99.23 368.67 T
1 11 Q
0.35 (The procedure described above to train models from scratch was used to obtain generic) 108 344.67 P
(CD SCHMMs. These were further \336ne tuned to separate male and female models.) 72 322.67 T
0 14 Q
(6.1.1) 72 292.67 T
(Context-Independent Semi-Continuous HMMs) 110.9 292.67 T
1 11 Q
0.18 (Once the acoustic and lexical features were extracted as described above, \336ve iterations) 108 268.67 P
-0.49 (of maximum likelihood \050Baum-W) 72 246.67 P
-0.49 (elch\051 training were run to train discrete models. These are the ini-) 228.45 246.67 P
0.89 (tial models for training CI-SCHMMs. T) 72 224.67 P
0.89 (o train optimally the CI-SCHMMs the output probabilities) 260.22 224.67 P
0.75 (were closely monitored. Baum-W) 72 202.67 P
0.75 (elch was stopped when the current iteration failed to increase) 235.23 202.67 P
-0.4 (the output probabilities by more than 5%. It was also seen that at this stage further training did not) 72 180.67 P
-0.72 (improve the decoding performance of the models. Five iterations were required to train these mod-) 72 158.67 P
(els to acceptable level.) 72 136.67 T
-0.72 (The performance of these models \050after the \336fth iteration\051 was as follows. They were tested) 108 114.67 P
(on test data from the training database \050MALL88\051 as well as on test data from MALL91.) 72 92.67 T
FMENDPAGE
%%EndPage: "29" 31
%%Page: "30" 31
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 6: Data-Driven T) 72 749.33 T
(raining) 183.27 749.33 T
(30) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
1 11 Q
0 X
0.24 (T) 108 514.67 P
0.24 (able 7 shows that these models, on the two test sets, have already dramatically outper-) 113.49 514.67 P
-0.07 (formed the models that were obtained after a complete training dependent on the \336ltered WSJ or) 72 492.67 P
0.02 (the Macrophone models. This is an encouraging result as this training procedure is not complete) 72 470.67 P
0.71 (yet and the context dependence has yet to be trained into the models. W) 72 448.67 P
0.71 (e now clearly see the) 433.98 448.67 P
0.58 (advantage of using only training data and models from the environment at hand. The cross-do-) 72 426.67 P
0.8 (main nature of the \336ltered WSJ and the Macrophone models caused mismatches in the phone) 72 404.67 P
-0.23 (cluster generation used to train the initial models that the training process could not recover from,) 72 382.67 P
-0.07 (causing the \336nal models to settle at a sub-optimal performance level. The improved performance) 72 360.67 P
(of these models will help minimize this ef) 72 338.67 T
(fect.) 270.23 338.67 T
0 14 Q
(6.1.2) 72 308.67 T
(Context-Dependent Semi-Continuous HMMs) 110.9 308.67 T
1 11 Q
1.2 (As the best possible models are used for the segmentation task, the CI-SCHMMs that) 108 284.67 P
-0.06 (were trained from scratch were the models used for segmentation. This insured that in this entire) 72 262.67 P
-0.21 (training process, of the MALL88 models, only information derived from the MALL88 training data-) 72 240.67 P
(base was used.) 72 218.67 T
-0.34 (Once the mapping table was created Baum-W) 108 196.67 P
-0.34 (elch \050maximum likelihood\051 training was per-) 330.47 196.67 P
-0.27 (formed using all the available training data from MALL88. The progress of these models was also) 72 174.67 P
0.53 (closely monitored. The models were monitored for increasing output probabilities, and tested at) 72 152.67 P
-0.6 (every iteration to make sure that over training had not occurred. The models converged to the \336nal) 72 130.67 P
-0.52 (generic models after four iterations of the BW algorithm. They were tested on the MALL88 and the) 72 108.67 P
(MALL91 test sets.) 72 86.67 T
2 12 Q
(MALL88 models) 192.19 674 T
(MALL88) 296.78 681 T
(test set) 303.27 667 T
(MALL91) 368.78 681 T
(test set) 375.27 667 T
(Filtered WSJ) 190.24 643 T
(6.2) 316.77 643 T
(1) 384 643 T
(1.0) 389.55 643 T
(Macrophone) 190.24 621 T
(6.0) 316.77 621 T
(10.8) 384 621 T
(CI-SCHMMs) 190.24 599 T
(3.7) 316.77 599 T
(4.1) 388.77 599 T
5 F
(T) 88.13 577 T
(able 7: The performance of the MALL88 Context-Independent models trained fr) 95.03 577 T
(om) 507.88 577 T
(scratch. Comparison points with the \336lter) 87.17 563 T
(ed WSJ and Macr) 300.16 563 T
(ophone gender dependent) 392.89 563 T
(models is also pr) 245.13 549 T
(ovided.) 329.88 549 T
184.24 696 184.24 591.25 2 L
V
2 H
0 Z
N
283.77 698 283.77 590.75 2 L
V
0.5 H
N
355.77 698 355.77 590.75 2 L
V
N
427.77 696 427.77 591.25 2 L
V
2 H
N
183.24 697 428.77 697 2 L
V
N
183.24 657 428.77 657 2 L
V
N
183.24 635 428.77 635 2 L
V
0.5 H
N
183.24 613 428.77 613 2 L
V
N
183.24 591 428.77 591 2 L
V
N
FMENDPAGE
%%EndPage: "30" 32
%%Page: "31" 32
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 6: Data-Driven T) 72 749.33 T
(raining) 183.27 749.33 T
(31) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
1 11 Q
0 X
-0.19 (Similar training was carried out to produce male and female models. The male models re-) 108 712.67 P
-0.4 (quired four iterations and the female models required three iterations of further Baum W) 72 690.67 P
-0.4 (elch train-) 492.17 690.67 P
1.1 (ing. This dif) 72 668.67 P
1.1 (ference is attributed to the fact that the MALL88 training set has three times more) 130.17 668.67 P
0.37 (female speech data than male data. This causes the generic models to be closer to the \336nal fe-) 72 646.67 P
(male models than the male models, so it took less iterations to train the female models.) 72 624.67 T
-0.31 (W) 108 396.67 P
-0.31 (e see that there has been further improvement in the performance of these models. The) 118.17 396.67 P
0.28 (generic CD-SCHMMs have improved by 40.5% on the CI models in the matched condition. Fur-) 72 374.67 P
0.69 (ther improvement is expected as we move from context-independent models to context-depen-) 72 352.67 P
0.63 (dent models in a continuous speech recognition task because of the improved modelling of co-) 72 330.67 P
0.71 (articulation ef) 72 308.67 P
0.71 (fects of continuous speech. W) 137.85 308.67 P
0.71 (e observed a 73% improvement of the generic CD-) 287.04 308.67 P
0.8 (SCHMMs on the generic models and 64.6% improvement using the gender-dependent models) 72 286.67 P
0.08 (trained by bootstrapping with the \336ltered WSJ system. Similar improvements are observed when) 72 264.67 P
0.1 (the results are compared to the models bootstrapped from Macrophone models, 73% for the ge-) 72 242.67 P
(neric models and 63% for the gender-dependent models.) 72 220.67 T
-0.12 (It should also be noted that the cross-domain performance of these models has improved) 108 198.67 P
0.34 (as well. The performance on the MALL91 test set has improved 74.2% relative to \050\336ltered WSJ-) 72 176.67 P
-0.55 (bootstrapped generic models\051. Hence we see that only using the MALL88 data to train these mod-) 72 154.67 P
(els does not have an adverse ef) 72 132.67 T
(fect on the cross domain adaptability of these models.) 227.53 132.67 T
0.11 (With gender-dependent training, a further decrease of 13.5% in the word error rate is ob-) 108 110.67 P
0.47 (served for the MALL88 test set. The error rate on the MALL91 test set, however) 72 88.67 P
0.47 (, has increased) 464.56 88.67 P
2 12 Q
(MALL88 models) 192.19 564 T
(MALL88) 329.13 571 T
(test set) 335.62 557 T
(MALL91) 401.13 571 T
(test set) 407.62 557 T
(CI-SCHMMs) 157.89 533 T
(3.7) 349.11 533 T
(4.1) 421.11 533 T
(CD-SCHMMs:) 157.89 511 T
(generic) 157.89 489 T
(2.2) 349.11 489 T
(2.5) 421.11 489 T
(gender dependent) 157.89 467 T
(1.9) 349.11 467 T
(2.6) 421.11 467 T
5 F
-0.39 (T) 72 445 P
-0.39 (able 8: The performance of the MALL88 Context-Dependent models trained fr) 78.9 445 P
-0.39 (om scratch.) 478.5 445 P
(Comparison point with the Context-Independent models is also pr) 118.7 431 T
(ovided.) 456.31 431 T
151.89 586 151.89 459.25 2 L
V
2 H
0 Z
N
316.11 588 316.11 458.75 2 L
V
0.5 H
N
388.11 588 388.11 458.75 2 L
V
N
460.11 586 460.11 459.25 2 L
V
2 H
N
150.89 587 461.11 587 2 L
V
N
150.89 547 461.11 547 2 L
V
N
150.89 525 461.11 525 2 L
V
0.5 H
N
150.89 503 461.11 503 2 L
V
N
150.89 481 461.11 481 2 L
V
N
150.89 459 461.11 459 2 L
V
N
FMENDPAGE
%%EndPage: "31" 33
%%Page: "32" 33
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 6: Data-Driven T) 72 749.33 T
(raining) 183.27 749.33 T
(32) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
1 11 Q
0 X
-0.37 (4%. As before, we have seen that further \336ne tuning of the generic MALL88 models has improved) 72 712.67 P
-0.03 (the performance on the MALL88 test set but reduced the robustness of the models as applicable) 72 690.67 P
(to the MALL91 test set.) 72 668.67 T
0 14 Q
(6.2) 72 632.67 T
(MALL91) 99.23 632.67 T
1 11 Q
-0.72 (A similar training process was used for the MALL91 database. However certain dif) 108 608.67 P
-0.72 (ferences) 497.87 608.67 P
-0.25 (required special treatment in the training procedure in this case. The main dif) 72 586.67 P
-0.25 (ference was that the) 441.83 586.67 P
0.42 (speech in this database has a greater degree of co-articulation. The digit strings are longer and) 72 564.67 P
-0.03 (this caused the utterances to be spoken at a faster rate which caused the greater co-articulation.) 72 542.67 P
(This required additional iterations of Baum-W) 72 520.67 T
(elch and segmentation in the training process.) 291.61 520.67 T
0 14 Q
(6.2.1) 72 490.67 T
(Context-Independent Semi-Continuous HMMs) 110.9 490.67 T
1 11 Q
0.74 (The training of initial models for the MALL91 set followed the same lines as that for the) 108 466.67 P
0.1 (MALL88 set. In this case, however) 72 444.67 P
0.1 (, the performance of the CI-SCHMMs was not better than that) 239.81 444.67 P
(obtained in the bootstrapped training.) 72 422.67 T
0.7 (W) 108 202.67 P
0.7 (e assume that as this training progresses the performance of the models will improve) 118.17 202.67 P
0.3 (beyond the level of the previously-trained models. By training context dependent models we will) 72 180.67 P
(be able to better model the coarticulation ef) 72 158.67 T
(fects in this data.) 282.49 158.67 T
0 14 Q
(6.2.2) 72 128.67 T
(Context-Dependent Semi-Continuous HMMs) 110.9 128.67 T
1 11 Q
-0.36 (W) 108 104.67 P
-0.36 (e stated earlier that segmentation should be carried out with the models that provide the) 118.17 104.67 P
0.34 (best recognition result. The CI-SCHMMs are clearly not the models with the best result but they) 72 82.67 P
2 12 Q
(MALL91 models) 192.19 362 T
(MALL88) 298.85 369 T
(test set) 305.35 355 T
(MALL91) 370.85 369 T
(test set) 377.35 355 T
(Filtered WSJ) 188.16 331 T
(7.8) 320.64 331 T
(4.7) 392.64 331 T
(Macrophone) 188.16 309 T
(7.7) 320.64 309 T
(4.5) 392.64 309 T
(CI-SCHMMs) 188.16 287 T
(8.4) 320.64 287 T
(7.8) 392.64 287 T
5 F
(T) 88.63 265 T
(able 9: The performance of the MALL91 Context Independent models trained fr) 95.53 265 T
(om) 507.38 265 T
(scratch. Comparison points with the \336lter) 87.17 251 T
(ed WSJ and Macr) 300.16 251 T
(ophone gender dependent) 392.89 251 T
(models is also pr) 245.13 237 T
(ovided.) 329.88 237 T
182.16 384 182.16 279.25 2 L
V
2 H
0 Z
N
285.84 386 285.84 278.75 2 L
V
0.5 H
N
357.84 386 357.84 278.75 2 L
V
N
429.84 384 429.84 279.25 2 L
V
2 H
N
181.16 385 430.84 385 2 L
V
N
181.16 345 430.84 345 2 L
V
N
181.16 323 430.84 323 2 L
V
0.5 H
N
181.16 301 430.84 301 2 L
V
N
181.16 279 430.84 279 2 L
V
N
FMENDPAGE
%%EndPage: "32" 34
%%Page: "33" 34
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 6: Data-Driven T) 72 749.33 T
(raining) 183.27 749.33 T
(33) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
1 11 Q
0 X
0.5 (were used to produce segmentation information as we wanted to create the mapping table with) 72 712.67 P
0.08 (information derived from the MALL91 database only) 72 690.67 P
0.08 (. With the mapping table created the training) 323.87 690.67 P
0.69 (proceeded as before with iterations of the Baum-W) 72 668.67 P
0.69 (elch algorithm. The following are the results) 323.96 668.67 P
(obtained from the models that were obtained after the \336fth iteration of training:) 72 646.67 T
2.06 (The CD-SCHMM models have moved away from the local maxima around the boot-) 108 426.67 P
-0.16 (strapped models. This is seen in the improved performance in the matched and cross conditions.) 72 404.67 P
-0.33 (Additionally the result obtained is a 44.8% further reduction in word error rate in the matched con-) 72 382.67 P
0.11 (ditions when compared to the performance of the CI-SCHMMs. This is comparable to the 40.5%) 72 360.67 P
1.08 (error rate reduction that was obtained in the similar case for the MALL88 models. However to) 72 338.67 P
0.71 (achieve the level of performance that we have with the MALL88 models further training for this) 72 316.67 P
(database is required.) 72 294.67 T
1.09 (For databases where the greater degree of acoustic confusability causes the \336rst pass) 108 272.67 P
-0.03 (models to be sub-optimally trained the accepted procedure is to resegment the training data with) 72 250.67 P
0.02 (the CD-SCHMMs and rerun the BW algorithm. This causes the models to move closer to the op-) 72 228.67 P
1.2 (timum performance level. This resegment-train cycle is continued until the performance of the) 72 206.67 P
-0.06 (models does not improve any further) 72 184.67 P
-0.06 (. At this point it is assumed that the resulting models are op-) 249.41 184.67 P
0.94 (timum. A resegmentation-training cycle on the MALL91 data improved the performance on the) 72 162.67 P
(MALL91 test set to 3.5% W) 72 140.67 T
(ord Error Rate.) 204.92 140.67 T
0.28 (The training procedure now calls for another resegmentation-train iteration. This process) 108 118.67 P
-0.1 (is very time consuming and with this database we have seen that the convergence of the models) 72 96.67 P
2 12 Q
(MALL91 models) 192.19 586 T
(MALL88) 299.29 593 T
(test set) 305.78 579 T
(MALL91) 371.29 593 T
(test set) 377.78 579 T
(Filtered WSJ) 187.73 555 T
(7.8) 312.07 555 T
(4.7) 393.07 555 T
(Macrophone) 187.73 533 T
(7.7) 312.07 533 T
(4.5) 393.07 533 T
(CD-SCHMMS) 187.73 511 T
(4.7) 312.07 511 T
(4.3) 393.07 511 T
5 F
-0.19 (T) 72.48 489 P
-0.19 (able 10: W) 79.38 489 P
-0.19 (ord Err) 133.63 489 P
-0.19 (or Rate of \336rst pass Context-Dependent generic MALL91 models tested) 172.86 489 P
(on the MALL88 and the MALL91 test sets. Comparison points with \336lter) 87.89 475 T
(ed WSJ and) 462.13 475 T
(Macr) 130.36 461 T
(ophone bootstrapped gender) 158.12 461 T
(-dependent model is also pr) 304.27 461 T
(ovided.) 444.65 461 T
181.73 608 181.73 503.25 2 L
V
2 H
0 Z
N
286.27 610 286.27 502.75 2 L
V
0.5 H
N
358.27 610 358.27 502.75 2 L
V
N
430.27 608 430.27 503.25 2 L
V
2 H
N
180.73 609 431.27 609 2 L
V
N
180.73 569 431.27 569 2 L
V
N
180.73 547 431.27 547 2 L
V
0.5 H
N
180.73 525 431.27 525 2 L
V
N
180.73 503 431.27 503 2 L
V
N
FMENDPAGE
%%EndPage: "33" 35
%%Page: "34" 35
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 6: Data-Driven T) 72 749.33 T
(raining) 183.27 749.33 T
(34) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
1 11 Q
0 X
-0.02 (is slow) 72 712.67 P
-0.02 (. A reason for the slow progress is that the senone clusters do not improve drastically with) 104.34 712.67 P
-0.55 (every resegmentation. At this point we assumed that since the mapping table had been generated) 72 690.67 P
0.4 (after two iterations of segmentation it re\337ects the optimum senone clusters. Therefore the latest) 72 668.67 P
0.47 (mapping table was used with the MALL88 generic models as initial models resulting in the opti-) 72 646.67 P
-0.15 (mum models without having to invest in the expensive resegmentation process iteratively) 72 624.67 P
-0.15 (. After 4) 501.83 624.67 P
(iterations the performance of the models stabilized at a WER of 1.9% on the MALL91 test set.) 72 602.67 T
0 14 Q
(6.2.3) 72 572.67 T
(Context-Dependent Semi-Continuous HMMs) 110.9 572.67 T
1 11 Q
-0.02 (Further training of male and female models was also performed. The results obtained us-) 108 548.67 P
(ing these models are presented in T) 72 526.67 T
(able 1) 246.03 526.67 T
(1.) 275.15 526.67 T
-0.31 (Compared to the Context-Independent models these models have reduced the word error) 108 298.67 P
0.28 (rate by 75% on the MALL91 test and 71% on the MALL88 test set. These models have also im-) 72 276.67 P
-0.38 (proved performance by 62% on the \336ltered WSJ and 60% on the Macrophone bootstrapped mod-) 72 254.67 P
1.33 (els. Fine tuning the models to the speaker gender further improved the performance of these) 72 232.67 P
1.36 (models. The performance of the MALL91 models are now at par with the performance of the) 72 210.67 P
(MALL88 models) 72 188.67 T
0 14 Q
(6.3) 72 152.67 T
(Summary) 99.23 152.67 T
1 11 Q
0.21 (T) 108 128.67 P
0.21 (raining from scratch has resulted in models that perform at a much better level than the) 114.31 128.67 P
-0.27 (models that were trained from existing systems. The process was cycle intensive and care had to) 72 106.67 P
0.36 (be taken at each stage that the system was not over-trained.) 72 84.67 P
0.36 (Every initial model used had to be) 372.98 84.67 P
2 12 Q
(MALL91 models) 192.19 466 T
(MALL88) 329.13 473 T
(test set) 335.62 459 T
(MALL91) 401.13 473 T
(test set) 407.62 459 T
(CI-SCHMMs) 157.89 435 T
(8.4) 350.91 435 T
(7.8) 422.91 435 T
(CD-SCHMMs:) 157.89 413 T
(generic) 157.89 391 T
(2.4) 350.91 391 T
(1.9) 422.91 391 T
(gender dependent) 157.89 369 T
(2.4) 350.91 369 T
(1.8) 422.91 369 T
5 F
(T) 90.14 347 T
(able 1) 97.03 347 T
(1: The performance of the MALL91 Context-Dependent models trained fr) 126.69 347 T
(om) 505.88 347 T
(scratch. Comparison point with the Context-Independent models is also pr) 97.05 333 T
(ovided.) 477.96 333 T
151.89 488 151.89 361.25 2 L
V
2 H
0 Z
N
316.11 490 316.11 360.75 2 L
V
0.5 H
N
388.11 490 388.11 360.75 2 L
V
N
460.11 488 460.11 361.25 2 L
V
2 H
N
150.89 489 461.11 489 2 L
V
N
150.89 449 461.11 449 2 L
V
N
150.89 427 461.11 427 2 L
V
0.5 H
N
150.89 405 461.11 405 2 L
V
N
150.89 383 461.11 383 2 L
V
N
150.89 361 461.11 361 2 L
V
N
FMENDPAGE
%%EndPage: "34" 36
%%Page: "35" 36
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 6: Data-Driven T) 72 749.33 T
(raining) 183.27 749.33 T
(35) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
1 11 Q
0 X
-0.27 (as optimum as possible in order to obtain optimum models at later stages. In cases where the co-) 72 712.67 P
-0.73 (articulation or other acoustic features \050such as noise\051 make training harder) 72 690.67 P
-0.73 (, more of CPU-intensive) 425.58 690.67 P
-0.4 (iterations of generating the mapping table are required. This process, though expensive, does im-) 72 668.67 P
(prove the overall performance of the \336nal models.) 72 646.67 T
0.1 (At this point the best models that we have for both databases are the gender-dependent,) 108 624.67 P
-0.09 (context-dependent, semi-continuous HMMs. The output probabilities in these models are all tied,) 72 602.67 P
0.59 (having been derived from the same set of 256 Gaussian distributions. One way to increase the) 72 580.67 P
0.45 (dif) 72 558.67 P
0.45 (ferentiability of the models would be to use multiple sets of Gaussians for the models. This is) 83.4 558.67 P
0.17 (usually done by grouping certain phonemes according to their acoustic characteristics with each) 72 536.67 P
-0.39 (group of phonemes sharing its distributions with a dif) 72 514.67 P
-0.39 (ferent set. This approach will be used to train) 324.52 514.67 P
(the next set of word-based models described in the following chapter) 72 492.67 T
(.) 405.41 492.67 T
FMENDPAGE
%%EndPage: "35" 37
%%Page: "36" 37
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 7: W) 72 749.33 T
(ord-based Systems) 130.7 749.33 T
(36) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
0 18 Q
0 X
(Chapter 7) 264.52 708 T
(W) 213.69 674 T
(ord-Based Systems) 230.35 674 T
1 11 Q
0.16 (The main dif) 108 638.67 P
0.16 (ference between the MALL databases and the ones with which SPHINX II is) 168.58 638.67 P
-0.59 (usually used is the vocabulary size. SPHINX II was developed to perform well on large-vocabulary) 72 616.67 P
-0.4 (tasks. In such tasks normally there are not enough training data to train models perfectly for every) 72 594.67 P
0.02 (word in the database. SPHINX II overcomes this problem by training context-dependent phones.) 72 572.67 P
0.18 (In continuous speech the articulation of a single phone dif) 72 550.67 P
0.18 (fers according to the word it is present) 353.12 550.67 P
-0.25 (in. SPHINX II reduces this dependency to the left and right phones in the current context. Though) 72 528.67 P
-0.31 (triphone modelling reduces the amount of training data required, there are still not enough data to) 72 506.67 P
0.32 (train individually every triphone. For this reason senones that share the same central phone are) 72 484.67 P
(tied to share the same output distribution. This tying is part of the senone mapping table.) 72 462.67 T
-0.45 (In the digit task the vocabulary is small enough that word models may be used. If there are) 108 440.67 P
0.5 (enough training data, word models perform better than phone models because they do a better) 72 418.67 P
0.35 (job of modelling intra-word context dependencies. However) 72 396.67 P
0.35 (, due to the continuous nature of the) 361.68 396.67 P
0.68 (data, inter-word context dependency must be incorporated into the \336nal models. Sharing of se-) 72 374.67 P
-0.17 (nones is not necessary in the digit task because with the small number of phones \05022\051 and possi-) 72 352.67 P
0.32 (ble contexts \050again limited by the size of the dictionary\051 it should be possible to individually train) 72 330.67 P
1.65 (all senones. Hence untying some of these dependencies should improve the performance of) 72 308.67 P
(SPHINX II on the digits task.) 72 286.67 T
0 14 Q
(7.1) 72 250.67 T
(System Description) 99.23 250.67 T
1 11 Q
0.36 (A new phone set was de\336ned to train a system that is close to a word-based continuous) 108 226.67 P
0.11 (system. For all the words in the dictionary the phones were made word-dependent. For example) 72 204.67 P
(in the original dictionary based on the original phone set the representation for \322SEVEN\323 is) 72 182.67 T
(S EH V AX N) 108 160.67 T
(In the new dictionary the representation is) 72 138.67 T
( S_7 EH_7 V_7 AX_7 N_7) 108 116.67 T
FMENDPAGE
%%EndPage: "36" 38
%%Page: "37" 38
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 7: W) 72 749.33 T
(ord-based Systems) 130.7 749.33 T
(37) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
1 11 Q
0 X
-0.38 (Here we see that the word \322SEVEN\323 is now made up of unique phones that are not shared) 108 712.67 P
-0.01 (by any other word in the vocabulary) 72 690.67 P
-0.01 (. The phone \322S\323 that used to be common to SIX also now ap-) 244.55 690.67 P
0.7 (pears as \322S_6\323 in the word SIX and \322S_7\323 in the word SEVEN. Hence by untying the individual) 72 668.67 P
-0.49 (phones at the word level the number of phones has increased from 22 to 33. Since the vocabulary) 72 646.67 P
0.5 (is small in this task, making the phones word-dependent does not increase their number drasti-) 72 624.67 P
0.29 (cally) 72 602.67 P
0.29 (. W) 93.16 602.67 P
0.29 (e still have fewer phones than the number required by SPHINX II to model all the sound) 109.73 602.67 P
(in English.) 72 580.67 T
0.24 (The use of this phone structure ensures that triphones are not shared across words. Un-) 108 558.67 P
0.17 (tying of this nature is only possible in a small-vocabulary system as it would greatly increase the) 72 536.67 P
-0.35 (number of parameters to be learned in a larger system. Learning the increased number of param-) 72 514.67 P
0.52 (eters from the same amount of training data is more likely to be detrimental than bene\336cial in a) 72 492.67 P
(larger system.) 72 470.67 T
-0.29 (Another change that was made was that the number of senones was not minimized. Each) 108 448.67 P
0.95 (senone was allowed to form a cluster containing just itself. However for optimum usage of the) 72 426.67 P
(training data some clustering of the senones did take place.) 72 404.67 T
-0.01 (Now that identical phones that had been shared by two words have been dif) 108 382.67 P
-0.01 (ferentiated in) 476.5 382.67 P
-0.76 (the new phone set, it was easy to set up Gaussian sets for phones from single words and to ensure) 72 360.67 P
0.71 (that there is no sharing of distributions between dif) 72 338.67 P
0.71 (ferent words. All the phones that make up a) 322.39 338.67 P
(single word have tied output distributions.) 72 316.67 T
0 14 Q
(7.2) 72 280.67 T
(T) 99.23 280.67 T
(raining) 107.01 280.67 T
1 11 Q
-0.32 (As the word-based system uses a new phone set, for which no initial models exist, a train-) 108 256.67 P
(ing method to generate initial models must be selected.) 72 234.67 T
-0.55 (One method would be to use existing models as initial models. Thus the model for N would) 108 212.67 P
-0.29 (be an initial model for N_1, N_7 and N_9. The advantage of this method is that training could pro-) 72 190.67 P
0.57 (ceed at a rapid rate as the existing models would just be \336ne tuned to the dif) 72 168.67 P
0.57 (ferent contexts for) 450.93 168.67 P
-0.52 (every model. Instead of training each new model from the ground up just a few iterations of Baum-) 72 146.67 P
0.24 (W) 72 124.67 P
0.24 (elch retraining should provide us with fully-trained models. The disadvantage, however) 82.17 124.67 P
0.24 (, is that) 504.09 124.67 P
0.17 (because each of the new models are seeded from the same initial models, the new models may) 72 102.67 P
-0.06 (inherit enough of the properties of the initial models that they would remain mutually confusable.) 72 80.67 P
FMENDPAGE
%%EndPage: "37" 39
%%Page: "38" 39
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 7: W) 72 749.33 T
(ord-based Systems) 130.7 749.33 T
(38) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
1 11 Q
0 X
0.18 (A second method would be to use the data-driven approach and train the new phone set) 108 712.67 P
0.91 (from scratch. This method has already been shown to be successful in training models for the) 72 690.67 P
0.01 (MALL88 and the MALL91 databases, albeit using the traditional phone set. This process has the) 72 668.67 P
-0.64 (additional advantage of facilitating comparisons between systems based on the original and word-) 72 646.67 P
-0.54 (based phone sets. The disadvantage is that this approach is computationally expensive, especial-) 72 624.67 P
(ly for the MALL91 database.) 72 602.67 T
0 14 Q
(7.2.1) 72 572.67 T
(The MALL88 Database) 110.9 572.67 T
1 11 Q
-0.37 (The training procedure followed a similar path as in training from scratch using the original) 108 548.67 P
0.12 (phone set. V) 72 526.67 P
0.12 (ector-quantized data were used to bootstrap the CI-DHMMs. These models eventu-) 133.33 526.67 P
(ally led to the CD-SCHMMs by the way of segmentation of the training data by CI-SCHMMs.) 72 504.67 T
0 F
(7.2.1.1) 72 482.67 T
(Context-Independent Semi Continuous HMMs) 111.71 482.67 T
1 F
-0.13 (Acoustic and lexical features were extracted as described above. As before \336ve iterations) 108 459.67 P
0.35 (of maximum likelihood training was used to generate CI-DHMMs models starting from \337at distri-) 72 437.67 P
-0.24 (butions. With these models as the initial point maximum likelihood training was performed to gen-) 72 415.67 P
(erate acceptable CI-SCHMMs.) 72 393.67 T
-0.75 (The performance of these models on the tests sets MALL88 and MALL91 is shown in T) 108 371.67 P
-0.75 (able) 519.23 371.67 P
1.38 (12. For comparison, results obtained using the original phone-set have also been included. It) 72 349.67 P
-0.23 (should be noted that even though these models are context independent, a degree of context de-) 72 327.67 P
-0.13 (pendency has been built into the models because each phone depends on the word of which it is) 72 305.67 P
-0.51 (a part. Hence these models already have some of the advantages of intra word context modelling.) 72 283.67 P
-0.5 (This context dependency is one of the reasons for the 13.5% improvement in performance) 108 135.67 P
-0.1 (over the original phone models using the MALL88 test set. The 2.4% increase in errors observed) 72 113.67 P
2 12 Q
(MALL88 models) 192.19 245 T
(MALL88) 309.22 252 T
(test set) 315.72 238 T
(MALL91) 381.22 252 T
(test set) 387.72 238 T
(Original phone-set) 177.79 214 T
(3.7) 331.01 214 T
(4.1) 403.01 214 T
(W) 177.79 192 T
(ord-based phone-set) 188.15 192 T
(3.2) 331.01 192 T
(4.2) 403.01 192 T
5 F
(T) 163.25 170 T
(able 12: W) 170.15 170 T
(ord Err) 224.79 170 T
(or Rates for MALL88 CI-SCHMMs) 264.21 170 T
171.79 267 171.79 184.25 2 L
V
2 H
0 Z
N
296.21 269 296.21 183.75 2 L
V
0.5 H
N
368.21 269 368.21 183.75 2 L
V
N
440.21 267 440.21 184.25 2 L
V
2 H
N
170.79 268 441.21 268 2 L
V
N
170.79 228 441.21 228 2 L
V
N
170.79 206 441.21 206 2 L
V
0.5 H
N
170.79 184 441.21 184 2 L
V
N
FMENDPAGE
%%EndPage: "38" 40
%%Page: "39" 40
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 7: W) 72 749.33 T
(ord-based Systems) 130.7 749.33 T
(39) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
1 11 Q
0 X
0.2 (for the MALL91 data suggests that as these models become more \336ne tuned to the subtleties of) 72 712.67 P
(the of the MALL88 database they lose some of their generality) 72 690.67 T
(.) 373.48 690.67 T
0 F
(7.2.1.2) 72 668.67 T
(Context-Dependent Semi-Continuous HMMs) 111.71 668.67 T
1 F
1.04 (The next step towards context dependent modelling is the segmentation of the training) 108 645.67 P
-0.28 (data. In cases such as the current one where a new system is being built \050new phone set\051 no pre-) 72 623.67 P
-0.02 (vious models exist. This is where the advantage of training from scratch is evident; it provides us) 72 601.67 P
(with initial models to perform the segmentation.) 72 579.67 T
-0.63 (The segmentation process resulted in a list of 375 trainable triphones for this task. The 375) 108 557.67 P
-0.02 (triphones are made up of a total of 1875 unclustered senones. In this system we attempt to mini-) 72 535.67 P
0.3 (mize the tying between these senones so as to approach the spirit of a fully-continuous system.) 72 513.67 P
0.09 (The tying is now performed not at the senonic level but only at the output distribution level. Later) 72 491.67 P
-0.35 (attempts will be made to further untie the output distributions of the HMMs. It should be noted that) 72 469.67 P
-0.15 (each untying increases the amount of training data required, as the number of free parameters in) 72 447.67 P
(the system increases.) 72 425.67 T
-0.72 (Once the senone mapping table was created, three iterations of Baum-W) 108 403.67 P
-0.72 (elch training were) 455.36 403.67 P
1.58 (required to obtain context-dependent SCHMMs. Further iterations did not improve the perfor-) 72 381.67 P
-0.64 (mance of the models. Once again these models were tested on both the MALL88 and the MALL91) 72 359.67 P
(test sets.) 72 337.67 T
0.63 (The results obtained with the models trained with the original phone set have been pre-) 108 167.67 P
0.14 (sented along with the results for the new models. The new models perform slightly \0504.5%\051 better) 72 145.67 P
0.48 (than the existing models on the MALL88 test set and slightly worse on the MALL91 test set. By) 72 123.67 P
0.32 (this stage the models based on the original phone set are context dependent and hence have a) 72 101.67 P
-0.4 (performance close to the word-based phone models. The advantage of the word-based models is) 72 79.67 P
2 12 Q
(MALL88 models) 192.19 277 T
(MALL88) 309.22 284 T
(test set) 315.72 270 T
(MALL91) 381.22 284 T
(test set) 387.72 270 T
(Original phone set) 177.79 246 T
(2.2) 330 246 T
(2.5) 402 246 T
(W) 177.79 224 T
(ord based phone set) 188.15 224 T
(2.1) 330 224 T
(2.6) 402 224 T
5 F
(T) 161.26 202 T
(able 13: W) 168.15 202 T
(ord Err) 222.8 202 T
(or Rates for MALL88 CD-SCHMMs) 262.22 202 T
171.79 299 171.79 216.25 2 L
V
2 H
0 Z
N
296.21 301 296.21 215.75 2 L
V
0.5 H
N
368.21 301 368.21 215.75 2 L
V
N
440.21 299 440.21 216.25 2 L
V
2 H
N
170.79 300 441.21 300 2 L
V
N
170.79 260 441.21 260 2 L
V
N
170.79 238 441.21 238 2 L
V
0.5 H
N
170.79 216 441.21 216 2 L
V
N
FMENDPAGE
%%EndPage: "39" 41
%%Page: "40" 41
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 7: W) 72 749.33 T
(ord-based Systems) 130.7 749.33 T
(40) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
1 11 Q
0 X
0.89 (that each triphone \050except the inter-word triphones\051 has been trained individually from scratch,) 72 712.67 P
-0.27 (and information from triphones sharing the same central phone has not been shared. This has al-) 72 690.67 P
0.17 (lowed for cleaner triphone modelling, as in this case there were enough training data to train the) 72 668.67 P
-0.29 (triphones from scratch. In cases where there is limited training data, some amount of tying is nec-) 72 646.67 P
-0.76 (essary to obtain robust estimates for the triphone. In our case each triphone model is bootstrapped) 72 624.67 P
(with the model of its central phone.) 72 602.67 T
-0.2 (In the cross-condition test we can see the limits of the robustness of this method. As a set) 108 580.67 P
-0.64 (of models are \336ne-tuned to a certain training set, their adaptability to cross conditions deteriorates.) 72 558.67 P
2.15 (These models have been \336ne tuned to the MALL88 database, so their performance on the) 72 536.67 P
-0.27 (MALL91 database is worse than models using the original phone set. This trend was also evident) 72 514.67 P
(with the CI-SCHMMs.) 72 492.67 T
0 F
(7.2.1.3) 72 470.67 T
(Further Processing) 111.71 470.67 T
1 F
0.69 (At this point we have generic context-dependent, SCHMMs for the word-based phones.) 108 447.67 P
0.02 (Further processing for these models includes sex dependent and Multiple Gaussian Set training.) 72 425.67 P
-0.26 (Both these procedure will be discussed once the creation of context-dependent, SCHMMs for the) 72 403.67 P
(W) 72 381.67 T
(ord-based phones for the MALL91 database has been described.) 82.17 381.67 T
0 14 Q
(7.2.2) 72 351.67 T
(The MALL91 Database) 110.9 351.67 T
1 11 Q
-0.35 (The training for the MALL91 word-based phone models closely followed the training of the) 108 327.67 P
(original phone models.) 72 305.67 T
0 F
(7.2.2.1) 72 283.67 T
(Context-Independent Semi-Continuous HMMs) 111.71 283.67 T
1 F
0.07 (Once the acoustic and lexical features were extracted as described above, Context Inde-) 108 260.67 P
(pendent HMMs were trained. The performance of the CI-SCHMMs are shown in T) 72 238.67 T
(able 14.) 468.86 238.67 T
2 12 Q
(MALL91 models) 192.19 178 T
(MALL88) 309.22 185 T
(test set) 315.72 171 T
(MALL91) 381.22 185 T
(test set) 387.72 171 T
(Original phone set) 177.79 147 T
(8.4) 322.37 147 T
(7.8) 394.37 147 T
(W) 177.79 125 T
(ord-based phone set) 188.15 125 T
(8.3) 321 125 T
(7.1) 393 125 T
5 F
(T) 163.25 103 T
(able 14: W) 170.15 103 T
(ord Err) 224.79 103 T
(or Rates for MALL91 CI-SCHMMs) 264.21 103 T
171.79 200 171.79 117.25 2 L
V
2 H
0 Z
N
296.21 202 296.21 116.75 2 L
V
0.5 H
N
368.21 202 368.21 116.75 2 L
V
N
440.21 200 440.21 117.25 2 L
V
2 H
N
170.79 201 441.21 201 2 L
V
N
170.79 161 441.21 161 2 L
V
N
170.79 139 441.21 139 2 L
V
0.5 H
N
170.79 117 441.21 117 2 L
V
N
FMENDPAGE
%%EndPage: "40" 42
%%Page: "41" 42
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 7: W) 72 749.33 T
(ord-based Systems) 130.7 749.33 T
(41) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
1 11 Q
0 X
0.28 (As stated earlier word-based phones already have a degree of context dependence built) 108 712.67 P
0.54 (into them. This context dependency provides the 8.9% improvement on the original phone con-) 72 690.67 P
0.97 (text-independent system, on the MALL91 test set \050matched conditions\051. However the improve-) 72 668.67 P
0.22 (ment on the MALL88 test set \050cross set conditions\051 is minimal. The context dependencies of the) 72 646.67 P
-0.59 (MALL91 data set have not improved performance on to the MALL88 task. This is another indicator) 72 624.67 P
(to the dif) 72 602.67 T
(ferences in these two data sets.) 113.95 602.67 T
0 F
(7.2.2.2) 72 580.67 T
(Context Dependent Semi-Continuous HMMs) 111.71 580.67 T
1 F
0.54 (The CI-SCHMMs that had just been trained were used for segmenting the training data.) 108 557.67 P
0.19 (The segmentation process resulted in a list of 385 trainable triphones for the MALL91 database.) 72 535.67 P
0.38 (The 385 triphones are made up of a total of 1925 unclustered senones. The clustering between) 72 513.67 P
0.25 (these senones was minimized so that each senone would be individually trained hence approxi-) 72 491.67 P
(mating a continuous system.) 72 469.67 T
0.8 (Once the mapping table had been created, context-dependent models were trained. As) 108 447.67 P
0.5 (with the original phone system the \336rst pass generic CD-SCHMMs were used to resegment the) 72 425.67 P
0.67 (training data and obtain a more accurate senonic mapping table. This mapping table was used) 72 403.67 P
-0.26 (with generic MALL88 word based, context-dependent, phone models as initial models to train ge-) 72 381.67 P
-0.2 (neric MALL91 word based, context-dependent, phone models. The performance of these models) 72 359.67 P
(on the MALL88 and the MALL91 test sets is shown below) 72 337.67 T
(.) 351.09 337.67 T
-0.65 (W) 108 167.67 P
-0.65 (e observe that the W) 118.17 167.67 P
-0.65 (ord-based phone model have not achieved the level of performance) 216.73 167.67 P
-0.27 (of the original phone models. W) 72 145.67 P
-0.27 (e assume that the sharing of parameters allowed the distributions) 224.93 145.67 P
-0.14 (in the original phone models to be better trained. The training data in the MALL91 database does) 72 123.67 P
-0.48 (not seem suf) 72 101.67 P
-0.48 (\336cient to train word-based models to the same level of performance. W) 133.73 101.67 P
-0.48 (e however as-) 471.97 101.67 P
2 12 Q
(MALL91 models) 192.19 277 T
(MALL88) 309.22 284 T
(test set) 315.72 270 T
(MALL91) 381.22 284 T
(test set) 387.72 270 T
(Original phone set) 177.79 246 T
(2.4) 330 246 T
(1.9) 402 246 T
(W) 177.79 224 T
(ord based phone set) 188.15 224 T
(2.5) 330 224 T
(2.2) 402 224 T
5 F
(T) 161.26 202 T
(able 15: W) 168.15 202 T
(ord Err) 222.8 202 T
(or Rates for MALL91 CD-SCHMMs) 262.22 202 T
171.79 299 171.79 216.25 2 L
V
2 H
0 Z
N
296.21 301 296.21 215.75 2 L
V
0.5 H
N
368.21 301 368.21 215.75 2 L
V
N
440.21 299 440.21 216.25 2 L
V
2 H
N
170.79 300 441.21 300 2 L
V
N
170.79 260 441.21 260 2 L
V
N
170.79 238 441.21 238 2 L
V
0.5 H
N
170.79 216 441.21 216 2 L
V
N
FMENDPAGE
%%EndPage: "41" 43
%%Page: "42" 43
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 7: W) 72 749.33 T
(ord-based Systems) 130.7 749.33 T
(42) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
1 11 Q
0 X
-0.28 (sume that the performance of the word-based models will improve further with the processing de-) 72 712.67 P
(scribed in the following chapter) 72 690.67 T
(.) 222.22 690.67 T
0 F
(7.2.2.3) 72 668.67 T
(Further Processing) 111.71 668.67 T
1 F
0.32 (W) 108 645.67 P
0.32 (e described the training of generic context-dependent SCHMMs for the MALL91 word-) 118.17 645.67 P
-0.29 (based phone system. The next step in the training procedure would be to train gender-dependent) 72 623.67 P
1.06 (models \050\336ne tune the CD-SCHMMs to the male and female speakers separately\051 and multiple) 72 601.67 P
(Gaussian set system. The work on these extensions will be described in the next chapter) 72 579.67 T
(.) 503.1 579.67 T
0 14 Q
(7.3) 72 543.67 T
(Summary) 99.23 543.67 T
1 11 Q
1.02 (W) 108 519.67 P
1.02 (e have described the training of word-based phone systems for the MALL88 and the) 118.17 519.67 P
-0.72 (MALL91 task. The system development in both cases proceeded as in the case of the correspond-) 72 497.67 P
0.91 (ing systems using the original phone set. The performance using word-based phones is better) 72 475.67 P
-0.09 (than that obtained using the original phone set. This gain is primarily due to the fact that we have) 72 453.67 P
0.44 (minimized the amount of acoustic training data shared by the within-word triphones, thereby re-) 72 431.67 P
1.37 (ducing the acoustic confusability of the resulting triphone models. It should be noted that this) 72 409.67 P
-0.08 (method presupposes the availability of enough training data to accurately model the new phones) 72 387.67 P
(and the increased number of triphones and may reduce the generality of the models obtained.) 72 365.67 T
FMENDPAGE
%%EndPage: "42" 44
%%Page: "43" 44
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 8: T) 72 749.33 T
(owards a W) 126.44 749.33 T
(ord-based System using an Approximation to Continuous HMMs) 179.02 749.33 T
(43) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
0 18 Q
0 X
(Chapter 8) 264.52 708 T
(T) 133.88 674 T
(owards a W) 143.54 674 T
(ord-based System using an) 243.19 674 T
(Approximation to Continuous HMMs) 150.09 654 T
1 11 Q
0.06 (The training of the word-based systems up to this point has followed closely the develop-) 108 618.67 P
-0.02 (ment of the original phone systems that had been trained from scratch. Further processing in the) 72 596.67 P
-0.46 (case of the normal phone systems implied gender dependent models and some degree of param-) 72 574.67 P
-0.46 (eter optimization. The advantages of the word-based system are that we can carry the processing) 72 552.67 P
-0.13 (a step further towards a continuous system that uses word models to model the vocabulary) 72 530.67 P
-0.13 (. Both) 511.42 530.67 P
(procedures should further improve performance.) 72 508.67 T
0.09 (In a system that uses word models, each word in the vocabulary is modelled by a unique) 108 486.67 P
-0.54 (HMM. The advantage is that within-word transitions between phonemes are perfectly modelled as) 72 464.67 P
-0.46 (training data are not shared between words. Inter-phoneme transitions are \336ne tuned to the single) 72 442.67 P
0.13 (context that is found in the word being modelled. Hence each \336nal model perfectly models its in-) 72 420.67 P
(dividual word to the extent that it can be trained.) 72 398.67 T
1.15 (SPHINX II is a semi-continuous HMM system. Its state output probabilities are mixture) 108 376.67 P
-0.2 (Gaussians consisting the top four distributions from a set of 256 Gaussians. Hence the modelling) 72 354.67 P
0.41 (of the output probabilities are inherently limited to the combinations possible from the given set.) 72 332.67 P
-0.33 (In a fully continuous system the output distributions are made up of untied \050unshared\051 Gaussians.) 72 310.67 P
-0.11 (This limitation, in SPHINX II, can be removed by increasing the number of Gaussian distributions) 72 288.67 P
-0.01 (to choose from. SPHINX II achieves this in a systematic manner) 72 266.67 P
-0.01 (. Phones are grouped into dif) 382.69 266.67 P
-0.01 (fer-) 523.52 266.67 P
-0.11 (ent acoustic classes. Each phone class then shares a completely independent set of 256 Gauss-) 72 244.67 P
-0.51 (ian distributions to generate output probabilities for all the senones in that class. T) 72 222.67 P
-0.51 (o move SPHINX) 461.04 222.67 P
0.13 (II more towards a continuous system it was decided to group the phones according to the words) 72 200.67 P
0.37 (from which they were derived rather than according to their acoustic classes. W) 72 178.67 P
0.37 (e are able to do) 462.16 178.67 P
-0.1 (this because each word in our dictionary is made up of unique phones. This ensures that training) 72 156.67 P
0.22 (data for one digit are not used to train the output distributions for a senone from another digit. In) 72 134.67 P
0.44 (this manner we achieve fully-continuous word modelling using the SPHINX II system. If enough) 72 112.67 P
FMENDPAGE
%%EndPage: "43" 45
%%Page: "44" 45
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 8: T) 72 749.33 T
(owards a W) 126.44 749.33 T
(ord-based System using an Approximation to Continuous HMMs) 179.02 749.33 T
(44) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
1 11 Q
0 X
0.26 (training data exists, the word-based classes can be further divided according to acoustical char-) 72 712.67 P
(acteristics) 72 690.67 T
-0.14 (In this chapter we will \336rst describe the \336nal stages of the development of the word-based) 108 668.67 P
0.09 (system. Once this system has been trained we will attempt to further \336ne tune the system devel-) 72 646.67 P
0.36 (opment by training gender dependent models for both the MALL88 and the MALL91 systems. It) 72 624.67 P
-0.14 (should be noted that both these methods increase the demand on the amount of training data re-) 72 602.67 P
0.24 (quired as they increase the number of parameters to be learnt. This increased data requirement) 72 580.67 P
(remains a limiting factor in the eventual performance of these systems.) 72 558.67 T
0 14 Q
(8.1) 72 522.67 T
(T) 99.23 522.67 T
(raining using Multiple Gaussian Set \050MGS\051) 107.01 522.67 T
1 11 Q
0.19 (The set of Gaussian distributions that are shared and make up the output distributions of) 108 498.67 P
0.54 (the senones is referred to as a Gaussian set \050GS\051. T) 72 476.67 P
0.54 (raditionally a Gaussian set in SPHINX II is) 331.65 476.67 P
0.59 (made up of 256 unique Gaussian distributions. Up to this point the systems consist of only one) 72 454.67 P
0.18 (Gaussian set. The following systems have individual Gaussian sets for each of the digits. All the) 72 432.67 P
-0.18 (senones, of these systems, that make up the phones of a particular digit derive their output distri-) 72 410.67 P
-0.37 (butions from the single Gaussian set associated with the digit. Hence there is no sharing of Gaus-) 72 388.67 P
(sian distributions among the digits.) 72 366.67 T
-0.68 (The initial models used were generic models using a single Gaussian set. The distributions) 108 344.67 P
0.63 (in these models were used as a starting point for the 1) 72 322.67 P
0.63 (1 distribution sets that make up the new) 341.98 322.67 P
-0.07 (models. The training was stopped after two iterations since further iterations did not improve per-) 72 300.67 P
-0.09 (formance on the test set. The models were tested on the MALL88 and MALL91 test sets. The re-) 72 278.67 P
(sults are shown below in T) 72 256.67 T
(able 16.) 200.22 256.67 T
2 12 Q
(MALL88) 211.83 203 T
(SGS models) 204.99 189 T
(MALL88) 291.03 203 T
(MGS models) 282.2 189 T
(MALL91) 370.23 203 T
(SGS models) 363.39 189 T
(MALL91) 449.43 203 T
(MGS models) 440.6 189 T
(MALL88 test set) 105.99 165 T
(2.1) 219.22 165 T
(1.8) 307.42 165 T
(2.5) 386.61 165 T
(2.5) 465.82 165 T
(MALL91 test set) 105.99 143 T
(2.6) 219.22 143 T
(2.2) 307.42 143 T
(2.2) 386.61 143 T
(1.9) 465.82 143 T
5 F
(T) 171.58 121 T
(able 16: W) 178.48 121 T
(ord Err) 233.12 121 T
(or Rates for MGS CD-SCHMMs) 272.54 121 T
99.99 218 99.99 136 2 L
V
2 H
0 Z
N
195.22 220 195.22 134 2 L
V
0.5 H
N
274.42 220 274.42 134 2 L
V
N
353.61 220 353.61 134 2 L
V
2 H
N
432.82 220 432.82 134 2 L
V
0.25 H
N
512.01 218 512.01 136 2 L
V
2 H
N
98.99 219 513.01 219 2 L
V
N
98.99 179 513.01 179 2 L
V
N
98.99 157 513.01 157 2 L
V
0.5 H
N
98.99 135 513.01 135 2 L
V
2 H
N
FMENDPAGE
%%EndPage: "44" 46
%%Page: "45" 46
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 8: T) 72 749.33 T
(owards a W) 126.44 749.33 T
(ord-based System using an Approximation to Continuous HMMs) 179.02 749.33 T
(45) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
1 11 Q
0 X
0.31 (These results show that the MGS models perform better than the previous SGS models.) 108 712.67 P
-0.68 (They perform better on the matched conditions. They improve performance in the cross conditions) 72 690.67 P
-0.76 (for the MALL88 models while no change is observed for the MALL91 models. The MALL88 models) 72 668.67 P
0.73 (improve performance by 14% in matched conditions and 15% in cross conditions. Similarly the) 72 646.67 P
(MALL91 models show a 13.6% improvement in the matched conditions.) 72 624.67 T
0 14 Q
(8.2) 72 588.67 T
(Gender-dependent training) 99.23 588.67 T
1 11 Q
-0.35 (Gender dependent training is a common way to further \336ne tune the models to a particular) 108 564.67 P
0.69 (set of speakers. Here the models are \336ne tuned to the gender of the test speaker) 72 542.67 P
0.69 (. The training) 474.49 542.67 P
0.13 (corpus is divided according to gender with the male training speakers used to \336ne tune the male) 72 520.67 P
-0.67 (models and the female training speakers used to \336ne tune the female models. It should be remem-) 72 498.67 P
-0.4 (bered that the training available for the male/female models is about half of what was available for) 72 476.67 P
0.07 (the generic models. Hence the performance of the gender-dependent models is closely linked to) 72 454.67 P
(suf) 72 432.67 T
(\336ciency of the training data to suitably estimate the gender dependent parameters.) 86.46 432.67 T
0.69 (Using the MGS generic models as initial models gender dependent training was carried) 108 410.67 P
0.02 (out. These models were then tested in matched and cross conditions. The results are shown be-) 72 388.67 P
(low in T) 72 366.67 T
(able 17.) 108.63 366.67 T
1.2 (The MALL88 models show an improved performance in the matched conditions with a) 108 210.67 P
1.32 (marginal drop in performance in the cross conditions. This is a trend that has been observed) 72 188.67 P
-0.48 (throughout this work: as the models get \336ne tuned to one database their performance on the other) 72 166.67 P
-0.19 (database degrades. The MGS gender-dependent models provide the best performance so far on) 72 144.67 P
0.5 (the MALL88 test data. The performance on the MALL91 models has however degraded in both) 72 122.67 P
0.02 (conditions. This show us that the training data was not able to successfully trained the increased) 72 100.67 P
(parameters caused by moving to a MGS gender-dependent system.) 72 78.67 T
2 12 Q
(MALL88) 297.41 313 T
(MALL91) 369.41 313 T
(MALL88 models) 189.6 289 T
(1.6) 317.4 289 T
(2.3) 389.4 289 T
(MALL91 models) 189.6 267 T
(3.1) 317.4 267 T
(2.2) 389.4 267 T
5 F
(T) 104.79 245 T
(able 17: W) 111.68 245 T
(ord Err) 166.32 245 T
(or Rates for gender dependent MALL MGS CD-SCHMMs) 205.75 245 T
183.6 328 183.6 259.25 2 L
V
2 H
0 Z
N
284.4 330 284.4 258.75 2 L
V
0.5 H
N
356.4 330 356.4 258.75 2 L
V
N
428.4 328 428.4 259.25 2 L
V
2 H
N
182.6 329 429.4 329 2 L
V
N
182.6 303 429.4 303 2 L
V
N
182.6 281 429.4 281 2 L
V
0.5 H
N
182.6 259 429.4 259 2 L
V
N
FMENDPAGE
%%EndPage: "45" 47
%%Page: "46" 47
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 8: T) 72 749.33 T
(owards a W) 126.44 749.33 T
(ord-based System using an Approximation to Continuous HMMs) 179.02 749.33 T
(46) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
0 14 Q
0 X
(8.3) 72 710.67 T
(Summary) 99.23 710.67 T
1 11 Q
3.05 (W) 108 686.67 P
3.05 (e have explored the possibility of improving the performance of the generic CD-) 118.17 686.67 P
0.67 (SCHMMs word based phone models that were trained. The \336rst technique used was to reduce) 72 664.67 P
1.04 (parameter sharing between the models. Gaussians that make up the output distributions were) 72 642.67 P
0.28 (shared between states that made up a single word, instead of across all trained states. This en-) 72 620.67 P
-0.13 (sured that the training data for a speci\336c word only trained parameters for that word, and was not) 72 598.67 P
-0.04 (used to jointly estimate parameters for other words in the dictionary) 72 576.67 P
-0.04 (. W) 397.45 576.67 P
-0.04 (e observed improvements) 413.69 576.67 P
0.58 (in performance for both the MALL88 and the MALL91 database when tested in matched condi-) 72 554.67 P
-0.45 (tions. The MALL88 models also improved performance in the cross conditions. This suggests that) 72 532.67 P
-0.59 (by reducing the amount of parameter sharing we have increased the discerning power of the mod-) 72 510.67 P
-0.55 (els. Parameter sharing causes the models to be similar to each other and hence more confusable.) 72 488.67 P
-0.2 (The second technique, gender dependent training, has been explored with previous mod-) 108 466.67 P
-0.5 (els. In this case we observed improved performance only for the MALL88 models. Gender-depen-) 72 444.67 P
0.02 (dent training doubles the number of parameters being trained and the MALL91 training data was) 72 422.67 P
-0.25 (not able to successfully estimate these increased parameters. W) 72 400.67 P
-0.25 (e see that the improvements ob-) 383.68 400.67 P
0.58 (tained from gender dependent training add on those obtained from reduced parameter sharing.) 72 378.67 P
0.09 (However with the caveat that there should be enough training data to train the larger set of inde-) 72 356.67 P
(pendent parameters) 72 334.67 T
FMENDPAGE
%%EndPage: "46" 48
%%Page: "47" 48
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 9: Environmental Adaptation) 72 749.33 T
(47) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
0 18 Q
0 X
(Chapter 9) 264.52 708 T
(Environmental Adaptation) 194.05 674 T
1 11 Q
-0.75 (Recognition systems perform best when the testing environment closely matches the train-) 108 638.67 P
0.07 (ing environment. This is especially true for recognition systems based on HMMs. T) 72 616.67 P
0.07 (o increase ro-) 472.71 616.67 P
-0.4 (bustness to environmental dif) 72 594.67 P
-0.4 (ferences between testing and training conditions algorithms such as) 213.48 594.67 P
1.5 (CDCN \050Codeword-Dependent Cepstral Normalization\051 [1] are used. These algorithms are de-) 72 572.67 P
0.51 (signed to work on the cepstral vectors before they are used for recognition and normalize them) 72 550.67 P
(\050bring them closer\051 to the training vectors.) 72 528.67 T
-0.01 (Both the MALL88 and the MALL91 databases consists of two data recorded at 2 dif) 108 506.67 P
-0.01 (ferent) 511.91 506.67 P
0.21 (sites, namely Long Island and Boston. These parts during training have been considered similar) 72 484.67 P
-0.46 (enough to be used together for training purposes. W) 72 462.67 P
-0.46 (e now look at the acoustic dif) 322.19 462.67 P
-0.46 (ferences in each) 460.31 462.67 P
-0.3 (of these parts closely and study our ability to adapt to the acoustic dif) 72 440.67 P
-0.3 (ferences that might exist be-) 403.19 440.67 P
(tween the data collected from the two sites.) 72 418.67 T
0.06 (Another source of acoustic mismatch that usually occurs, to a lesser degree, is the found) 108 396.67 P
0.37 (between the training and testing utterances. W) 72 374.67 P
0.37 (e would like our system to be robust to these dif-) 300.59 374.67 P
1.75 (ferences as they degrade the system performance in addition to the degradation extraneous) 72 352.67 P
(sources such as additive noise.) 72 330.67 T
0 14 Q
(9.1) 72 294.67 T
(CDCN) 99.23 294.67 T
1 11 Q
1.1 (CDCN is a technique for dealing jointly with additive noise and channel equalization. It) 108 270.67 P
-0.6 (does not require stereo training data. Hence it is suitable for a task such as recognition on the tele-) 72 248.67 P
(phone where no stereo data exist.) 72 226.67 T
0 14 Q
(9.2) 72 190.67 T
(Cross Environment Normalization) 99.23 190.67 T
1 11 Q
-0.65 (In this section we look at acoustic dif) 108 166.67 P
-0.65 (ferences across the recording site dimension. W) 280.96 166.67 P
-0.65 (e look) 511.34 166.67 P
0.71 (at CDCN\325) 72 144.67 P
0.71 (s ability to normalize these acoustic mis-matches and reduce the dif) 118.9 144.67 P
0.71 (ference in perfor-) 454.93 144.67 P
-0.18 (mance between matched and cross site recognition results. The experiments are performed sep-) 72 122.67 P
(arately for the MALL88 and the MALL91 databases.) 72 100.67 T
FMENDPAGE
%%EndPage: "47" 49
%%Page: "48" 49
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 9: Environmental Adaptation) 72 749.33 T
(48) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
0 14 Q
0 X
(9.2.1) 72 710.67 T
(MALL88) 110.9 710.67 T
1 11 Q
-0.37 (The entire MALL88 training set was divided into two training sets - the Long Island set and) 108 686.67 P
-0.52 (the Boston set. A similar division was performed on the test set. Using the new training set models) 72 664.67 P
1.35 (were trained for the Long Island and for the Boston sets. The models trained were SGS CD-) 72 642.67 P
0.5 (SCHMM word based phone models. Only generic models were trained as the training data had) 72 620.67 P
-0.59 (already been halved and further division for gender-dependent or MGS models were likely to have) 72 598.67 P
(been poorly estimated.) 72 576.67 T
-0.02 (The initial models used in the training procedure were the CI-SCHMM word-based phone) 108 554.67 P
1.12 (models. Three iterations of Baum W) 72 532.67 P
1.12 (elch were performed for both the Long Island and Boston) 252.65 532.67 P
0.23 (data. T) 72 510.67 P
0.23 (able 18 shows the results obtained, testing separately on speech recorded in Boston and) 105.21 510.67 P
(Long Island.) 72 488.67 T
0.37 (The Long Island models perform better because there is 30% more training data from LI) 108 332.67 P
0.08 (than from Boston. The dif) 72 310.67 P
0.08 (ferences in matched and cross conditions do suggest a certain amount) 195.46 310.67 P
-0.38 (of acoustic dif) 72 288.67 P
-0.38 (ferences between the two sets. W) 138.21 288.67 P
-0.38 (e see that both models perform better on the Bos-) 300.99 288.67 P
0.4 (ton test set. This was expected for the Boston models, but it is surprising for the LI models. It is) 72 266.67 P
0.88 (possible that the Boston part of the MALL88 database has more clearly-enunciated utterances) 72 244.67 P
0.2 (though these dif) 72 222.67 P
0.2 (ferences are not apparent by casual listening. This would explain the better per-) 150.39 222.67 P
(formance of both models on the Boston test set.) 72 200.67 T
0.49 (CDCN distributions were now trained separately on the Boston and LI training sets. The) 108 178.67 P
0.26 (test sets were processed with CDCN and recognition with the above models was rerun. The fol-) 72 156.67 P
(lowing results were obtained after CDCN was used to process the test data.) 72 134.67 T
2 12 Q
(LI test set) 289.55 435 T
(BOS test set) 355.55 435 T
(LI models) 196.8 411 T
(2.3) 303 411 T
(1.9) 375 411 T
(BOS models) 196.8 389 T
(3.8) 303 389 T
(2.0) 375 389 T
5 F
(T) 211.22 367 T
(able 18: Baseline W) 218.11 367 T
(ord Err) 318.4 367 T
(or Rates) 357.82 367 T
190.8 450 190.8 381.25 2 L
V
2 H
0 Z
N
277.2 452 277.2 380.75 2 L
V
0.5 H
N
349.2 452 349.2 380.75 2 L
V
N
421.2 450 421.2 381.25 2 L
V
2 H
N
189.8 451 422.2 451 2 L
V
N
189.8 425 422.2 425 2 L
V
N
189.8 403 422.2 403 2 L
V
0.5 H
N
189.8 381 422.2 381 2 L
V
N
FMENDPAGE
%%EndPage: "48" 50
%%Page: "49" 50
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 9: Environmental Adaptation) 72 749.33 T
(49) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
1 11 Q
0 X
-0.46 (W) 108 550.67 P
-0.46 (e see that CDCN has brought the LI test set acoustically closer to the LI models. W) 118.17 550.67 P
-0.46 (e see) 513.59 550.67 P
-0.63 (an 13% improvement on the LI test set. On the other hand CDCN did not improve the performance) 72 528.67 P
0.12 (of the Boston models on the Boston test set. This was expected as we assumed that the Boston) 72 506.67 P
0.51 (test set was already quite similar to the Boston training set and normalization was not required.) 72 484.67 P
(The cross condition results were not signi\336cantly changed.) 72 462.67 T
0 14 Q
(9.2.2) 72 432.67 T
(MALL91) 110.9 432.67 T
1 11 Q
-0.23 (As with the MALL88 database, SGS CD SCHMM word-based phone models were trained) 108 408.67 P
(for the Long Island and for the Boston sets, after splitting the database.) 72 386.67 T
-0.76 (The models were then tested on the Boston and Long Island test sets. The results obtained) 108 364.67 P
(are shown in T) 72 342.67 T
(able 20.) 142.83 342.67 T
0.83 (The dif) 108 208.67 P
0.83 (ferences in matched and cross conditions for this MALL91 data are greater than) 142.22 208.67 P
-0.23 (those observed in the MALL88 database. This suggests that there is a greater degree of acoustic) 72 186.67 P
0.06 (dif) 72 164.67 P
0.06 (ferences between the two, Boston and LI, sets. In this case both models perform better on the) 83.4 164.67 P
-0.38 (LI test set. This again suggests that in the MALL91 database the LI set is acoustically cleaner and) 72 142.67 P
(less confusable.) 72 120.67 T
2 12 Q
(LI test set) 308.56 681 T
(BOS test set) 374.55 681 T
(LI models +) 177.79 657 T
(LI trained CDCN) 177.79 643 T
(2.0) 322.01 657 T
(2.0) 394.01 657 T
(BOS models +) 177.79 621 T
(BOS trained CDCN) 177.79 607 T
(3.6) 322.01 621 T
(2.0) 394.01 621 T
5 F
(T) 201.4 585 T
(able 19: W) 208.3 585 T
(ord Err) 262.94 585 T
(or Rates after CDCN) 302.37 585 T
2 F
(LI test set) 289.55 311 T
(BOS test set) 355.55 311 T
(LI models) 196.8 287 T
(4.1) 303 287 T
(6.3) 375 287 T
(BOS models) 196.8 265 T
(4.9) 303 265 T
(5.6) 375 265 T
5 F
(T) 211.22 243 T
(able 20: Baseline W) 218.11 243 T
(ord Err) 318.4 243 T
(or Rates) 357.82 243 T
171.79 696 171.79 599.25 2 L
V
2 H
0 Z
N
296.21 698 296.21 598.75 2 L
V
0.5 H
N
368.21 698 368.21 598.75 2 L
V
N
440.21 696 440.21 599.25 2 L
V
2 H
N
170.79 697 441.21 697 2 L
V
N
170.79 671 441.21 671 2 L
V
N
170.79 635 441.21 635 2 L
V
0.5 H
N
170.79 599 441.21 599 2 L
V
N
190.8 326 190.8 257.25 2 L
V
2 H
N
277.2 328 277.2 256.75 2 L
V
0.5 H
N
349.2 328 349.2 256.75 2 L
V
N
421.2 326 421.2 257.25 2 L
V
2 H
N
189.8 327 422.2 327 2 L
V
N
189.8 301 422.2 301 2 L
V
N
189.8 279 422.2 279 2 L
V
0.5 H
N
189.8 257 422.2 257 2 L
V
N
FMENDPAGE
%%EndPage: "49" 51
%%Page: "50" 51
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 9: Environmental Adaptation) 72 749.33 T
(50) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
1 11 Q
0 X
-0.18 (CDCN distributions were trained separately from the MALL91 Boston and LI training sets.) 108 712.67 P
0.02 (The test sets were processed with CDCN and recognition with the above models was rerun. The) 72 690.67 P
(following are the results obtained after test data has been processed with CDCN.) 72 668.67 T
-0.4 (CDCN has improved the performance of the models both in matched conditions and cross) 108 484.67 P
-0.09 (conditions. The performance of the LI models improved by 7% on the LI test set and 9.5% on the) 72 462.67 P
0.51 (Boston test set. The performance of the Boston models improved by 9% on the Boston test set) 72 440.67 P
-0.14 (and 14% on the LI test set. W) 72 418.67 P
-0.14 (e see that the gains have been more in the cross conditions. These) 214.96 418.67 P
0.51 (results show us that there is a greater amount of mismatch in the MALL91 database than there) 72 396.67 P
0.54 (was in the MALL88 database. This was expected as the training for the MALL91 database was) 72 374.67 P
-0.07 (always more involved in order to reach a comparable \050to MALL88\051 level of performance. Further-) 72 352.67 P
0.19 (more we see that the gains obtained by CDCN are more across the dif) 72 330.67 P
0.19 (ferent environment rather) 416.27 330.67 P
(than across the training and testing sets.) 72 308.67 T
0 14 Q
(9.3) 72 272.67 T
(T) 99.23 272.67 T
(est set Normalization) 106.74 272.67 T
1 11 Q
-0.14 (In this section we look the ability of CDCN to bring the test set closer to the training set by) 108 248.67 P
-0.36 (applying CDCN to the test set. The CDCN distribution are trained on the entire training set. These) 72 226.67 P
0.39 (experiments for the MALL88 and the MALL91 databases were performed using the models that) 72 204.67 P
-0.13 (provided the best recognition accuracies. W) 72 182.67 P
-0.13 (e did this in order to learn how much CDCN process-) 284.26 182.67 P
0.89 (ing would help when the most optimized models were being used. The performance of unopti-) 72 160.67 P
-0.36 (mized models can be improved by CDCN and by further training thus obscuring the real cause for) 72 138.67 P
(the gain in performance.) 72 116.67 T
2 12 Q
(LI test set) 308.56 615 T
(BOS test set) 374.55 615 T
(LI models +) 177.79 591 T
(LI trained CDCN) 177.79 577 T
(3.8) 322.37 591 T
(5.7) 403.37 591 T
(BOS models +) 177.79 555 T
(BOS trained CDCN) 177.79 541 T
(4.2) 322.37 555 T
(5.1) 403.37 555 T
5 F
(T) 201.4 519 T
(able 21: W) 208.3 519 T
(ord Err) 262.94 519 T
(or Rates after CDCN) 302.37 519 T
171.79 630 171.79 533.25 2 L
V
2 H
0 Z
N
296.21 632 296.21 532.75 2 L
V
0.5 H
N
368.21 632 368.21 532.75 2 L
V
N
440.21 630 440.21 533.25 2 L
V
2 H
N
170.79 631 441.21 631 2 L
V
N
170.79 605 441.21 605 2 L
V
N
170.79 569 441.21 569 2 L
V
0.5 H
N
170.79 533 441.21 533 2 L
V
N
FMENDPAGE
%%EndPage: "50" 52
%%Page: "51" 52
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 9: Environmental Adaptation) 72 749.33 T
(51) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
1 11 Q
0 X
0.52 (Following are the baseline \050best system\051 and post CDCN \050best system + CDCN\051 results) 108 712.67 P
-0.2 (for the MALL88 and MALL91 databases. MGS sex dependent models were used for the MALL88) 72 690.67 P
0.32 (tests and MGS generic models were used for the MALL91 tests. Cross-database tests were not) 72 668.67 P
(performed as these databases dif) 72 646.67 T
(fer along more than just the environment dimension.) 234.85 646.67 T
0.75 (W) 108 462.67 P
0.75 (e observe no signi\336cant improvement in the performance with the use of CDCN. This) 118.17 462.67 P
-0.5 (suggests that the models have completely modelled all the environmental variability in the training) 72 440.67 P
0.45 (set and as the test set is close to the training set further normalization does not improve perfor-) 72 418.67 P
(mance further) 72 396.67 T
(.) 139.17 396.67 T
0 14 Q
(9.4) 72 360.67 T
(Summary) 99.23 360.67 T
1 11 Q
-0.49 (The following are the facts that were gleaned about CDCN\325) 108 336.67 P
-0.49 (s ability to achieve channel and) 389.78 336.67 P
-0.23 (environment normalization. CDCN improved performance to a limited degree due to channel nor-) 72 314.67 P
-0.03 (malization. CDCN appears to help when the models have not reached the optimum performance) 72 292.67 P
0.49 (level. However) 72 270.67 P
0.49 (, CDCN does not improve performance once the models have been optimized to) 143.92 270.67 P
1.69 (closely model the data. There are two reasons for the lack of performance gain provided by) 72 248.67 P
-0.36 (CDCN. CDCN works best in conditions where there is a mismatch in the acoustic condition os the) 72 226.67 P
0.3 (training and testing data. These mismatches are modelled as the test data being corrupted by a) 72 204.67 P
0.37 (linear channel and additive noise. In this task we reduce mismatch between training and testing) 72 182.67 P
-0.63 (data by ensuring that the training data resembles the test data as closely as possible. Furthermore) 72 160.67 P
0.11 (the linear channel assumption is a good model for the telephone channel. W) 72 138.67 P
0.11 (e believe that better) 443.18 138.67 P
0.44 (results can be obtained by using a normalization technique that models the nonlinearities found) 72 116.67 P
(in telephone channels.) 72 94.67 T
2 12 Q
(T) 207.86 593 T
(rain &) 214.76 593 T
(T) 205.4 579 T
(est Sets) 211.89 579 T
(No CDCN) 273.31 586 T
-1.02 (T) 340.8 593 P
-1.02 (est Set CDCN) 347.29 593 P
(Processed) 354.02 579 T
(MALL88) 196.8 555 T
(1.6) 285 555 T
(1.6) 366 555 T
(MALL91) 196.8 533 T
(1.9) 285 533 T
(1.8) 366 533 T
5 F
(T) 77.02 511 T
(able 22: Comparison of baseline WERs to those obtained after CDCN was applied to the) 83.91 511 T
(test sets.) 284.69 497 T
190.8 608 190.8 526 2 L
V
2 H
0 Z
N
262.8 610 262.8 524 2 L
V
0.5 H
N
334.8 610 334.8 524 2 L
V
N
421.2 608 421.2 526 2 L
V
2 H
N
189.8 609 422.2 609 2 L
V
N
189.8 569 422.2 569 2 L
V
N
189.8 547 422.2 547 2 L
V
0.5 H
N
189.8 525 422.2 525 2 L
V
2 H
N
FMENDPAGE
%%EndPage: "51" 53
%%Page: "52" 53
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 10: Conclusion) 72 749.33 T
(52) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
0 18 Q
0 X
(Chapter 10) 259.51 708 T
(Conclusion) 257.02 674 T
1 11 Q
0.59 (In this chapter we discuss the results we obtained in this work. Finally we close by sug-) 108 638.67 P
(gesting some directions for future work.) 72 616.67 T
0.26 (In this work we have shown that a large vocabulary system, SPHINX II, can be success-) 108 250.67 P
-0.7 (fully adapted and optimized for the task of digit recognition. As we see in the diagram above, which) 72 228.67 P
-0.06 (shows the reduction in WER obtained for the MALL88 test set, we started with a system that had) 72 206.67 P
1.29 (been optimized for large vocabulary recognition and by exploring new training paradigms and) 72 184.67 P
72 72 540 720 C
72 291 540 591 C
0 0 0 468 288 468 288 72 297 FMBEGINEPSF
%%BeginDocument: <inline>
%!PS-Adobe-2.0 EPSF-1.2
%%DocumentFonts: (atend)
%%Creator: PLOT X1.0c
%%Pages: 0
%%BoundingBox: 0 0 468 288
%%EndComments
/MT {moveto} bind def
/LT {lineto} bind def
/sethsbcolor {setgray pop pop} bind def
/x2sqrt3 2 sqrt 3 mul def
%
% () x y o DoLText
%
%  Left justified text.
/DoLText {
    gsave
    3 1 roll
    translate
    rotate
    newpath
    0 0 moveto
    show
    grestore
} def
%
% () x y o DoRText
%
%  Right justified text.
/DoRText {
    gsave
    3 1 roll
    translate
    rotate
    dup stringwidth pop neg 0 translate
    newpath
    0 0 moveto
    show
    grestore
} def
%
% () x y o DoCText
%
%  Center justified text.
/DoCText {
    gsave
    3 1 roll
    translate
    rotate
    dup stringwidth pop 2 div neg 0 translate
    newpath
    0 0 moveto
    show
    grestore
} def
%
% Symbol Definitions
%
%
/SymbolStart {
    gsave
    [] 0 setdash
    3 1 roll
    translate
    dup dup scale
    1 exch div setlinewidth
    newpath
} def
/SBox {
    SymbolStart
    -3 -3 moveto
    3 -3 lineto
    3 3 lineto
    -3 3 lineto
    closepath
    stroke
    grestore
} def
/SBullet {
    SymbolStart
    0 0 3 0 360 arc fill
    grestore
} def
/SCircle {
    SymbolStart
    0 0 3 0 360 arc stroke
    grestore
} def
/SCross {
    SymbolStart
    -3 -3 moveto
    3 3 lineto stroke
    -3 3 moveto
    3 -3 lineto stroke
    grestore
} def
/SCustom {
    pop pop pop
} def
/SDel {
    SymbolStart
    x2sqrt3 2 moveto
    x2sqrt3 neg 2 lineto
    0 -4 lineto
    closepath stroke
    grestore
} def
/SPlus {
    SymbolStart
    -3 0 moveto
    3 0 lineto stroke
    0 -3 moveto
    0 3 lineto stroke
    grestore
} def
/SDiamond {
    SymbolStart
    45 rotate
    -3 -3 moveto
    3 -3 lineto
    3 3 lineto
    -3 3 lineto
    closepath
    stroke
    grestore
} def
/SEllipse {
    SymbolStart
    2 1 scale
    0 0 3 0 360 arc
    closepath
    stroke
    grestore
} def
/SNone {
    pop pop pop
} def
/SNumber {
    SymbolStart
    grestore
} def
/SSolidBox {
    SymbolStart
    -3 -3 moveto
    3 -3 lineto
    3 3 lineto
    -3 3 lineto
    closepath
    fill
    grestore
} def
/StarSide 6 36 cos div dup 36 sin mul sub 36 sin mul 36 cos div def
/SStar {
    SymbolStart
    0 3 translate
    -108 rotate
    0 0 moveto
    5 {
	StarSide 0 translate
	0 0 lineto
	-72 rotate
	StarSide 0 translate
	0 0 lineto
	144 rotate
    } repeat
    closepath
    stroke
    grestore
} def
/STriangle {
    SymbolStart
    x2sqrt3 -2 moveto
    x2sqrt3 neg -2 lineto
    0 4 lineto
    closepath stroke
    grestore
} def
%
% ci w h o x y bar
%
/bar {
    gsave
    translate
    rotate
%
    exch 2 div exch		% ci w/2 h
%
    newpath
    2 copy pop 0 moveto
    2 copy lineto
    2 copy exch neg exch lineto
    2 copy pop neg 0 lineto
    closepath stroke		% ci w/2 h
%
    3 -1 roll dup 0 ne {	% w/2 h ci
	3 copy pop moveto	% w/2 h ci
	3 copy add lineto
	3 copy add exch neg exch lineto
	3 copy pop exch neg exch lineto
	stroke
	3 copy pop moveto	% w/2 h ci
	3 copy sub lineto
	3 copy sub exch neg exch lineto
	3 copy pop exch neg exch lineto
	stroke
	currentlinewidth 2 mul setlinewidth
	pop 2 copy moveto
	exch neg exch lineto stroke
    } {pop pop pop } ifelse
%
    grestore
} def
%
% a linesfill
% 
/linesfill {
    gsave
    clip
    initmatrix
    MFactor MFactor scale
    0.5 setlinewidth
    rotate
    1 dict begin
    /ksp 1000 MFactor div def
    ksp neg 5 ksp {	% v
	newpath
	dup ksp exch moveto
	ksp neg exch lineto stroke
    } for
    end
    grestore
    newpath
} def
%
% a lines2fill
% 
/lines2fill {
    gsave
    clip
    initmatrix
    MFactor MFactor scale
    0.5 setlinewidth
    rotate
    1 dict begin
    /ksp 1000 MFactor div def
    ksp neg 8 ksp {	% v
	newpath
	dup ksp exch moveto
	dup ksp neg exch lineto stroke
	2 add
	dup ksp exch moveto
	ksp neg exch lineto stroke
    } for
    end
    grestore
    newpath
} def
%
% a lineswfill
% 
/lineswfill {
    gsave
    clip
    initmatrix
    MFactor MFactor scale
    0.5 setlinewidth
    rotate
    1 dict begin
    /ksp 1000 MFactor div def
    ksp neg 10 ksp {	% v
	newpath
	dup ksp exch moveto
	ksp neg exch lineto stroke
    } for
    end
    grestore
    newpath
} def
/crosshatch {
    dup gsave linesfill grestore
    90 add linesfill
} def
%
% ci w h o x y {pg2} {pg1} linefillbar
%
/fillbar {
    2 dict begin
    /pg1 exch def
    /pg2 exch def    
    6 copy			% save bar parameters
    gsave
    translate
    rotate
%
    exch 2 div exch		% ci w/2 h
    3 -1 roll			% w/2 h ci
%
    newpath
%
    3 copy pop pop neg 0 moveto
    3 copy sub exch neg exch lineto
    3 copy sub lineto
    3 copy pop pop 0 lineto
    closepath pg1
%
    3 copy sub exch neg exch moveto
    3 copy add exch neg exch lineto
    3 copy add lineto
    3 copy sub lineto
    closepath pg2
%
    grestore
    pop pop pop
    bar
    end
} def
%%EndProlog
save	% Start Page
save
0.0 0.0 translate
1.000000 1.000000 scale
/MFactor 1.000000 def
1.000000 setlinewidth
[] 0 setdash
1.000000 setlinewidth
[] 0 setdash
0.0 30.9 212.8 0 43.7 63.6 {0.0 0.0 0.9 sethsbcolor fill} {0.0 0.0 0.6 sethsbcolor fill} fillbar
0.0 34.4 112.6 0 97.1 63.6 {0.0 0.0 0.9 sethsbcolor fill} {0.0 0.0 0.6 sethsbcolor fill} fillbar
0.0 34.4 80.7 0 165.9 63.6 {0.0 0.0 0.9 sethsbcolor fill} {0.0 0.0 0.6 sethsbcolor fill} fillbar
0.0 34.4 55.0 0 234.7 63.6 {0.0 0.0 0.9 sethsbcolor fill} {0.0 0.0 0.6 sethsbcolor fill} fillbar
0.0 34.4 37.5 0 303.5 63.6 {0.0 0.0 0.9 sethsbcolor fill} {0.0 0.0 0.6 sethsbcolor fill} fillbar
0.0 34.4 11.8 0 372.3 63.6 {0.0 0.0 0.9 sethsbcolor fill} {0.0 0.0 0.6 sethsbcolor fill} fillbar
0.0 17.2 10.0 0 432.5 63.6 {0.0 0.0 0.9 sethsbcolor fill} {0.0 0.0 0.6 sethsbcolor fill} fillbar
1.000000 setlinewidth
[] 0 setdash
42.0 276.4 1.0000 SNone
97.1 176.2 1.0000 SNone
165.9 144.3 1.0000 SNone
234.7 118.6 1.0000 SNone
303.5 101.1 1.0000 SNone
372.3 75.4 1.0000 SNone
441.1 73.6 1.0000 SNone
newpath
28.3 63.6 MT
441.1 63.6 LT
stroke
42.0 63.6 MT
42.0 67.2 LT
stroke
97.1 63.6 MT
97.1 67.2 LT
stroke
165.9 63.6 MT
165.9 67.2 LT
stroke
234.7 63.6 MT
234.7 67.2 LT
stroke
303.5 63.6 MT
303.5 67.2 LT
stroke
372.3 63.6 MT
372.3 67.2 LT
stroke
441.1 63.6 MT
441.1 67.2 LT
stroke
/Helvetica findfont 10 scalefont setfont
(SYSTEM USED) 369.5 14.0 0 DoLText
(Bandlimited) 16.0 50.0 0 DoLText
(Bandlimited ) 69.7 50.0 0 DoLText
(with ) 86.9 36.9 0 DoLText
(digit dictionary) 65.2 23.8 0 DoLText
(Filtered ) 147.9 50.0 0 DoLText
(speech models) 132.4 36.9 0 DoLText
(Telephone speech ) 192.3 50.0 0 DoLText
(models) 218.7 36.9 0 DoLText
(Initialized ) 281.4 50.0 0 DoLText
(training) 287.2 36.9 0 DoLText
(Data driven ) 345.4 50.0 0 DoLText
(training) 356.0 36.9 0 DoLText
(New phone ) 414.5 50.0 0 DoLText
(set) 434.5 36.9 0 DoLText
28.3 63.6 MT
28.3 282.7 LT
stroke
28.3 94.9 MT
31.9 94.9 LT
stroke
28.3 126.2 MT
31.9 126.2 LT
stroke
28.3 157.5 MT
31.9 157.5 LT
stroke
28.3 188.8 MT
31.9 188.8 LT
stroke
28.3 220.1 MT
31.9 220.1 LT
stroke
28.3 251.4 MT
31.9 251.4 LT
stroke
28.3 282.7 MT
31.9 282.7 LT
stroke
(WORD ERROR RATE) 10.0 182.8 90 DoLText
(5) 19.2 89.9 0 DoLText
(10) 13.6 121.2 0 DoLText
(15) 13.6 152.5 0 DoLText
(20) 13.6 183.8 0 DoLText
(25) 13.6 215.1 0 DoLText
(30) 13.6 246.4 0 DoLText
(35) 13.6 277.7 0 DoLText
(0) 19.2 58.6 0 DoLText
/Helvetica-BoldOblique findfont 14 scalefont setfont
(Overall word error rate reduction) 124.9 0.0 0 DoLText
restore
%%Trailer
restore
%%DocumentFonts: Helvetica Helvetica-BoldOblique

%%EndDocument
FMENDEPSF
72 72 540 720 C
0 0 612 792 C
FMENDPAGE
%%EndPage: "52" 54
%%Page: "53" 54
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 10: Conclusion) 72 749.33 T
(53) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
1 11 Q
0 X
-0.03 (adapting the acoustic models we were able eventually to achieve respectable results for the digit) 72 712.67 P
(recognition task. W) 72 690.67 T
(e summarize the advantages obtained from the dif) 165.22 690.67 T
(ferent solutions explored) 409.28 690.67 T
(\245) 90 668.67 T
(T) 99 668.67 T
(raining models as close to the testing data as possible) 105.31 668.67 T
(\245) 90 645.67 T
(Making the system completely digit oriented) 99 645.67 T
(\245) 90 622.67 T
(Increasing the model size, from phone-level models to word level models) 99 622.67 T
(\245) 90 599.67 T
(Reducing the amount of parameter sharing) 99 599.67 T
0 14 Q
(10.1) 72 572.67 T
(T) 107.01 572.67 T
(raining models closer to the training data) 114.79 572.67 T
1 11 Q
-0.29 (The digit database that we were trying to recognize had been collected over long distance) 108 548.67 P
-0.28 (telephone channels. Starting from models trained on bandlimited speech we improved the perfor-) 72 526.67 P
0.67 (mance by testing on models trained on speech \336ltered by the average telephone channel. This) 72 504.67 P
-0.46 (improvement was due to the additional modelling of the spectral coloration of the channel. Further) 72 482.67 P
0.91 (improvements were then obtained by testing using models that were trained on real telephone) 72 460.67 P
-0.48 (speech. This improvement re\337ects the fact that speech recognition systems are sensitive to dif) 72 438.67 P
-0.48 (fer-) 523.52 438.67 P
0.27 (ences between the training and testing environments. Furthermore we observe that the ef) 72 416.67 P
0.27 (fect of) 509.8 416.67 P
0.14 (the telephone channel is more than that of bandlimiting and attenuating some frequencies of the) 72 394.67 P
(speech signal.) 72 372.67 T
0 14 Q
(10.2) 72 336.67 T
(Making the system completely digit oriented) 107.01 336.67 T
1 11 Q
-0.69 (Large vocabulary systems are optimized to work with dictionaries with thousands of words.) 108 312.67 P
0.15 (These systems then depend on language model scores, along with acoustic scores to prune the) 72 290.67 P
0.02 (search space caused by the large vocabulary) 72 268.67 P
0.02 (. In the digit task we did not have the added bene\336t) 291.77 268.67 P
-0.2 (that is derived from language modelling. The search space was reduced by limiting the dictionary) 72 246.67 P
-0.1 (to the digits to be recognized. This improved the performance by reducing the amounts of substi-) 72 224.67 P
(tutions in the hypotheses.) 72 202.67 T
-0.08 (Further improvements were obtained by training models using the digit training database.) 108 180.67 P
0.63 (T) 72 158.67 P
0.63 (o this end we explored two training paradigms. The \336rst, using existing models to initialize the) 77.49 158.67 P
-0.16 (training data, is the method routinely used when training models for a large-vocabulary task. This) 72 136.67 P
0.88 (method did not improve performance much further than the initializing models. W) 72 114.67 P
0.88 (e believe this) 474.12 114.67 P
0.55 (was because the initializing models caused the training to settle in a local maximum which was) 72 92.67 P
FMENDPAGE
%%EndPage: "53" 55
%%Page: "54" 55
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 10: Conclusion) 72 749.33 T
(54) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
1 11 Q
0 X
0.36 (close to the maxima that the models themselves had been trained too. W) 72 712.67 P
0.36 (e require a completely) 430.86 712.67 P
0.11 (fresh way of initializing the training data if we are to move away from the local maxima of the ini-) 72 690.67 P
(tializing models.) 72 668.67 T
0.84 (The second method attempted to move the training procedure away from local maxima) 108 646.67 P
0.05 (around previously trained models by not using them to initialize the data. In this case the models) 72 624.67 P
0.76 (were trained using only the training data and not using any extraneous information or assump-) 72 602.67 P
-0.54 (tions. This method provide models that showed a drastic improvement in performance. This meth-) 72 580.67 P
0.05 (od is applicable to a small vocabulary task with automatic clustering as the models to be learned) 72 558.67 P
-0.66 (are small in number and the training data exhibits limited variability) 72 536.67 P
-0.66 (. This method would not be suc-) 388.23 536.67 P
-0.37 (cessful in a large-vocabulary tasks as the amount of variability is higher and the training data can-) 72 514.67 P
0.25 (not be clustered automatically without substantial errors. Hence for these tasks the training data) 72 492.67 P
(is initialized by using existing models.) 72 470.67 T
0 14 Q
(10.3) 72 434.67 T
(Increased models size and reduced parameter sharing) 107.01 434.67 T
1 11 Q
-0.28 (Small-vocabulary systems by their very nature have fewer parameters to train. This allevi-) 108 410.67 P
0.37 (ates the problem of limited training data that one faces when training large vocabulary systems.) 72 388.67 P
-0.59 (The fewer parameters allow us to reduce the parameter sharing and eventually train sharper mod-) 72 366.67 P
0.47 (els that closer model the acoustic data. The existence of enough training data also allows us to) 72 344.67 P
-0.19 (increase the model size \050from phone to word models\051 which is a advantage in continuous speech) 72 322.67 P
-0.05 (recognition systems. Larger models allow closer modelling of coarticulation ef) 72 300.67 P
-0.05 (fects. W) 447.48 300.67 P
-0.05 (e achieved) 486.92 300.67 P
-0.37 (both of these ends by de\336ning phones that were dependent on words, word based phones. In this) 72 278.67 P
-0.11 (work we have shown that these models improve performance over the usual phone models. This) 72 256.67 P
(leads us to believe that greater improvements can be derived by training pure word models.) 72 234.67 T
0 14 Q
(10.4) 72 198.67 T
(Normalization) 107.01 198.67 T
1 11 Q
0.96 (Finally we explored the possibility of bringing the training set and the test set closer by) 108 174.67 P
-0.1 (channel and test set normalization. T) 72 152.67 P
-0.1 (o this end we used the CDCN algorithm which works in situ-) 249.83 152.67 P
0.19 (ations where there is no stereo \050simultaneous recording of clean and noisy\051 data. This algorithm) 72 130.67 P
-0.35 (assumes that the speech has been corrupted by a linear channel and additive noise. Because lin-) 72 108.67 P
0.71 (ear \336ltering and noise ef) 72 86.67 P
0.71 (fects do not appear to be the limiting factors for digit recognition in the) 191.88 86.67 P
FMENDPAGE
%%EndPage: "54" 56
%%Page: "55" 56
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(Chapter 10: Conclusion) 72 749.33 T
(55) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
1 11 Q
0 X
-0.63 (present system, we did not observe improvements in performance using CDCN on our databases.) 72 712.67 P
0.29 (W) 72 690.67 P
0.29 (e believe that better results could have been obtained by modelling the nonlinearities found in) 82.17 690.67 P
(telephone channels.) 72 668.67 T
0 14 Q
(10.5) 72 632.67 T
(Future W) 107.01 632.67 T
(ork) 167.39 632.67 T
1 11 Q
(Further improvements in performance in the digit recognition task can be obtained by) 108 608.67 T
0 14 Q
(10.5.1) 72 578.67 T
(Power variance training) 118.68 578.67 T
1 11 Q
-0.33 (Here we increase the parameter set to also model the variance in the power of our feature) 108 554.67 P
0.73 (vectors. This method has shown some improvements in recognition of telephone and low SNR) 72 532.67 P
(speech.) 72 510.67 T
0 14 Q
(10.5.2) 72 480.67 T
(Silence removal) 118.68 480.67 T
1 11 Q
0.6 (W) 108 456.67 P
0.6 (e should make sure that the training and testing corpus do not have large amounts of) 118.17 456.67 P
0.37 (non-speech events at the beginning and the end of the utterances. This is particularly important) 72 434.67 P
1.02 (when we try to automatically initialize the training data, as noise events would cause incorrect) 72 412.67 P
(clustering of the training data. Pilot experiments showed improved performance.) 72 390.67 T
FMENDPAGE
%%EndPage: "55" 57
%%Page: "56" 57
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(References) 72 749.33 T
(56) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
0 18 Q
0 X
(References) 257.51 708 T
1 11 Q
0.47 ([1]  A. Acero, \322Acoustical and Environmental Robustness in Automatic Speech Recogni-) 108 670.67 P
1.3 (tion\323, Ph.D. Thesis, Department of Electrical and Computer Engineering, Carnegie) 129.6 648.67 P
(Mellon University) 129.6 626.67 T
(, Sept., 1990.) 212.41 626.67 T
0.68 ([2]  F) 108 604.67 P
0.68 (. Alleva, X. Huang, and M. Hwang, \322An Improved Search Algorithm for Continuous) 133.17 604.67 P
-0.2 (Speech Recognition\323, IEEE International Conference on Acoustics, Speech, and Sig-) 129.6 582.67 P
(nal Processing, pp. II 307-310, May) 129.6 560.67 T
(, 1993.) 301.6 560.67 T
1.41 ([3]  R. Bakis, \322Continuous Speech Recognition via Centisecond Acoustic States\323, 91st) 108 538.67 P
(Meeting of the Acoustical Society of America, April, 1976.) 129.6 516.67 T
-0.08 ([4]  L. Baum, \322An Inequality and Associated Maximization T) 108 494.67 P
-0.08 (echnique in Statistical Estima-) 393.69 494.67 P
(tion of Probabilistic Functions of Markov Processes\323, Inequalities 3:1-8, 1972.) 129.6 472.67 T
0.38 ([5]  J. Bernstein and K. T) 108 450.67 P
0.38 (aussig., \322Macrophone: An American English T) 229.97 450.67 P
0.38 (elephone Speech) 454.11 450.67 P
0.75 (Corpus for the Polyphone Project\323. International Conference on Acoustics, Speech,) 129.6 428.67 P
(and Signal Processing, pp. I 81-84, May) 129.6 406.67 T
(, 1994.) 323.59 406.67 T
0.64 ([6]  R. Gray) 108 384.67 P
0.64 (, \322V) 165.27 384.67 P
0.64 (ector Quantization\323, IEEE T) 182.39 384.67 P
0.64 (ransactions onAcoustics, Speech, and Signal) 317.62 384.67 P
(Processing 1\0502\051:4-29, April, 1984.) 129.6 362.67 T
0.28 ([7]  X. Huang, Y) 108 340.67 P
0.28 (. Ariki, and M. Jack, Hidden Markov Models for Speech Recognition, Ed-) 185.26 340.67 P
(inburgh University Press, Edinburgh, U.K., 1990.) 129.6 318.67 T
-0.36 ([8]  X. Huang, F) 108 296.67 P
-0.36 (. Alleva, H. Hon, M. Hwang, K. Lee, R. Rosenfeld, \322The SPHINX-II Speech) 182.27 296.67 P
-0.55 (Recognition System: An Overview\323, Computer Speech and Language, vol. 2, pp. 137-) 129.6 274.67 P
(148, 1993.) 129.6 252.67 T
2 ([9]  M. Hwang, \322Subphonetic Acoustic Modeling for Speaker-Independent Continuous) 108 230.67 P
0.89 (Speech Recognition\323, Ph.D. Thesis, School of Computer Science, Carnegie Mellon) 129.6 208.67 P
(University) 129.6 186.67 T
(, Dec., 1993.) 177.01 186.67 T
1.02 ([10]  K. Lee, \322Large-V) 108 164.67 P
1.02 (ocabulary Speaker-Independent Continuous Speech Recognition:) 216.53 164.67 P
0.38 (The SPHINX System\323, Ph.D. Thesis, School of Computer Science, Carnegie Mellon) 129.6 142.67 P
(University) 129.6 120.67 T
(, April, 1988.) 177.01 120.67 T
1.59 ([1) 108 98.67 P
1.59 (1]  Y) 116.35 98.67 P
1.59 (. Linde, A. Buzo, R. Gray) 140.71 98.67 P
1.59 (, \322An Algorithm for V) 269.36 98.67 P
1.59 (ector Quantization Design\323, IEEE) 374.03 98.67 P
(T) 129.6 76.67 T
(ransactions on Communication COM-28\0501\051: 84-95, Jan., 1980.) 135.91 76.67 T
FMENDPAGE
%%EndPage: "56" 58
%%Page: "57" 58
612 792 0 FMBEGINPAGE
72 746 540 756 R
7 X
0 K
V
1 10 Q
0 X
(References) 72 749.33 T
(57) 528.89 749.33 T
72 32.67 540 42.67 R
7 X
V
72 72 540 720 R
V
1 11 Q
0 X
-0.01 ([12]  P) 108 712.67 P
-0.01 (. J. Moreno, M. A. Siegler) 138.33 712.67 P
-0.01 (, U. Jain, R. M. Stern, \322 Continuous Recognition of Large-) 261.64 712.67 P
0.69 (V) 129.6 690.67 P
0.69 (ocabulary T) 136.32 690.67 P
0.69 (elephone-Quality Speech\323, Proceedings of the Spoken Language Sys-) 193.19 690.67 P
(tems T) 129.6 668.67 T
(echnology W) 161.96 668.67 T
(orkshop, pp 70-73, Jan., 1995.) 225.26 668.67 T
0.5 ([13]  D. Paul, and J. Baker) 108 646.67 P
0.5 (, \322The Design of the W) 238.61 646.67 P
0.5 (all Street Journal-based CSR Corpus\323,) 350.58 646.67 P
0.47 (Proceedings of ARP) 129.6 624.67 P
0.47 (A Speech and Natural Language W) 228.65 624.67 P
0.47 (orkshop, pp. 357-362, Feb.,) 403.62 624.67 P
(1992.) 129.6 602.67 T
-0.03 ([14]  L. Rabiner) 108 580.67 P
-0.03 (, and B. Juang, Fundamentals of Speech Recognition, Prentice-Hall Inter-) 182.42 580.67 P
(national, New Jersey) 129.6 558.67 T
(, U.S.A., 1993.) 230.75 558.67 T
0.3 ([15]  R. Stern, F) 108 536.67 P
0.3 (. Liu, Y) 185.52 536.67 P
0.3 (. Ohshima, T) 218.9 536.67 P
0.3 (. Sullivan, and A. Acero, \322Multiple Approaches to Ro-) 281.16 536.67 P
1.45 (bust Speech Recognition\323, Proceedings of DARP) 129.6 514.67 P
1.45 (A Speech and Natural Language) 374.8 514.67 P
(W) 129.6 492.67 T
(orkshop, pp. 274-279, Feb., 1992.) 139.77 492.67 T
FMENDPAGE
%%EndPage: "57" 59
%%Trailer
%%BoundingBox: 0 0 612 792
%%Pages: 58 1
%%DocumentFonts: Helvetica-Bold
%%+ Helvetica
%%+ Times-Roman
%%+ Helvetica-Oblique
%%+ Symbol
%%+ Times-Bold
